{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67dca47b",
   "metadata": {
    "papermill": {
     "duration": 0.008489,
     "end_time": "2024-04-10T12:21:59.733223",
     "exception": false,
     "start_time": "2024-04-10T12:21:59.724734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Notebook modified from https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub.\n",
    "- Training only, EDA part not included.\n",
    "- Image model only, tabular data not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef498ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:21:59.751778Z",
     "iopub.status.busy": "2024-04-10T12:21:59.750488Z",
     "iopub.status.idle": "2024-04-10T12:22:15.761835Z",
     "shell.execute_reply": "2024-04-10T12:22:15.760561Z"
    },
    "papermill": {
     "duration": 16.02331,
     "end_time": "2024-04-10T12:22:15.764783",
     "exception": false,
     "start_time": "2024-04-10T12:21:59.741473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as imageio\n",
    "import albumentations as A\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import glob\n",
    "import torchmetrics\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "tqdm.pandas()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0df88d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:15.782126Z",
     "iopub.status.busy": "2024-04-10T12:22:15.781641Z",
     "iopub.status.idle": "2024-04-10T12:22:15.789559Z",
     "shell.execute_reply": "2024-04-10T12:22:15.787980Z"
    },
    "papermill": {
     "duration": 0.019925,
     "end_time": "2024-04-10T12:22:15.792387",
     "exception": false,
     "start_time": "2024-04-10T12:22:15.772462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    IMAGE_SIZE = 384\n",
    "    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n",
    "#     BACKBONE = 'tf_efficientnet_b0'\n",
    "    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "    N_TARGETS = len(TARGET_COLUMNS)\n",
    "    BATCH_SIZE = 64\n",
    "    LR_MAX = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    N_EPOCHS = 6\n",
    "    TRAIN_MODEL = True\n",
    "    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "    \n",
    "    MODEL_PATH = '/kaggle/input/plainttraits2024-swintransformer/model.pth'\n",
    "        \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1ac0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:15.810641Z",
     "iopub.status.busy": "2024-04-10T12:22:15.810123Z",
     "iopub.status.idle": "2024-04-10T12:22:58.646248Z",
     "shell.execute_reply": "2024-04-10T12:22:58.644915Z"
    },
    "papermill": {
     "duration": 42.855057,
     "end_time": "2024-04-10T12:22:58.655484",
     "exception": false,
     "start_time": "2024-04-10T12:22:15.800427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_TRAIN_SAMPLES: 49168 N_TEST_SAMPLES: 6545\n",
      "CPU times: user 2.77 s, sys: 7.14 s, total: 9.9 s\n",
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read_images = False\n",
    "\n",
    "if not read_images:\n",
    "    train = pd.read_pickle('/kaggle/input/plainttraits2024-swintransformer/train.pkl')\n",
    "    test = pd.read_pickle('/kaggle/input/plainttraits2024-swintransformer/test.pkl')\n",
    "else: \n",
    "    # if CONFIG.TRAIN_MODEL:\n",
    "    train = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\n",
    "    train['file_path'] = train['id'].apply(lambda s: f'/kaggle/input/planttraits2024/train_images/{s}.jpeg')\n",
    "    train['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n",
    "    train.to_pickle('train.pkl')\n",
    "\n",
    "    test = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n",
    "    test['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/planttraits2024/test_images/{s}.jpeg')\n",
    "    test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n",
    "    test.to_pickle('test.pkl')\n",
    "\n",
    "for column in CONFIG.TARGET_COLUMNS:\n",
    "    lower_quantile = train[column].quantile(0.005)\n",
    "    upper_quantile = train[column].quantile(0.985)  \n",
    "    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]    \n",
    "    \n",
    "CONFIG.N_TRAIN_SAMPLES = len(train)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1    \n",
    "    \n",
    "if CONFIG.TRAIN_MODEL:\n",
    "    print('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))\n",
    "else:\n",
    "    print('N_TEST_SAMPLES:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ead7df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.673497Z",
     "iopub.status.busy": "2024-04-10T12:22:58.671957Z",
     "iopub.status.idle": "2024-04-10T12:22:58.709070Z",
     "shell.execute_reply": "2024-04-10T12:22:58.707350Z"
    },
    "papermill": {
     "duration": 0.04931,
     "end_time": "2024-04-10T12:22:58.712230",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.662920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if CONFIG.TRAIN_MODEL:\n",
    "LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "\n",
    "y_df = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n",
    "for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "    v = train[target].values\n",
    "    if target in LOG_FEATURES:\n",
    "        v = np.log10(v)\n",
    "    y_df[:, target_idx] = v\n",
    "\n",
    "SCALER = StandardScaler()\n",
    "y_df = SCALER.fit_transform(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4015f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.730118Z",
     "iopub.status.busy": "2024-04-10T12:22:58.729301Z",
     "iopub.status.idle": "2024-04-10T12:22:58.737616Z",
     "shell.execute_reply": "2024-04-10T12:22:58.736514Z"
    },
    "papermill": {
     "duration": 0.020363,
     "end_time": "2024-04-10T12:22:58.740095",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.719732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MEAN = np.array([0.485, 0.456, 0.406])\n",
    "# STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# TRAIN_TRANSFORMS = A.Compose([\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.RandomSizedCrop(\n",
    "#             [int(0.85*CONFIG.IMAGE_SIZE), CONFIG.IMAGE_SIZE],\n",
    "#             CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n",
    "#         A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "#         A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "#         A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "#         A.ToFloat(),\n",
    "#         A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "#         ToTensorV2(),\n",
    "#     ])\n",
    "\n",
    "# TEST_TRANSFORMS = A.Compose([\n",
    "#         A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "#         A.ToFloat(),\n",
    "#         A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "#         ToTensorV2(),\n",
    "#     ])\n",
    "\n",
    "# class Dataset(Dataset):\n",
    "#     def __init__(self, X_jpeg_bytes, y, transforms=None):\n",
    "#         self.X_jpeg_bytes = X_jpeg_bytes\n",
    "#         self.y = y\n",
    "#         self.transforms = transforms\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X_jpeg_bytes)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         X_sample = self.transforms(\n",
    "#             image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "#         )['image']\n",
    "#         y_sample = self.y[index]\n",
    "        \n",
    "#         return X_sample, y_sample\n",
    "\n",
    "# if CONFIG.TRAIN_MODEL:\n",
    "#     # Splitting the data into training and validation sets\n",
    "#     train_df, val_df, y_train, y_val = train_test_split(train, y_df, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Creating datasets for training and validation\n",
    "#     train_dataset = Dataset(\n",
    "#         train_df['jpeg_bytes'].values,\n",
    "#         y_train,\n",
    "#         TRAIN_TRANSFORMS,\n",
    "#     )\n",
    "\n",
    "#     val_dataset = Dataset(\n",
    "#         val_df['jpeg_bytes'].values,\n",
    "#         y_val,\n",
    "#         TEST_TRANSFORMS,\n",
    "#     )\n",
    "\n",
    "#     # Creating dataloaders for training and validation\n",
    "#     train_dataloader = DataLoader(\n",
    "#         train_dataset,\n",
    "#         batch_size=CONFIG.BATCH_SIZE,\n",
    "#         shuffle=True,\n",
    "#         drop_last=True,\n",
    "#         num_workers=psutil.cpu_count(),\n",
    "#     )\n",
    "\n",
    "#     val_dataloader = DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=CONFIG.BATCH_SIZE,\n",
    "#         shuffle=False,  # No need to shuffle validation data\n",
    "#         num_workers=psutil.cpu_count(),\n",
    "#     )\n",
    "\n",
    "\n",
    "# test_dataset = Dataset(\n",
    "#     test['jpeg_bytes'].values,\n",
    "#     test['id'].values,\n",
    "#     TEST_TRANSFORMS,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac23755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.757682Z",
     "iopub.status.busy": "2024-04-10T12:22:58.757172Z",
     "iopub.status.idle": "2024-04-10T12:22:58.762704Z",
     "shell.execute_reply": "2024-04-10T12:22:58.761425Z"
    },
    "papermill": {
     "duration": 0.017473,
     "end_time": "2024-04-10T12:22:58.765210",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.747737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.backbone = timm.create_model(\n",
    "#                 CONFIG.BACKBONE,\n",
    "#                 num_classes=CONFIG.N_TARGETS,\n",
    "#                 pretrained=True)\n",
    "        \n",
    "#     def forward(self, inputs):\n",
    "#         return self.backbone(inputs)\n",
    "\n",
    "# model = Model()\n",
    "# model = model.to(device)\n",
    "# # print(model.backbone.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197360e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.782838Z",
     "iopub.status.busy": "2024-04-10T12:22:58.782330Z",
     "iopub.status.idle": "2024-04-10T12:22:58.794905Z",
     "shell.execute_reply": "2024-04-10T12:22:58.793888Z"
    },
    "papermill": {
     "duration": 0.024938,
     "end_time": "2024-04-10T12:22:58.797774",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.772836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_features = False\n",
    "\n",
    "if create_features:\n",
    "    feature_model = torch.load(CONFIG.MODEL_PATH)\n",
    "    feature_model.backbone.head.fc = nn.Identity()\n",
    "    feature_model.to(device);\n",
    "\n",
    "#     dataset = Dataset(\n",
    "#         train['jpeg_bytes'].values,\n",
    "#         y_df,\n",
    "#         TEST_TRANSFORMS,\n",
    "#     )\n",
    "    dataset = test_dataset\n",
    "\n",
    "    # Create a DataLoader for the dataset\n",
    "    dataloader = DataLoader(dataset, batch_size=CONFIG.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define the shape of the features array\n",
    "    num_samples = len(dataset)\n",
    "    num_features = 1536\n",
    "\n",
    "    # Initialize an empty array filled with zeros to store features\n",
    "    features_array = np.zeros((num_samples, num_features), dtype=np.float32)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize the index counter\n",
    "    index = 0\n",
    "\n",
    "    # Iterate over the data loader batches\n",
    "    for batch in dataloader:\n",
    "        if index % 10 == 0:\n",
    "            print(index, end=', ')\n",
    "\n",
    "        # Extract inputs and labels from the batch\n",
    "        inputs, _ = batch\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Forward pass through the model to extract features\n",
    "        with torch.no_grad():\n",
    "            features = feature_model(inputs)\n",
    "\n",
    "        # Flatten the features\n",
    "        features = features.view(features.size(0), -1)\n",
    "\n",
    "        # Calculate the end index for the current batch\n",
    "        end_index = index + inputs.size(0)\n",
    "\n",
    "        # Assign features to the pre-allocated array\n",
    "        features_array[index:end_index] = features.cpu().numpy()\n",
    "\n",
    "        # Update the index counter\n",
    "        index = end_index\n",
    "\n",
    "    # Save the features as a NumPy array\n",
    "    np.save('features_test.npy', features_array)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4770681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.816627Z",
     "iopub.status.busy": "2024-04-10T12:22:58.815742Z",
     "iopub.status.idle": "2024-04-10T12:22:58.821621Z",
     "shell.execute_reply": "2024-04-10T12:22:58.820485Z"
    },
    "papermill": {
     "duration": 0.018826,
     "end_time": "2024-04-10T12:22:58.824641",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.805815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# # Count parameters\n",
    "# num_parameters = count_parameters(model)\n",
    "# print(\"Number of parameters in the model:\", num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65affab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.843877Z",
     "iopub.status.busy": "2024-04-10T12:22:58.843386Z",
     "iopub.status.idle": "2024-04-10T12:22:58.851161Z",
     "shell.execute_reply": "2024-04-10T12:22:58.849778Z"
    },
    "papermill": {
     "duration": 0.020894,
     "end_time": "2024-04-10T12:22:58.854311",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.833417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_lr_scheduler(optimizer):\n",
    "#     return torch.optim.lr_scheduler.OneCycleLR(\n",
    "#         optimizer=optimizer,\n",
    "#         max_lr=CONFIG.LR_MAX,\n",
    "#         total_steps=CONFIG.N_STEPS,\n",
    "#         pct_start=0.1,\n",
    "#         anneal_strategy='cos',\n",
    "#         div_factor=1e1,\n",
    "#         final_div_factor=1e1,\n",
    "#     )\n",
    "\n",
    "# class AverageMeter(object):\n",
    "#     def __init__(self):\n",
    "#         self.reset()\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.avg = 0\n",
    "#         self.sum = 0\n",
    "#         self.count = 0\n",
    "\n",
    "#     def update(self, val):\n",
    "#         self.sum += val.sum()\n",
    "#         self.count += val.numel()\n",
    "#         self.avg = self.sum / self.count\n",
    "\n",
    "# if CONFIG.TRAIN_MODEL:\n",
    "#     MAE = torchmetrics.regression.MeanAbsoluteError().to(device)\n",
    "#     R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to(device)\n",
    "#     LOSS = AverageMeter()\n",
    "\n",
    "#     Y_MEAN = torch.tensor(y_train).mean(dim=0).to(device)\n",
    "#     EPS = torch.tensor([1e-6]).to(device)\n",
    "\n",
    "#     def r2_loss(y_pred, y_true):\n",
    "#         ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n",
    "#         ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n",
    "#         ss_total = torch.maximum(ss_total, EPS)\n",
    "#         r2 = torch.mean(ss_res / ss_total)\n",
    "#         return r2\n",
    "\n",
    "#     LOSS_FN = r2_loss\n",
    "\n",
    "#     optimizer = torch.optim.AdamW(\n",
    "#         params=model.parameters(),\n",
    "#         lr=CONFIG.LR_MAX,\n",
    "#         weight_decay=CONFIG.WEIGHT_DECAY,\n",
    "#     )\n",
    "\n",
    "#     LR_SCHEDULER = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2508fb28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.875440Z",
     "iopub.status.busy": "2024-04-10T12:22:58.874643Z",
     "iopub.status.idle": "2024-04-10T12:22:58.887147Z",
     "shell.execute_reply": "2024-04-10T12:22:58.885999Z"
    },
    "papermill": {
     "duration": 0.028015,
     "end_time": "2024-04-10T12:22:58.890467",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.862452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if CONFIG.TRAIN_MODEL:\n",
    "#     print(\"Start Training:\")\n",
    "#     for epoch in range(CONFIG.N_EPOCHS):\n",
    "#         MAE.reset()\n",
    "#         R2.reset()\n",
    "#         LOSS.reset()\n",
    "#         model.train()\n",
    "\n",
    "#         for step, (X_batch, y_true) in enumerate(train_dataloader):\n",
    "#             X_batch = X_batch.to(device)\n",
    "#             y_true = y_true.to(device)\n",
    "#             t_start = time.perf_counter_ns()\n",
    "#             y_pred = model(X_batch)\n",
    "#             loss = LOSS_FN(y_pred, y_true)\n",
    "#             LOSS.update(loss)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             LR_SCHEDULER.step()\n",
    "#             MAE.update(y_pred, y_true)\n",
    "#             R2.update(y_pred, y_true)\n",
    "\n",
    "#             if not CONFIG.IS_INTERACTIVE and (step+1) == len(train_dataloader):\n",
    "#                 print(\n",
    "#                     f'EPOCH {epoch+1:02d}, {step+1:04d}/{len(train_dataloader)} | ' + \n",
    "#                     f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "#                     f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "#                 )\n",
    "#             elif CONFIG.IS_INTERACTIVE:\n",
    "#                 print(\n",
    "#                     f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{len(train_dataloader)} | ' + \n",
    "#                     f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "#                     f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "#                     end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n",
    "#                 )\n",
    "            \n",
    "#         MAE.reset()\n",
    "#         R2.reset()\n",
    "#         LOSS.reset()\n",
    "#         model.eval()\n",
    "        \n",
    "#         print()\n",
    "        \n",
    "#         for step, (X_batch, y_true) in enumerate(val_dataloader):\n",
    "#             X_batch = X_batch.to(device)\n",
    "#             y_true = y_true.to(device)\n",
    "#             t_start = time.perf_counter_ns()\n",
    "#             with torch.no_grad():\n",
    "#                 y_pred = model(X_batch)\n",
    "#                 loss = LOSS_FN(y_pred, y_true)\n",
    "                \n",
    "#             LOSS.update(loss)\n",
    "#             MAE.update(y_pred, y_true)\n",
    "#             R2.update(y_pred, y_true)\n",
    "#             if not CONFIG.IS_INTERACTIVE and (step+1) == len(val_dataloader):\n",
    "#                 print(\n",
    "#                     f'EPOCH VAL, {epoch+1:02d}, {step+1:04d}/{len(val_dataloader)} | ' + \n",
    "#                     f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "#                     f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "#                 )\n",
    "#             elif CONFIG.IS_INTERACTIVE:\n",
    "#                 print(\n",
    "#                     f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{len(val_dataloader)} | ' + \n",
    "#                     f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "#                     f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "#                     end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n",
    "#                 )\n",
    "#         print()\n",
    "\n",
    "#     torch.save(model, 'model.pth')\n",
    "# else:\n",
    "#     model = torch.load(CONFIG.MODEL_PATH)\n",
    "#     model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d7198f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:22:58.912402Z",
     "iopub.status.busy": "2024-04-10T12:22:58.911804Z",
     "iopub.status.idle": "2024-04-10T12:23:04.889286Z",
     "shell.execute_reply": "2024-04-10T12:23:04.887917Z"
    },
    "papermill": {
     "duration": 5.992241,
     "end_time": "2024-04-10T12:23:04.892788",
     "exception": false,
     "start_time": "2024-04-10T12:22:58.900547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = np.load('/kaggle/input/planttraits2024-image-features/features_train.npy')\n",
    "test_features = np.load('/kaggle/input/planttraits2024-image-features/features_test.npy')\n",
    "\n",
    "features_df = pd.DataFrame(train_features)\n",
    "features_df.columns = [f'feature_{i}' for i in range(train_features.shape[1])]\n",
    "features_df.head()\n",
    "\n",
    "train_df = pd.concat([train.reset_index(drop=True), features_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "features_df = pd.DataFrame(test_features)\n",
    "features_df.columns = [f'feature_{i}' for i in range(test_features.shape[1])]\n",
    "features_df.head()\n",
    "\n",
    "test_df = pd.concat([test.reset_index(drop=True), features_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4371bd84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:23:04.911615Z",
     "iopub.status.busy": "2024-04-10T12:23:04.911168Z",
     "iopub.status.idle": "2024-04-10T18:46:42.074568Z",
     "shell.execute_reply": "2024-04-10T18:46:42.068997Z"
    },
    "papermill": {
     "duration": 23017.180855,
     "end_time": "2024-04-10T18:46:42.082033",
     "exception": false,
     "start_time": "2024-04-10T12:23:04.901178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doing cross-validation scoring for X4_mean...\n",
      "R^2 score for X4_mean: 0.7131849654656999\n",
      "Training model for X4_mean...\n",
      "\n",
      "Doing cross-validation scoring for X11_mean...\n",
      "R^2 score for X11_mean: 0.672348941822913\n",
      "Training model for X11_mean...\n",
      "\n",
      "Doing cross-validation scoring for X18_mean...\n",
      "R^2 score for X18_mean: 0.7029637869477492\n",
      "Training model for X18_mean...\n",
      "\n",
      "Doing cross-validation scoring for X50_mean...\n",
      "R^2 score for X50_mean: 0.656351349996905\n",
      "Training model for X50_mean...\n",
      "\n",
      "Doing cross-validation scoring for X26_mean...\n",
      "R^2 score for X26_mean: 0.4002268987398194\n",
      "Training model for X26_mean...\n",
      "\n",
      "Doing cross-validation scoring for X3112_mean...\n",
      "R^2 score for X3112_mean: 0.5746836570582942\n",
      "Training model for X3112_mean...\n"
     ]
    }
   ],
   "source": [
    "do_cv = True\n",
    "\n",
    "remove_cols = [ \n",
    " 'X4_sd',\n",
    " 'X11_sd',\n",
    " 'X18_sd',\n",
    " 'X26_sd',\n",
    " 'X50_sd',\n",
    " 'X3112_sd',\n",
    " 'file_path',\n",
    " 'jpeg_bytes'\n",
    "]\n",
    "\n",
    "X_full = train_df.drop(columns=CONFIG.TARGET_COLUMNS + remove_cols)\n",
    "Y_full = train_df[CONFIG.TARGET_COLUMNS]\n",
    "\n",
    "models = {}\n",
    "\n",
    "for column in Y_full.columns:\n",
    "\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=150, learning_rate=0.1, max_depth=10)\n",
    "\n",
    "    if do_cv:\n",
    "        print(f\"\\nDoing cross-validation scoring for {column}...\")\n",
    "        scores = cross_val_score(model, X_full, Y_full[column],\n",
    "                                 cv=KFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                                 scoring='r2')        \n",
    "        print(f\"R^2 score for {column}: {np.mean(scores)}\")\n",
    "    \n",
    "    #train model with all data\n",
    "    print(f\"Training model for {column}...\")\n",
    "    model.fit(X_full, Y_full[column])\n",
    "    models[column] = model\n",
    "    \n",
    "with open('all_models.pkl', 'wb') as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944696dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:46:42.109923Z",
     "iopub.status.busy": "2024-04-10T18:46:42.108824Z",
     "iopub.status.idle": "2024-04-10T18:46:42.391689Z",
     "shell.execute_reply": "2024-04-10T18:46:42.389932Z"
    },
    "papermill": {
     "duration": 0.303809,
     "end_time": "2024-04-10T18:46:42.396127",
     "exception": false,
     "start_time": "2024-04-10T18:46:42.092318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('all_models.pkl', 'rb') as file:\n",
    "    models = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83978a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:46:42.419103Z",
     "iopub.status.busy": "2024-04-10T18:46:42.418568Z",
     "iopub.status.idle": "2024-04-10T18:46:42.510379Z",
     "shell.execute_reply": "2024-04-10T18:46:42.508516Z"
    },
    "papermill": {
     "duration": 0.110815,
     "end_time": "2024-04-10T18:46:42.517123",
     "exception": false,
     "start_time": "2024-04-10T18:46:42.406308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3378947079.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  submission[Y_full.columns] = mean_values\n",
      "/tmp/ipykernel_18/3378947079.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  submission[Y_full.columns] = mean_values\n",
      "/tmp/ipykernel_18/3378947079.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  submission[Y_full.columns] = mean_values\n",
      "/tmp/ipykernel_18/3378947079.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  submission[Y_full.columns] = mean_values\n",
      "/tmp/ipykernel_18/3378947079.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  submission[Y_full.columns] = mean_values\n",
      "/tmp/ipykernel_18/3378947079.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  submission[Y_full.columns] = mean_values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X4</th>\n",
       "      <th>X11</th>\n",
       "      <th>X18</th>\n",
       "      <th>X50</th>\n",
       "      <th>X26</th>\n",
       "      <th>X3112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201238668</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202310319</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202604412</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201353439</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195351745</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>195548469</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>199261251</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>203031744</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>197736382</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>202625693</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>15.752458</td>\n",
       "      <td>2.772597</td>\n",
       "      <td>1.592122</td>\n",
       "      <td>24.176388</td>\n",
       "      <td>1598.76301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6545 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        X4        X11       X18       X50        X26  \\\n",
       "0     201238668  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "1     202310319  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "2     202604412  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "3     201353439  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "4     195351745  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "...         ...       ...        ...       ...       ...        ...   \n",
       "6540  195548469  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "6541  199261251  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "6542  203031744  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "6543  197736382  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "6544  202625693  0.516058  15.752458  2.772597  1.592122  24.176388   \n",
       "\n",
       "           X3112  \n",
       "0     1598.76301  \n",
       "1     1598.76301  \n",
       "2     1598.76301  \n",
       "3     1598.76301  \n",
       "4     1598.76301  \n",
       "...          ...  \n",
       "6540  1598.76301  \n",
       "6541  1598.76301  \n",
       "6542  1598.76301  \n",
       "6543  1598.76301  \n",
       "6544  1598.76301  \n",
       "\n",
       "[6545 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values = Y_full.mean()\n",
    "submission = pd.DataFrame({'id': test_df['id']})\n",
    "submission[Y_full.columns] = mean_values\n",
    "\n",
    "#rename from _mean\n",
    "submission.columns = submission.columns.str.replace('_mean', '')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc9edc4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:46:42.542124Z",
     "iopub.status.busy": "2024-04-10T18:46:42.541546Z",
     "iopub.status.idle": "2024-04-10T18:46:46.232288Z",
     "shell.execute_reply": "2024-04-10T18:46:46.230327Z"
    },
    "papermill": {
     "duration": 3.707431,
     "end_time": "2024-04-10T18:46:46.235994",
     "exception": false,
     "start_time": "2024-04-10T18:46:42.528563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X4</th>\n",
       "      <th>X11</th>\n",
       "      <th>X18</th>\n",
       "      <th>X50</th>\n",
       "      <th>X26</th>\n",
       "      <th>X3112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201238668</td>\n",
       "      <td>0.538798</td>\n",
       "      <td>8.555768</td>\n",
       "      <td>1.328512</td>\n",
       "      <td>1.642259</td>\n",
       "      <td>3.404278</td>\n",
       "      <td>328.345917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202310319</td>\n",
       "      <td>0.564764</td>\n",
       "      <td>17.404047</td>\n",
       "      <td>0.439812</td>\n",
       "      <td>1.076741</td>\n",
       "      <td>0.218322</td>\n",
       "      <td>902.472961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202604412</td>\n",
       "      <td>0.645296</td>\n",
       "      <td>13.065586</td>\n",
       "      <td>2.627984</td>\n",
       "      <td>1.639338</td>\n",
       "      <td>24.762333</td>\n",
       "      <td>952.253296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201353439</td>\n",
       "      <td>0.463182</td>\n",
       "      <td>18.467920</td>\n",
       "      <td>0.339206</td>\n",
       "      <td>1.146362</td>\n",
       "      <td>-0.152916</td>\n",
       "      <td>2018.330688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195351745</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>6.611946</td>\n",
       "      <td>0.225449</td>\n",
       "      <td>1.913098</td>\n",
       "      <td>0.248918</td>\n",
       "      <td>126.208115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>195548469</td>\n",
       "      <td>0.653133</td>\n",
       "      <td>10.960112</td>\n",
       "      <td>1.377365</td>\n",
       "      <td>1.830360</td>\n",
       "      <td>4.531377</td>\n",
       "      <td>429.424194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>199261251</td>\n",
       "      <td>0.555159</td>\n",
       "      <td>13.632323</td>\n",
       "      <td>6.907156</td>\n",
       "      <td>1.655766</td>\n",
       "      <td>33.499557</td>\n",
       "      <td>3574.922852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>203031744</td>\n",
       "      <td>0.454249</td>\n",
       "      <td>23.640532</td>\n",
       "      <td>0.420358</td>\n",
       "      <td>1.198588</td>\n",
       "      <td>19.354586</td>\n",
       "      <td>2728.925293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>197736382</td>\n",
       "      <td>0.450884</td>\n",
       "      <td>25.608112</td>\n",
       "      <td>0.152235</td>\n",
       "      <td>1.152176</td>\n",
       "      <td>1.292659</td>\n",
       "      <td>110.714981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>202625693</td>\n",
       "      <td>0.551598</td>\n",
       "      <td>14.639801</td>\n",
       "      <td>11.796988</td>\n",
       "      <td>1.469941</td>\n",
       "      <td>139.744919</td>\n",
       "      <td>5313.538086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6545 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        X4        X11        X18       X50         X26  \\\n",
       "0     201238668  0.538798   8.555768   1.328512  1.642259    3.404278   \n",
       "1     202310319  0.564764  17.404047   0.439812  1.076741    0.218322   \n",
       "2     202604412  0.645296  13.065586   2.627984  1.639338   24.762333   \n",
       "3     201353439  0.463182  18.467920   0.339206  1.146362   -0.152916   \n",
       "4     195351745  0.552239   6.611946   0.225449  1.913098    0.248918   \n",
       "...         ...       ...        ...        ...       ...         ...   \n",
       "6540  195548469  0.653133  10.960112   1.377365  1.830360    4.531377   \n",
       "6541  199261251  0.555159  13.632323   6.907156  1.655766   33.499557   \n",
       "6542  203031744  0.454249  23.640532   0.420358  1.198588   19.354586   \n",
       "6543  197736382  0.450884  25.608112   0.152235  1.152176    1.292659   \n",
       "6544  202625693  0.551598  14.639801  11.796988  1.469941  139.744919   \n",
       "\n",
       "            X3112  \n",
       "0      328.345917  \n",
       "1      902.472961  \n",
       "2      952.253296  \n",
       "3     2018.330688  \n",
       "4      126.208115  \n",
       "...           ...  \n",
       "6540   429.424194  \n",
       "6541  3574.922852  \n",
       "6542  2728.925293  \n",
       "6543   110.714981  \n",
       "6544  5313.538086  \n",
       "\n",
       "[6545 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_cols = [ \n",
    " 'file_path',\n",
    " 'jpeg_bytes'\n",
    "]\n",
    "\n",
    "X_test = test_df.drop(columns=remove_cols)\n",
    "\n",
    "submission['X4'] = models['X4_mean'].predict(X_test)\n",
    "submission['X11'] = models['X11_mean'].predict(X_test)\n",
    "submission['X18'] = models['X18_mean'].predict(X_test)\n",
    "submission['X50'] = models['X50_mean'].predict(X_test)\n",
    "submission['X26'] = models['X26_mean'].predict(X_test)\n",
    "submission['X3112'] = models['X3112_mean'].predict(X_test)\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8fa9f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:46:46.260810Z",
     "iopub.status.busy": "2024-04-10T18:46:46.260262Z",
     "iopub.status.idle": "2024-04-10T18:46:46.357993Z",
     "shell.execute_reply": "2024-04-10T18:46:46.356614Z"
    },
    "papermill": {
     "duration": 0.114279,
     "end_time": "2024-04-10T18:46:46.361604",
     "exception": false,
     "start_time": "2024-04-10T18:46:46.247325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd992520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:46:46.384942Z",
     "iopub.status.busy": "2024-04-10T18:46:46.384428Z",
     "iopub.status.idle": "2024-04-10T18:46:46.391581Z",
     "shell.execute_reply": "2024-04-10T18:46:46.389673Z"
    },
    "papermill": {
     "duration": 0.022552,
     "end_time": "2024-04-10T18:46:46.394731",
     "exception": false,
     "start_time": "2024-04-10T18:46:46.372179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SUBMISSION_ROWS = []\n",
    "# model.eval()\n",
    "\n",
    "# for X_sample_test, test_id in tqdm(test_dataset):\n",
    "#     with torch.no_grad():\n",
    "#         y_pred = model(X_sample_test.unsqueeze(0).to(device)).detach().cpu().numpy()\n",
    "    \n",
    "#     y_pred = SCALER.inverse_transform(y_pred).squeeze()\n",
    "#     row = {'id': test_id}\n",
    "    \n",
    "#     for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n",
    "#         if k in LOG_FEATURES:\n",
    "#             row[k.replace('_mean', '')] = 10 ** v\n",
    "#         else:\n",
    "#             row[k.replace('_mean', '')] = v\n",
    "\n",
    "#     SUBMISSION_ROWS.append(row)\n",
    "    \n",
    "# submission_df = pd.DataFrame(SUBMISSION_ROWS)\n",
    "# submission_df.to_csv('submission.csv', index=False)\n",
    "# print(\"Submit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798f38e",
   "metadata": {
    "papermill": {
     "duration": 0.011599,
     "end_time": "2024-04-10T18:46:46.417361",
     "exception": false,
     "start_time": "2024-04-10T18:46:46.405762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ba118",
   "metadata": {
    "papermill": {
     "duration": 0.015097,
     "end_time": "2024-04-10T18:46:46.446290",
     "exception": false,
     "start_time": "2024-04-10T18:46:46.431193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8046133,
     "sourceId": 65626,
     "sourceType": "competition"
    },
    {
     "datasetId": 4761376,
     "sourceId": 8069756,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4769096,
     "sourceId": 8080312,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23093.178375,
   "end_time": "2024-04-10T18:46:49.494936",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-10T12:21:56.316561",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
