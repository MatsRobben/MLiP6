{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff839fc",
   "metadata": {
    "papermill": {
     "duration": 0.00501,
     "end_time": "2024-04-18T16:25:59.294099",
     "exception": false,
     "start_time": "2024-04-18T16:25:59.289089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Notebook modified from https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub.\n",
    "- Training only, EDA part not included.\n",
    "- Image model only, tabular data not used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ae401",
   "metadata": {
    "papermill": {
     "duration": 0.004258,
     "end_time": "2024-04-18T16:25:59.303196",
     "exception": false,
     "start_time": "2024-04-18T16:25:59.298938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e628f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:25:59.313639Z",
     "iopub.status.busy": "2024-04-18T16:25:59.313179Z",
     "iopub.status.idle": "2024-04-18T16:26:11.495547Z",
     "shell.execute_reply": "2024-04-18T16:26:11.494763Z"
    },
    "papermill": {
     "duration": 12.190287,
     "end_time": "2024-04-18T16:26:11.497951",
     "exception": false,
     "start_time": "2024-04-18T16:25:59.307664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as imageio\n",
    "import albumentations as A\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import glob\n",
    "import torchmetrics\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "tqdm.pandas()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8a2cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:26:11.507990Z",
     "iopub.status.busy": "2024-04-18T16:26:11.507689Z",
     "iopub.status.idle": "2024-04-18T16:26:11.513358Z",
     "shell.execute_reply": "2024-04-18T16:26:11.512509Z"
    },
    "papermill": {
     "duration": 0.012885,
     "end_time": "2024-04-18T16:26:11.515429",
     "exception": false,
     "start_time": "2024-04-18T16:26:11.502544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    IMAGE_SIZE = 384\n",
    "    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n",
    "#     BACKBONE = 'tf_efficientnet_b0'\n",
    "    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "    \n",
    "    N_TARGETS = len(TARGET_COLUMNS)\n",
    "    BATCH_SIZE = 10\n",
    "    LR_MAX = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    N_EPOCHS = 7\n",
    "    TRAIN_MODEL = True\n",
    "    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "    \n",
    "#     MODEL_PATH = '/kaggle/input/plainttraits2024-swintransformer/model.pth'\n",
    "    MODEL_PATH = '/kaggle/input/planttraits2024-swintransformer-tabular/model.pth'\n",
    "        \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ec3c5",
   "metadata": {
    "papermill": {
     "duration": 0.003996,
     "end_time": "2024-04-18T16:26:11.523713",
     "exception": false,
     "start_time": "2024-04-18T16:26:11.519717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879ad49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:26:11.533216Z",
     "iopub.status.busy": "2024-04-18T16:26:11.532944Z",
     "iopub.status.idle": "2024-04-18T16:26:49.915360Z",
     "shell.execute_reply": "2024-04-18T16:26:49.914420Z"
    },
    "papermill": {
     "duration": 38.393389,
     "end_time": "2024-04-18T16:26:49.921262",
     "exception": false,
     "start_time": "2024-04-18T16:26:11.527873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_TRAIN_SAMPLES: 49168 N_TEST_SAMPLES: 6545\n",
      "CPU times: user 1.78 s, sys: 2.89 s, total: 4.67 s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read_images = False\n",
    "\n",
    "if not read_images:\n",
    "    train = pd.read_pickle('/kaggle/input/plainttraits2024-swintransformer/train.pkl')\n",
    "    test = pd.read_pickle('/kaggle/input/plainttraits2024-swintransformer/test.pkl')\n",
    "else: \n",
    "    # if CONFIG.TRAIN_MODEL:\n",
    "    train = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\n",
    "    train['file_path'] = train['id'].apply(lambda s: f'/kaggle/input/planttraits2024/train_images/{s}.jpeg')\n",
    "    train['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n",
    "    train.to_pickle('train.pkl')\n",
    "\n",
    "    test = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n",
    "    test['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/planttraits2024/test_images/{s}.jpeg')\n",
    "    test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n",
    "    test.to_pickle('test.pkl')\n",
    "\n",
    "for column in CONFIG.TARGET_COLUMNS:\n",
    "    lower_quantile = train[column].quantile(0.005)\n",
    "    upper_quantile = train[column].quantile(0.985)  \n",
    "    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]    \n",
    "    \n",
    "sd_columns = [col for col in train.columns if col.endswith('_sd')]\n",
    "train = train.drop(columns=sd_columns)\n",
    "    \n",
    "CONFIG.N_TRAIN_SAMPLES = len(train)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1    \n",
    "CONFIG.TABULAR_COLUMNS = train.filter(regex='^(WORLDCLIM_BIO|SOIL|MODIS_2000|VOD)').columns\n",
    "    \n",
    "if CONFIG.TRAIN_MODEL:\n",
    "    print('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))\n",
    "else:\n",
    "    print('N_TEST_SAMPLES:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcba73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:26:49.931447Z",
     "iopub.status.busy": "2024-04-18T16:26:49.931151Z",
     "iopub.status.idle": "2024-04-18T16:26:49.953435Z",
     "shell.execute_reply": "2024-04-18T16:26:49.952559Z"
    },
    "papermill": {
     "duration": 0.029618,
     "end_time": "2024-04-18T16:26:49.955407",
     "exception": false,
     "start_time": "2024-04-18T16:26:49.925789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if CONFIG.TRAIN_MODEL:\n",
    "LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "\n",
    "y_df = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n",
    "for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "    v = train[target].values\n",
    "    if target in LOG_FEATURES:\n",
    "        v = np.log10(v)\n",
    "    y_df[:, target_idx] = v\n",
    "\n",
    "SCALER = StandardScaler()\n",
    "y_df = SCALER.fit_transform(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267dd289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:26:49.965122Z",
     "iopub.status.busy": "2024-04-18T16:26:49.964844Z",
     "iopub.status.idle": "2024-04-18T16:26:50.161568Z",
     "shell.execute_reply": "2024-04-18T16:26:50.160555Z"
    },
    "papermill": {
     "duration": 0.20413,
     "end_time": "2024-04-18T16:26:50.163904",
     "exception": false,
     "start_time": "2024-04-18T16:26:49.959774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCALER_tabular = StandardScaler()\n",
    "tabular_train = SCALER_tabular.fit_transform(train[CONFIG.TABULAR_COLUMNS])\n",
    "tabular_test = SCALER_tabular.fit_transform(test[CONFIG.TABULAR_COLUMNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a429cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:26:50.174583Z",
     "iopub.status.busy": "2024-04-18T16:26:50.174248Z",
     "iopub.status.idle": "2024-04-18T16:26:50.190430Z",
     "shell.execute_reply": "2024-04-18T16:26:50.189449Z"
    },
    "papermill": {
     "duration": 0.023735,
     "end_time": "2024-04-18T16:26:50.192457",
     "exception": false,
     "start_time": "2024-04-18T16:26:50.168722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomSizedCrop(\n",
    "            [int(0.85*CONFIG.IMAGE_SIZE), CONFIG.IMAGE_SIZE],\n",
    "            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n",
    "        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "TEST_TRANSFORMS = A.Compose([\n",
    "        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, X_tabular, y, transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.X_tabular = X_tabular\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_jpeg_bytes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_sample = self.transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )\n",
    "        X_sample['tabular'] = self.X_tabular[index].astype('float32')\n",
    "        y_sample = self.y[index]\n",
    "        \n",
    "        return X_sample, y_sample\n",
    "\n",
    "if CONFIG.TRAIN_MODEL:\n",
    "    # Creating datasets for training and validation\n",
    "    train_dataset = Dataset(\n",
    "        train['jpeg_bytes'].values,\n",
    "        tabular_train,\n",
    "        y_df,\n",
    "        TRAIN_TRANSFORMS,\n",
    "    )\n",
    "\n",
    "    # Creating dataloaders for training and validation\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=psutil.cpu_count(),\n",
    "    )\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    test['jpeg_bytes'].values,\n",
    "    tabular_test,\n",
    "    test['id'].values,\n",
    "    TEST_TRANSFORMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b241381a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:26:50.202891Z",
     "iopub.status.busy": "2024-04-18T16:26:50.202543Z",
     "iopub.status.idle": "2024-04-18T16:27:06.114624Z",
     "shell.execute_reply": "2024-04-18T16:27:06.113665Z"
    },
    "papermill": {
     "duration": 15.919784,
     "end_time": "2024-04-18T16:27:06.116943",
     "exception": false,
     "start_time": "2024-04-18T16:26:50.197159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dbee921214468ab6cc5e1321a65bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/801M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "                CONFIG.BACKBONE,\n",
    "                pretrained=True,\n",
    "                num_classes=0,\n",
    "        )\n",
    "        \n",
    "        # EfficientNet = 1280, SwinTrans = 1536, Tabular = 163\n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.Linear(1536+163, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 6)  \n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        image = inputs['image']\n",
    "        tabular = inputs['tabular']\n",
    "\n",
    "        x = self.backbone(image)\n",
    "        x = torch.cat((tabular, x), dim=1)\n",
    "        x = self.custom_layers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "# print(model.backbone.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50b65fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:27:06.127578Z",
     "iopub.status.busy": "2024-04-18T16:27:06.127284Z",
     "iopub.status.idle": "2024-04-18T16:27:06.147023Z",
     "shell.execute_reply": "2024-04-18T16:27:06.146182Z"
    },
    "papermill": {
     "duration": 0.028444,
     "end_time": "2024-04-18T16:27:06.150192",
     "exception": false,
     "start_time": "2024-04-18T16:27:06.121748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=CONFIG.LR_MAX,\n",
    "        total_steps=CONFIG.N_STEPS,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=1e1,\n",
    "        final_div_factor=1e1,\n",
    "    )\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "if CONFIG.TRAIN_MODEL:\n",
    "    MAE = torchmetrics.regression.MeanAbsoluteError().to(device)\n",
    "    R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to(device)\n",
    "    LOSS = AverageMeter()\n",
    "\n",
    "    Y_MEAN = torch.tensor(y_df).mean(dim=0).to(device)\n",
    "    EPS = torch.tensor([1e-6]).to(device)\n",
    "\n",
    "    def r2_loss(y_pred, y_true):\n",
    "        ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n",
    "        ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n",
    "        ss_total = torch.maximum(ss_total, EPS)\n",
    "        r2 = torch.mean(ss_res / ss_total)\n",
    "        return r2\n",
    "\n",
    "    LOSS_FN = nn.SmoothL1Loss() #r2_loss\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params=model.parameters(),\n",
    "        lr=CONFIG.LR_MAX,\n",
    "        weight_decay=CONFIG.WEIGHT_DECAY,\n",
    "    )\n",
    "\n",
    "    LR_SCHEDULER = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63c0e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T16:27:06.161396Z",
     "iopub.status.busy": "2024-04-18T16:27:06.161116Z",
     "iopub.status.idle": "2024-04-19T04:21:00.502197Z",
     "shell.execute_reply": "2024-04-19T04:21:00.501204Z"
    },
    "papermill": {
     "duration": 42834.349386,
     "end_time": "2024-04-19T04:21:00.505022",
     "exception": false,
     "start_time": "2024-04-18T16:27:06.155636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 01, 4916/4916 | loss: 0.2618, mae: 0.5850, r2: 0.4163, step: 1.352s, lr: 9.94e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 02, 4916/4916 | loss: 0.2301, mae: 0.5388, r2: 0.4907, step: 1.240s, lr: 9.00e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 03, 4916/4916 | loss: 0.1961, mae: 0.4886, r2: 0.5716, step: 1.237s, lr: 7.09e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 04, 4916/4916 | loss: 0.1579, mae: 0.4302, r2: 0.6606, step: 1.239s, lr: 4.68e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 05, 4916/4916 | loss: 0.1207, mae: 0.3694, r2: 0.7449, step: 1.237s, lr: 2.36e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 06, 4916/4916 | loss: 0.0907, mae: 0.3165, r2: 0.8110, step: 1.235s, lr: 7.03e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 07, 4916/4916 | loss: 0.0754, mae: 0.2868, r2: 0.8441, step: 1.240s, lr: 1.00e-06\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.TRAIN_MODEL:\n",
    "    print(\"Start Training:\")\n",
    "    \n",
    "    best = float('inf')\n",
    "    for epoch in range(CONFIG.N_EPOCHS):\n",
    "        MAE.reset()\n",
    "        R2.reset()\n",
    "        LOSS.reset()\n",
    "        model.train()\n",
    "\n",
    "        for step, (X_batch, y_true) in enumerate(train_dataloader):\n",
    "            X_batch['image'] = X_batch['image'].to(device)\n",
    "            X_batch['tabular'] = X_batch['tabular'].to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            t_start = time.perf_counter_ns()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = LOSS_FN(y_pred, y_true)\n",
    "            LOSS.update(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            LR_SCHEDULER.step()\n",
    "            MAE.update(y_pred, y_true)\n",
    "            R2.update(y_pred, y_true)\n",
    "\n",
    "            if not CONFIG.IS_INTERACTIVE and (step+1) == len(train_dataloader):\n",
    "                print(\n",
    "                    f'EPOCH {epoch+1:02d}, {step+1:04d}/{len(train_dataloader)} | ' + \n",
    "                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "                )\n",
    "            elif CONFIG.IS_INTERACTIVE:\n",
    "                print(\n",
    "                    f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{len(train_dataloader)} | ' + \n",
    "                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "                    end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n",
    "                )\n",
    "            \n",
    "    torch.save(model, 'model.pth')    \n",
    "else:\n",
    "    model = torch.load(CONFIG.MODEL_PATH)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90edefbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T04:21:00.519033Z",
     "iopub.status.busy": "2024-04-19T04:21:00.518712Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-04-19T04:21:00.511393",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b4fb67f8674a23a06c25ae7d35940b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SUBMISSION_ROWS = []\n",
    "model.eval()\n",
    "\n",
    "for X_sample_test, test_id in tqdm(test_dataset):\n",
    "    X_sample_test['image'] = torch.Tensor(X_sample_test['image']).unsqueeze(0).to(device)\n",
    "    X_sample_test['tabular'] = torch.Tensor(X_sample_test['tabular']).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_sample_test).detach().cpu().numpy()\n",
    "    \n",
    "    y_pred = SCALER.inverse_transform(y_pred).squeeze()\n",
    "    row = {'id': test_id}\n",
    "    \n",
    "    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n",
    "        if k in LOG_FEATURES:\n",
    "            row[k.replace('_mean', '')] = 10 ** v\n",
    "        else:\n",
    "            row[k.replace('_mean', '')] = v\n",
    "\n",
    "    SUBMISSION_ROWS.append(row)\n",
    "    \n",
    "submission_df = pd.DataFrame(SUBMISSION_ROWS)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submit!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8046133,
     "sourceId": 65626,
     "sourceType": "competition"
    },
    {
     "datasetId": 4761376,
     "sourceId": 8069756,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4769096,
     "sourceId": 8080312,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4794400,
     "sourceId": 8115215,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-18T16:25:56.539746",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}