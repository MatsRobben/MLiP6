{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67742b14",
   "metadata": {
    "papermill": {
     "duration": 0.013444,
     "end_time": "2024-03-13T14:29:57.269704",
     "exception": false,
     "start_time": "2024-03-13T14:29:57.256260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a233084",
   "metadata": {
    "papermill": {
     "duration": 0.012932,
     "end_time": "2024-03-13T14:29:57.295883",
     "exception": false,
     "start_time": "2024-03-13T14:29:57.282951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook\n",
    "\n",
    "The goal of this notebook is to improve the results of the [notebook](https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43#Train-DataLoader) shared by @cdeotte and [@alejopaullier](https://www.kaggle.com/code/alejopaullier/hms-efficientnetb0-pytorch-train), please check them out great notebooks.\n",
    "\n",
    "\n",
    "**Important note**:\n",
    "\n",
    "I shared in the last days a [discussion](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/478474) which was an Improvement of this [notebook](https://www.kaggle.com/code/nischaydnk/hms-submission-1d-eegnet-pipeline-lightning) created by @nischaydnk. The tricks I used were notably changing the optimizer (I used Adan) and I used the two stage training as stated by @seanbearden [here](https://www.kaggle.com/code/seanbearden/effnetb0-2-pop-model-train-twice-lb-0-39) and not using downsampling which worked pretty well.\n",
    "But the two stage training an issue which is data leakage. The idea was to seperate the data with few votes because the kl will hardly penalize the model if it mislabel them. So in my previous experiments I use two groupkfold CV on the two datasets and the samples with few votes are present in both datasets.\n",
    "\n",
    "So in this notebook, I use one CV scheme and in each stage I filter the data then validate on the data that contains both population to prevent data leakage. Let me know in the comment if this approach is correct more info can be found [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477461).\n",
    "\n",
    "As stated [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477498), adding 0.166666667 to the targets will reduce the CV/LB gap.\n",
    "\n",
    "**Consider upvoting this notebook if you find it useful**\n",
    "\n",
    "## Version 1\n",
    "* I train a tf_efficientnet_b0_ns model.\n",
    "\n",
    "### Hyperparams\n",
    "\n",
    "```\n",
    "scheduler='OneCycleLR' \n",
    " # OneCycleLR params\n",
    "  cosanneal_res_params={\n",
    "      'T_0':20,\n",
    "      'eta_min':1e-6,\n",
    "      'T_mult':1,\n",
    "      'last_epoch':-1}\n",
    "  print_freq=50\n",
    "  num_workers = 1\n",
    "  model_name = 'tf_efficientnet_b0_ns'\n",
    "  optimizer='Adam'\n",
    "  stage1_epochs = 5\n",
    "  stage1_epochs = 6\n",
    "  eps = 1e-6\n",
    "  lr = 1e-3\n",
    "  batch_size = 64\n",
    "  weight_decay = 1e-2\n",
    "  seed = 2024\n",
    "```\n",
    "\n",
    "## Version2\n",
    "\n",
    "* I changed the CV sheme, first stage train on all data second stage train on data with `total_evaluators >= 10`\n",
    "* Added Time masking augmentation from [here](https://www.kaggle.com/code/iglovikov/xymasking-aug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727dc3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:29:57.324817Z",
     "iopub.status.busy": "2024-03-13T14:29:57.324458Z",
     "iopub.status.idle": "2024-03-13T14:30:17.110335Z",
     "shell.execute_reply": "2024-03-13T14:30:17.109262Z"
    },
    "papermill": {
     "duration": 19.803292,
     "end_time": "2024-03-13T14:30:17.112835",
     "exception": false,
     "start_time": "2024-03-13T14:29:57.309543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.3.1)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-1.4.1-py3-none-any.whl.metadata (36 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.24.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.22.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.9.0)\r\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\r\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.9.0.80)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.2.1)\r\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (9.5.0)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2023.12.9)\r\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\r\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.2->albumentations) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.2->albumentations) (3.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.1.1)\r\n",
      "Downloading albumentations-1.4.1-py3-none-any.whl (130 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, albumentations\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.3.1\r\n",
      "    Uninstalling albumentations-1.3.1:\r\n",
      "      Successfully uninstalled albumentations-1.3.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed albumentations-1.4.1 scikit-learn-1.4.1.post1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc2b2c8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:17.145684Z",
     "iopub.status.busy": "2024-03-13T14:30:17.145338Z",
     "iopub.status.idle": "2024-03-13T14:30:17.152950Z",
     "shell.execute_reply": "2024-03-13T14:30:17.152086Z"
    },
    "papermill": {
     "duration": 0.02714,
     "end_time": "2024-03-13T14:30:17.155054",
     "exception": false,
     "start_time": "2024-03-13T14:30:17.127914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# directory settings\n",
    "# ====================================================\n",
    "\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "POP_2_DIR = OUTPUT_DIR + 'pop_2_weight_oof/'\n",
    "if not os.path.exists(POP_2_DIR):\n",
    "    os.makedirs(POP_2_DIR)\n",
    "    \n",
    "POP_1_DIR = OUTPUT_DIR + 'pop_1_weight_oof/'\n",
    "if not os.path.exists(POP_1_DIR):\n",
    "    os.makedirs(POP_1_DIR)\n",
    "    \n",
    "PSUEDO_DIR = OUTPUT_DIR + 'psuedo_labels_weights/'\n",
    "if not os.path.exists(PSUEDO_DIR):\n",
    "    os.makedirs(PSUEDO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e1ca4",
   "metadata": {
    "papermill": {
     "duration": 0.015163,
     "end_time": "2024-03-13T14:30:17.185144",
     "exception": false,
     "start_time": "2024-03-13T14:30:17.169981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa480d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:17.218486Z",
     "iopub.status.busy": "2024-03-13T14:30:17.218098Z",
     "iopub.status.idle": "2024-03-13T14:30:31.034969Z",
     "shell.execute_reply": "2024-03-13T14:30:31.033301Z"
    },
    "papermill": {
     "duration": 13.837287,
     "end_time": "2024-03-13T14:30:31.038169",
     "exception": false,
     "start_time": "2024-03-13T14:30:17.200882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
    "from kaggle_kl_div import score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as lg\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations import (Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "import timm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "VERSION=2\n",
    "\n",
    "# We added the pre-calculated mean and std\n",
    "MEAN = torch.load('/kaggle/input/mean-and-std-spectrograms/mean.pt').numpy()\n",
    "STD = torch.load('/kaggle/input/mean-and-std-spectrograms/std_dev.pt').numpy()\n",
    "\n",
    "# We added the pre-calculated pseudo labels\n",
    "efficentnet_model_psuedo_weights = [x for x in glob(\"/kaggle/input/mixmodel-weights/psuedo_labels_weights/*.pth\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797caf7",
   "metadata": {
    "papermill": {
     "duration": 0.01591,
     "end_time": "2024-03-13T14:30:31.069552",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.053642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0bbab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:31.102423Z",
     "iopub.status.busy": "2024-03-13T14:30:31.102044Z",
     "iopub.status.idle": "2024-03-13T14:30:31.113208Z",
     "shell.execute_reply": "2024-03-13T14:30:31.112139Z"
    },
    "papermill": {
     "duration": 0.030022,
     "end_time": "2024-03-13T14:30:31.115506",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.085484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "\n",
    "class CFG:\n",
    "    wandb = False\n",
    "    debug = False\n",
    "    train=True\n",
    "    apex=True\n",
    "    stage1_pop1=True\n",
    "    stage2_pop2=False\n",
    "    VISUALIZE=True\n",
    "    FREEZE=False\n",
    "    SparK=False\n",
    "    scheduler='OneCycleLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n",
    "    # CosineAnnealingLR params\n",
    "    cosanneal_params={\n",
    "        'T_max':6,\n",
    "        'eta_min':1e-5,\n",
    "        'last_epoch':-1\n",
    "    }\n",
    "    #ReduceLROnPlateau params\n",
    "    reduce_params={\n",
    "        'mode':'min',\n",
    "        'factor':0.2,\n",
    "        'patience':4,\n",
    "        'eps':1e-6,\n",
    "        'verbose':True\n",
    "    }\n",
    "    # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1\n",
    "    }\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'tf_efficientnet_b0_ns'\n",
    "    optimizer='Adan'\n",
    "    epochs = 5\n",
    "    factor = 0.9\n",
    "    patience = 2\n",
    "    eps = 1e-6\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 64\n",
    "    weight_decay = 1e-2\n",
    "    batch_scheduler=True\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1e7\n",
    "    seed = 2024\n",
    "    target_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    target_size = 6\n",
    "    num_channels = 8\n",
    "    pred_cols = ['pred_seizure_vote', 'pred_lpd_vote', 'pred_gpd_vote', 'pred_lrda_vote', 'pred_grda_vote', 'pred_other_vote']\n",
    "    n_fold = 5\n",
    "    trn_fold = [0, 1, 2, 3, 4]\n",
    "    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n",
    "    data_root = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n",
    "    raw_eeg_path = \"/kaggle/input/brain-eegs/eegs.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c99439",
   "metadata": {
    "papermill": {
     "duration": 0.0151,
     "end_time": "2024-03-13T14:30:31.145346",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.130246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9105d41c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:31.177306Z",
     "iopub.status.busy": "2024-03-13T14:30:31.176656Z",
     "iopub.status.idle": "2024-03-13T14:30:31.197032Z",
     "shell.execute_reply": "2024-03-13T14:30:31.196215Z"
    },
    "papermill": {
     "duration": 0.03877,
     "end_time": "2024-03-13T14:30:31.199078",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.160308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def get_score(preds, targets):\n",
    "    oof = pd.DataFrame(preds.copy())\n",
    "    oof['id'] = np.arange(len(oof))\n",
    "\n",
    "    true = pd.DataFrame(targets.copy())\n",
    "    true['id'] = np.arange(len(true))\n",
    "\n",
    "    cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
    "    return cv\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Sample rate and desired cutoff frequencies (in Hz).\n",
    "    fs = 200.0\n",
    "    lowcut = 1.0\n",
    "    highcut = 25.0\n",
    "    \n",
    "    # Filter a noisy signal.\n",
    "    T = 50\n",
    "    nsamples = T * fs\n",
    "    t = np.arange(0, nsamples) / fs\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n",
    "    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n",
    "    y = y[0:-1:4]\n",
    "    \n",
    "    return y\n",
    "\n",
    "class KLDivLossWithLogits(nn.KLDivLoss):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        y = nn.functional.log_softmax(y,  dim=1)\n",
    "        loss = super().forward(y, t)\n",
    "\n",
    "        return loss\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e58d5",
   "metadata": {
    "papermill": {
     "duration": 0.014078,
     "end_time": "2024-03-13T14:30:31.228045",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.213967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0b8fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:31.258408Z",
     "iopub.status.busy": "2024-03-13T14:30:31.258084Z",
     "iopub.status.idle": "2024-03-13T14:30:31.563775Z",
     "shell.execute_reply": "2024-03-13T14:30:31.562685Z"
    },
    "papermill": {
     "duration": 0.32387,
     "end_time": "2024-03-13T14:30:31.566180",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.242310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (106800, 15)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "There are 1950 patients in the training data.\n",
      "There are 17089 EEG IDs in the training data.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
    "TARGETS = train.columns[-6:]\n",
    "print('Train shape:', train.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "train['total_evaluators'] = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n",
    "\n",
    "print(f'There are {train.patient_id.nunique()} patients in the training data.')\n",
    "print(f'There are {train.eeg_id.nunique()} EEG IDs in the training data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d37743c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:31.599692Z",
     "iopub.status.busy": "2024-03-13T14:30:31.598890Z",
     "iopub.status.idle": "2024-03-13T14:30:31.887570Z",
     "shell.execute_reply": "2024-03-13T14:30:31.886686Z"
    },
    "papermill": {
     "duration": 0.308103,
     "end_time": "2024-03-13T14:30:31.889957",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.581854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d606a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:30:31.922483Z",
     "iopub.status.busy": "2024-03-13T14:30:31.921650Z",
     "iopub.status.idle": "2024-03-13T14:31:31.106868Z",
     "shell.execute_reply": "2024-03-13T14:31:31.105712Z"
    },
    "papermill": {
     "duration": 59.219489,
     "end_time": "2024-03-13T14:31:31.124740",
     "exception": false,
     "start_time": "2024-03-13T14:30:31.905251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.39 s, sys: 6.64 s, total: 10 s\n",
      "Wall time: 59.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944cd6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:31:31.158334Z",
     "iopub.status.busy": "2024-03-13T14:31:31.157847Z",
     "iopub.status.idle": "2024-03-13T14:32:58.143332Z",
     "shell.execute_reply": "2024-03-13T14:32:58.142306Z"
    },
    "papermill": {
     "duration": 87.021956,
     "end_time": "2024-03-13T14:32:58.162882",
     "exception": false,
     "start_time": "2024-03-13T14:31:31.140926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.33 s, sys: 10.9 s, total: 17.3 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_eegs = np.load('/kaggle/input/eeg-spectrogram-by-lead-id-unique/eeg_specs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c51d1b",
   "metadata": {
    "papermill": {
     "duration": 0.015658,
     "end_time": "2024-03-13T14:32:58.278662",
     "exception": false,
     "start_time": "2024-03-13T14:32:58.263004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deduplicate Train EEG Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3bfa02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:58.311022Z",
     "iopub.status.busy": "2024-03-13T14:32:58.310633Z",
     "iopub.status.idle": "2024-03-13T14:32:58.871356Z",
     "shell.execute_reply": "2024-03-13T14:32:58.870336Z"
    },
    "papermill": {
     "duration": 0.579701,
     "end_time": "2024-03-13T14:32:58.873764",
     "exception": false,
     "start_time": "2024-03-13T14:32:58.294063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train[train['label_id'].isin(all_eegs.keys())].copy()\n",
    "\n",
    "# Implentation for pseudo labels\n",
    "mask = train['total_evaluators'] < 10\n",
    "\n",
    "pseudo_labels = np.load('/kaggle/input/mixmodel-weights/pseudo_labels.npy')\n",
    "pseudo_labels = F.softmax(torch.tensor(pseudo_labels), dim=1).numpy()\n",
    "\n",
    "y_data = train[TARGETS].values + np.multiply(np.expand_dims(mask, axis=1), pseudo_labels)\n",
    "\n",
    "# y_data = train[TARGETS].values +  0.166666667 # Regularization value # We removed this from the code, as it did not improve the LB scores and used pseudo labels instead.\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "train['target'] = train['expert_consensus']\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "del y_data\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72603f1d",
   "metadata": {
    "papermill": {
     "duration": 0.016178,
     "end_time": "2024-03-13T14:32:58.906412",
     "exception": false,
     "start_time": "2024-03-13T14:32:58.890234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d08243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:58.940792Z",
     "iopub.status.busy": "2024-03-13T14:32:58.940161Z",
     "iopub.status.idle": "2024-03-13T14:32:59.199994Z",
     "shell.execute_reply": "2024-03-13T14:32:59.198879Z"
    },
    "papermill": {
     "duration": 0.280182,
     "end_time": "2024-03-13T14:32:59.202642",
     "exception": false,
     "start_time": "2024-03-13T14:32:58.922460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_fold)\n",
    "\n",
    "train[\"fold\"] = -1\n",
    "\n",
    "for fold_id, (_, val_idx) in enumerate(\n",
    "    gkf.split(train, y=train[\"target\"], groups=train[\"patient_id\"])\n",
    "):\n",
    "    train.loc[val_idx, \"fold\"] = fold_id\n",
    "    \n",
    "del gkf\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c33103",
   "metadata": {
    "papermill": {
     "duration": 0.015856,
     "end_time": "2024-03-13T14:32:59.288410",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.272554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a24dc652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.322297Z",
     "iopub.status.busy": "2024-03-13T14:32:59.321580Z",
     "iopub.status.idle": "2024-03-13T14:32:59.341935Z",
     "shell.execute_reply": "2024-03-13T14:32:59.340910Z"
    },
    "papermill": {
     "duration": 0.04007,
     "end_time": "2024-03-13T14:32:59.344096",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.304026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame,\n",
    "        augment: bool = False, mode: str = 'train',\n",
    "        specs: Dict[int, np.ndarray] = spectrograms,\n",
    "        eeg_specs: Dict[int, np.ndarray] = all_eegs\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.spectograms = spectrograms\n",
    "        self.eeg_spectograms = eeg_specs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        X, y = self.__data_generation(index)\n",
    "        if self.augment:\n",
    "            X = self.__transform(X) \n",
    "        return {\"spectrogram\":torch.tensor(X, dtype=torch.float32), \"labels\":torch.tensor(y, dtype=torch.float32)}\n",
    "                        \n",
    "    def __data_generation(self, index):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples.\n",
    "        \"\"\"\n",
    "        X = np.zeros((128, 256, 8), dtype='float32')\n",
    "        y = np.zeros(6, dtype='float32')\n",
    "        img = np.ones((128,256), dtype='float32')\n",
    "        row = self.df.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            r = 0\n",
    "        else: \n",
    "            r = int(row['spectrogram_label_offset_seconds'] // 2)\n",
    "            \n",
    "        for region in range(4):\n",
    "            img = self.spectograms[row.spectrogram_id][r:r+300, region*100:(region+1)*100].T\n",
    "            \n",
    "            # Log transform spectogram\n",
    "            img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "            img = np.log(img)\n",
    "\n",
    "            # Remove local normalization\n",
    "#             # Standarize per image\n",
    "#             ep = 1e-6\n",
    "#             mu = np.nanmean(img.flatten())\n",
    "#             std = np.nanstd(img.flatten())\n",
    "#             img = (img-mu)/(std+ep)\n",
    "\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n",
    "            img = self.eeg_spectograms[row.label_id]\n",
    "            X[:, :, 4:] = img\n",
    "            \n",
    "        if self.mode != 'test':\n",
    "            y = row[TARGETS].values.astype(np.float32)\n",
    "        \n",
    "        # Added global normalization\n",
    "        ep = 1e-6\n",
    "        X = (X - MEAN) / (STD+ep)\n",
    "        X = np.nan_to_num(X, nan=0.0)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __transform(self, img):\n",
    "        params1 = {\n",
    "                    \"num_masks_x\": 1,    \n",
    "                    \"mask_x_length\": (0, 20), # This line changed from fixed  to a range\n",
    "                    \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),\n",
    "                    }\n",
    "        params2 = {    \n",
    "                    \"num_masks_y\": 1,    \n",
    "                    \"mask_y_length\": (0, 20),\n",
    "                    \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),    \n",
    "                    }\n",
    "        params3 = {    \n",
    "                    \"num_masks_x\": (2, 4),\n",
    "                    \"num_masks_y\": 5,    \n",
    "                    \"mask_y_length\": 8,\n",
    "                    \"mask_x_length\": (10, 20),\n",
    "                    \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),  \n",
    "                    }\n",
    "        \n",
    "        transforms = A.Compose([\n",
    "            A.XYMasking(**params1, p=0.3),\n",
    "            A.XYMasking(**params2, p=0.3),\n",
    "            A.XYMasking(**params3, p=0.3),\n",
    "        ])\n",
    "        return transforms(image=img)['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f2feb",
   "metadata": {
    "papermill": {
     "duration": 0.016952,
     "end_time": "2024-03-13T14:32:59.378379",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.361427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed28a8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.412066Z",
     "iopub.status.busy": "2024-03-13T14:32:59.411684Z",
     "iopub.status.idle": "2024-03-13T14:32:59.416235Z",
     "shell.execute_reply": "2024-03-13T14:32:59.415276Z"
    },
    "papermill": {
     "duration": 0.023818,
     "end_time": "2024-03-13T14:32:59.418355",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.394537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = CustomDataset(train, augment=True, mode=\"train\")\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# batch = dataset[4]\n",
    "# X, y = batch[\"spectrogram\"], batch[\"labels\"]\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# plt.imshow(X[:,:,0])\n",
    "\n",
    "# del dataset, X, y\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69628a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.451505Z",
     "iopub.status.busy": "2024-03-13T14:32:59.450949Z",
     "iopub.status.idle": "2024-03-13T14:32:59.455883Z",
     "shell.execute_reply": "2024-03-13T14:32:59.455006Z"
    },
    "papermill": {
     "duration": 0.023417,
     "end_time": "2024-03-13T14:32:59.457827",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.434410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation of global mean and std\n",
    "\n",
    "# dataset = CustomDataset(train, augment=False, mode=\"test\")\n",
    "# dataloader = DataLoader(dataset, batch_size=128, shuffle=False, drop_last=False)\n",
    "\n",
    "# batch = dataset[0]\n",
    "# X, y = batch[\"spectrogram\"], batch[\"labels\"]\n",
    "\n",
    "# total_sum_mean = torch.zeros(X.shape)\n",
    "# total_samples_mean = 0\n",
    "\n",
    "# total_sum_var = torch.zeros(X.shape)\n",
    "# total_samples_var = 0\n",
    "\n",
    "# for i, batch in enumerate(dataloader):\n",
    "#     if i%10==0: print(i, end=\", \")\n",
    "#     X = batch[\"spectrogram\"]\n",
    "    \n",
    "#     total_sum_mean += torch.sum(X, dim=0)\n",
    "#     total_samples_mean += X.size(0)\n",
    "\n",
    "# # Compute mean\n",
    "# mean = total_sum_mean / total_samples_mean\n",
    "# torch.save(mean, 'mean.pt')\n",
    "\n",
    "# for i, batch in enumerate(dataloader):\n",
    "#     if i%10==0: print(i, end=\", \")\n",
    "#     X = batch[\"spectrogram\"]\n",
    "    \n",
    "#     total_sum_var += torch.sum((X - mean) ** 2, dim=0)\n",
    "#     total_samples_var += X.size(0)\n",
    "    \n",
    "# std_dev = torch.sqrt(total_sum_var / total_samples_var)\n",
    "# torch.save(std_dev, 'std_dev.pt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe4621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.491605Z",
     "iopub.status.busy": "2024-03-13T14:32:59.491286Z",
     "iopub.status.idle": "2024-03-13T14:32:59.496143Z",
     "shell.execute_reply": "2024-03-13T14:32:59.495263Z"
    },
    "papermill": {
     "duration": 0.0241,
     "end_time": "2024-03-13T14:32:59.498157",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.474057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if CFG.VISUALIZE:\n",
    "#     ROWS = 2\n",
    "#     COLS = 3\n",
    "#     for batch in dataloader:\n",
    "#         X, y = batch[\"spectrogram\"], batch[\"labels\"]\n",
    "#         plt.figure(figsize=(20,8))\n",
    "#         for row in range(ROWS):\n",
    "#             for col in range(COLS):\n",
    "#                 plt.subplot(ROWS, COLS, row*COLS + col+1)\n",
    "#                 t = y[row*COLS + col]\n",
    "#                 img = X[row*COLS + col, :, :, 0]\n",
    "#                 mn = img.flatten().min()\n",
    "#                 mx = img.flatten().max()\n",
    "#                 img = (img-mn)/(mx-mn)\n",
    "#                 plt.imshow(img)\n",
    "#                 tars = f'[{t[0]:0.2f}'\n",
    "#                 for s in t[1:]:\n",
    "#                     tars += f', {s:0.2f}'\n",
    "#                 eeg = train.eeg_id.values[row*CFG.batch_size + row*COLS + col]\n",
    "#                 plt.title(f'EEG = {eeg}\\nTarget = {tars}',size=12)\n",
    "#                 plt.yticks([])\n",
    "#                 plt.ylabel('Frequencies (Hz)',size=14)\n",
    "#                 plt.xlabel('Time (sec)',size=16)\n",
    "#         plt.show()\n",
    "#         break\n",
    "        \n",
    "# del dataloader\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0e0e7",
   "metadata": {
    "papermill": {
     "duration": 0.016387,
     "end_time": "2024-03-13T14:32:59.531665",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.515278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5854e049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.569270Z",
     "iopub.status.busy": "2024-03-13T14:32:59.568315Z",
     "iopub.status.idle": "2024-03-13T14:32:59.582083Z",
     "shell.execute_reply": "2024-03-13T14:32:59.581198Z"
    },
    "papermill": {
     "duration": 0.035755,
     "end_time": "2024-03-13T14:32:59.584413",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.548658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.USE_KAGGLE_SPECTROGRAMS = True\n",
    "        self.USE_EEG_SPECTROGRAMS = True\n",
    "        self.model = timm.create_model(\n",
    "            config.model_name,\n",
    "            pretrained=pretrained,\n",
    "        )\n",
    "        if config.FREEZE:\n",
    "            for i,(name, param) in enumerate(list(self.model.named_parameters())\\\n",
    "                                             [0:config.NUM_FROZEN_LAYERS]):\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-2])\n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.model.num_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def __reshape_input(self, x):\n",
    "        \"\"\"\n",
    "        Reshapes input (128, 256, 8) -> (512, 512, 3) monotone image.\n",
    "        \"\"\" \n",
    "        # === Get spectograms ===\n",
    "        spectograms = [x[:, :, :, i:i+1] for i in range(4)]\n",
    "        spectograms = torch.cat(spectograms, dim=1)\n",
    "        \n",
    "        # === Get EEG spectograms ===\n",
    "        eegs = [x[:, :, :, i:i+1] for i in range(4,8)]\n",
    "        eegs = torch.cat(eegs, dim=1)\n",
    "        \n",
    "        # === Reshape (512,512,3) ===\n",
    "        if self.USE_KAGGLE_SPECTROGRAMS & self.USE_EEG_SPECTROGRAMS:\n",
    "            x = torch.cat([spectograms, eegs], dim=2)\n",
    "        elif self.USE_EEG_SPECTROGRAMS:\n",
    "            x = eegs\n",
    "        else:\n",
    "            x = spectograms\n",
    "            \n",
    "        x = torch.cat([x,x,x], dim=3)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.__reshape_input(x)\n",
    "        x = self.features(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "badd6f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.622618Z",
     "iopub.status.busy": "2024-03-13T14:32:59.621573Z",
     "iopub.status.idle": "2024-03-13T14:32:59.626448Z",
     "shell.execute_reply": "2024-03-13T14:32:59.625449Z"
    },
    "papermill": {
     "duration": 0.026553,
     "end_time": "2024-03-13T14:32:59.628642",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.602089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iot = torch.randn(2, 128, 256, 8)\n",
    "# model = CustomModel(CFG)\n",
    "# output = model(iot)\n",
    "# print(output.shape)\n",
    "\n",
    "# del iot, model, output\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9490e45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.664727Z",
     "iopub.status.busy": "2024-03-13T14:32:59.664338Z",
     "iopub.status.idle": "2024-03-13T14:32:59.670427Z",
     "shell.execute_reply": "2024-03-13T14:32:59.669418Z"
    },
    "papermill": {
     "duration": 0.026834,
     "end_time": "2024-03-13T14:32:59.672529",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.645695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation of pseudo labels\n",
    "\n",
    "# dataset = CustomDataset(train, augment=False, mode=\"train\")\n",
    "# data_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# softmax = nn.Softmax(dim=1)\n",
    "\n",
    "# def generate_pseudo_labels(model, data_loader):\n",
    "#     pseudo_labels = []\n",
    "#     for batch in data_loader:\n",
    "#         X, y = batch[\"spectrogram\"].to(device), batch[\"labels\"].to(device)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(X)\n",
    "#             outputs = softmax(outputs)\n",
    "        \n",
    "#         pseudo_labels.append(outputs.detach().cpu().numpy())  \n",
    "#     pseudo_labels = np.concatenate(pseudo_labels, axis=0)\n",
    "#     return pseudo_labels\n",
    "\n",
    "\n",
    "# pseudo_labels_folds = []\n",
    "\n",
    "# for weights in efficentnet_model_psuedo_weights:\n",
    "#     model = CustomModel(CFG)\n",
    "\n",
    "#     checkpoint = torch.load(weights, map_location=device)\n",
    "#     model.load_state_dict(checkpoint[\"model\"])\n",
    "    \n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "    \n",
    "#     pseudo_labels = generate_pseudo_labels(model, data_loader)\n",
    "#     pseudo_labels_folds.append(pseudo_labels)\n",
    "    \n",
    "#     del model\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# mean_pseudo_labels = np.mean(pseudo_labels_folds, axis=0)\n",
    "# np.save('pseudo_labels.npy', mean_pseudo_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d32be",
   "metadata": {
    "papermill": {
     "duration": 0.016793,
     "end_time": "2024-03-13T14:32:59.706241",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.689448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adan Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2b6ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.741881Z",
     "iopub.status.busy": "2024-03-13T14:32:59.741533Z",
     "iopub.status.idle": "2024-03-13T14:32:59.769997Z",
     "shell.execute_reply": "2024-03-13T14:32:59.769111Z"
    },
    "papermill": {
     "duration": 0.049017,
     "end_time": "2024-03-13T14:32:59.772157",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.723140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "class Adan(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements a pytorch variant of Adan\n",
    "    Adan was proposed in\n",
    "    Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models[J]. arXiv preprint arXiv:2208.06677, 2022.\n",
    "    https://arxiv.org/abs/2208.06677\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n",
    "        lr (float, optional): learning rate. (default: 1e-3)\n",
    "        betas (Tuple[float, float, flot], optional): coefficients used for computing \n",
    "            running averages of gradient and its norm. (default: (0.98, 0.92, 0.99))\n",
    "        eps (float, optional): term added to the denominator to improve \n",
    "            numerical stability. (default: 1e-8)\n",
    "        weight_decay (float, optional): decoupled weight decay (L2 penalty) (default: 0)\n",
    "        max_grad_norm (float, optional): value used to clip \n",
    "            global grad norm (default: 0.0 no clip)\n",
    "        no_prox (bool): how to perform the decoupled weight decay (default: False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.98, 0.92, 0.99), eps=1e-8,\n",
    "                 weight_decay=0.2, max_grad_norm=0.0, no_prox=False):\n",
    "        if not 0.0 <= max_grad_norm:\n",
    "            raise ValueError(\"Invalid Max grad norm: {}\".format(max_grad_norm))\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        if not 0.0 <= betas[2] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 2: {}\".format(betas[2]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay,\n",
    "                        max_grad_norm=max_grad_norm, no_prox=no_prox)\n",
    "        super(Adan, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Adan, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('no_prox', False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def restart_opt(self):\n",
    "        for group in self.param_groups:\n",
    "            group['step'] = 0\n",
    "            for p in group['params']:\n",
    "                if p.requires_grad:\n",
    "                    state = self.state[p]\n",
    "                    # State initialization\n",
    "\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p)\n",
    "                    # Exponential moving average of gradient difference\n",
    "                    state['exp_avg_diff'] = torch.zeros_like(p)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "            Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        if self.defaults['max_grad_norm'] > 0:\n",
    "            device = self.param_groups[0]['params'][0].device\n",
    "            global_grad_norm = torch.zeros(1, device=device)\n",
    "\n",
    "            max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)\n",
    "            for group in self.param_groups:\n",
    "\n",
    "                for p in group['params']:\n",
    "                    if p.grad is not None:\n",
    "                        grad = p.grad\n",
    "                        global_grad_norm.add_(grad.pow(2).sum())\n",
    "\n",
    "            global_grad_norm = torch.sqrt(global_grad_norm)\n",
    "\n",
    "            clip_global_grad_norm = torch.clamp(max_grad_norm / (global_grad_norm + group['eps']), max=1.0)\n",
    "        else:\n",
    "            clip_global_grad_norm = 1.0\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, beta3 = group['betas']\n",
    "            # assume same step across group now to simplify things\n",
    "            # per parameter step can be easily support by making it tensor, or pass list into kernel\n",
    "            if 'step' in group:\n",
    "                group['step'] += 1\n",
    "            else:\n",
    "                group['step'] = 1\n",
    "\n",
    "            bias_correction1 = 1.0 - beta1 ** group['step']\n",
    "\n",
    "            bias_correction2 = 1.0 - beta2 ** group['step']\n",
    "\n",
    "            bias_correction3 = 1.0 - beta3 ** group['step']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['exp_avg'] = torch.zeros_like(p)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p)\n",
    "                    state['exp_avg_diff'] = torch.zeros_like(p)\n",
    "\n",
    "                grad = p.grad.mul_(clip_global_grad_norm)\n",
    "                if 'pre_grad' not in state or group['step'] == 1:\n",
    "                    state['pre_grad'] = grad\n",
    "\n",
    "                copy_grad = grad.clone()\n",
    "\n",
    "                exp_avg, exp_avg_sq, exp_avg_diff = state['exp_avg'], state['exp_avg_sq'], state['exp_avg_diff']\n",
    "                diff = grad - state['pre_grad']\n",
    "\n",
    "                update = grad + beta2 * diff\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)  # m_t\n",
    "                exp_avg_diff.mul_(beta2).add_(diff, alpha=1 - beta2)  # diff_t\n",
    "                exp_avg_sq.mul_(beta3).addcmul_(update, update, value=1 - beta3)  # n_t\n",
    "\n",
    "                denom = ((exp_avg_sq).sqrt() / math.sqrt(bias_correction3)).add_(group['eps'])\n",
    "                update = ((exp_avg / bias_correction1 + beta2 * exp_avg_diff / bias_correction2)).div_(denom)\n",
    "\n",
    "                if group['no_prox']:\n",
    "                    p.data.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "                    p.add_(update, alpha=-group['lr'])\n",
    "                else:\n",
    "                    p.add_(update, alpha=-group['lr'])\n",
    "                    p.data.div_(1 + group['lr'] * group['weight_decay'])\n",
    "\n",
    "                state['pre_grad'] = copy_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41da32c",
   "metadata": {
    "papermill": {
     "duration": 0.016546,
     "end_time": "2024-03-13T14:32:59.805354",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.788808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe9b0a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.840606Z",
     "iopub.status.busy": "2024-03-13T14:32:59.839956Z",
     "iopub.status.idle": "2024-03-13T14:32:59.864374Z",
     "shell.execute_reply": "2024-03-13T14:32:59.863355Z"
    },
    "papermill": {
     "duration": 0.044735,
     "end_time": "2024-03-13T14:32:59.866498",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.821763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        spectrogram = batch['spectrogram'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds= model(spectrogram)\n",
    "            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, batch in enumerate(valid_loader):\n",
    "        spectrogram = batch['spectrogram'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(spectrogram)\n",
    "            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(nn.Softmax(dim=1)(y_preds).to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61622262",
   "metadata": {
    "papermill": {
     "duration": 0.01624,
     "end_time": "2024-03-13T14:32:59.898879",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.882639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20c2cfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.933976Z",
     "iopub.status.busy": "2024-03-13T14:32:59.933549Z",
     "iopub.status.idle": "2024-03-13T14:32:59.961155Z",
     "shell.execute_reply": "2024-03-13T14:32:59.960136Z"
    },
    "papermill": {
     "duration": 0.047862,
     "end_time": "2024-03-13T14:32:59.963228",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.915366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold, directory):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    if CFG.stage1_pop1:\n",
    "        train_folds = folds[(folds['fold'] != fold)].reset_index(drop=True)\n",
    "    else:\n",
    "        train_folds = folds[(folds['fold'] != fold) & (folds['total_evaluators'] >= 10)].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[ CFG.target_cols].values\n",
    "    \n",
    "    train_dataset = CustomDataset(train_folds, augment=True, mode=\"train\")\n",
    "    valid_dataset = CustomDataset(valid_folds, augment=False, mode=\"train\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG)\n",
    "\n",
    "    if CFG.stage2_pop2:\n",
    "        model_weight = POP_1_DIR + f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\"\n",
    "        checkpoint = torch.load(model_weight, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    # CPMP: wrap the model to use all GPUs\n",
    "    #model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model.to(device)\n",
    "    \n",
    "    def build_optimizer(cfg, model, device):\n",
    "        lr = cfg.lr\n",
    "        # lr = default_configs[\"lr\"]\n",
    "        if cfg.optimizer == \"SAM\":\n",
    "            base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "            optimizer_model = SAM(model.parameters(), base_optimizer, lr=lr, momentum=0.9, weight_decay=cfg.weight_decay, adaptive=True)\n",
    "        elif cfg.optimizer == \"Ranger21\":\n",
    "            optimizer_model = Ranger21(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, \n",
    "            num_epochs=cfg.epochs, num_batches_per_epoch=len(train_loader))\n",
    "        elif cfg.optimizer == \"SGD\":\n",
    "            optimizer_model = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9)\n",
    "        elif cfg.optimizer == \"Adam\":\n",
    "            optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n",
    "        elif cfg.optimizer == \"Lion\":\n",
    "            optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "        elif cfg.optimizer == \"Adan\":\n",
    "            optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "    \n",
    "        return optimizer_model\n",
    "    \n",
    "    optimizer = build_optimizer(CFG, model, device)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    # ====================================================\n",
    "\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n",
    "        elif CFG.scheduler=='OneCycleLR':\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            scheduler = OneCycleLR(optimizer=optimizer, epochs=CFG.epochs, anneal_strategy=\"cos\", pct_start=0.05, steps_per_epoch=len(train_loader),\n",
    "        max_lr=CFG.lr, final_div_factor=100)\n",
    "        return scheduler\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score > avg_val_loss:\n",
    "            best_score = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best valid loss: {avg_val_loss:.4f} Model')\n",
    "            # CPMP: save the original model. It is stored as the module attribute of the DP model.\n",
    "            if CFG.stage1_pop1:\n",
    "                \n",
    "                torch.save({'model': model.state_dict(),\n",
    "                            'predictions': predictions},\n",
    "                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\")\n",
    "            else:\n",
    "                \n",
    "                torch.save({'model': model.state_dict(),\n",
    "                            'predictions': predictions},\n",
    "                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\")\n",
    "                \n",
    "    if CFG.stage1_pop1:\n",
    "        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    else:\n",
    "        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "    valid_folds[CFG.target_cols] = valid_labels \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0663bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:32:59.996722Z",
     "iopub.status.busy": "2024-03-13T14:32:59.996408Z",
     "iopub.status.idle": "2024-03-13T17:28:45.935450Z",
     "shell.execute_reply": "2024-03-13T17:28:45.934522Z"
    },
    "papermill": {
     "duration": 10545.95872,
     "end_time": "2024-03-13T17:28:45.938029",
     "exception": false,
     "start_time": "2024-03-13T14:32:59.979309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e38a4663fe4fde9eb76dcd29dcadb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/172] Elapsed 0m 5s (remain 15m 28s) Loss: 0.7470(0.7470) Grad: 60499.4102  LR: 0.00004134  \n",
      "Epoch: [1][50/172] Elapsed 1m 57s (remain 4m 38s) Loss: 0.4591(0.5853) Grad: 57693.6602  LR: 0.00099970  \n",
      "Epoch: [1][100/172] Elapsed 3m 48s (remain 2m 40s) Loss: 0.3142(0.4887) Grad: 102339.8438  LR: 0.00098719  \n",
      "Epoch: [1][150/172] Elapsed 5m 40s (remain 0m 47s) Loss: 0.4475(0.4395) Grad: 55302.7070  LR: 0.00095674  \n",
      "Epoch: [1][171/172] Elapsed 6m 27s (remain 0m 0s) Loss: 0.3113(0.4265) Grad: 47721.4258  LR: 0.00093884  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 15s) Loss: 0.5028(0.5028) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5268(0.4650) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4265  avg_val_loss: 0.4650  time: 425s\n",
      "Epoch 1 - Save Best valid loss: 0.4650 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/172] Elapsed 0m 3s (remain 8m 51s) Loss: 0.2558(0.2558) Grad: 56965.0703  LR: 0.00093792  \n",
      "Epoch: [2][50/172] Elapsed 1m 54s (remain 4m 32s) Loss: 0.2981(0.2746) Grad: 48929.9805  LR: 0.00088375  \n",
      "Epoch: [2][100/172] Elapsed 3m 46s (remain 2m 39s) Loss: 0.1916(0.2805) Grad: 35432.9961  LR: 0.00081546  \n",
      "Epoch: [2][150/172] Elapsed 5m 38s (remain 0m 47s) Loss: 0.2827(0.2766) Grad: 59563.1641  LR: 0.00073554  \n",
      "Epoch: [2][171/172] Elapsed 6m 25s (remain 0m 0s) Loss: 0.2478(0.2724) Grad: 45181.0820  LR: 0.00069921  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.4570(0.4570) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4838(0.4104) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2724  avg_val_loss: 0.4104  time: 425s\n",
      "Epoch 2 - Save Best valid loss: 0.4104 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/172] Elapsed 0m 3s (remain 8m 57s) Loss: 0.2733(0.2733) Grad: 72752.2656  LR: 0.00069744  \n",
      "Epoch: [3][50/172] Elapsed 1m 54s (remain 4m 32s) Loss: 0.2034(0.2248) Grad: 44067.7734  LR: 0.00060606  \n",
      "Epoch: [3][100/172] Elapsed 3m 46s (remain 2m 39s) Loss: 0.2116(0.2264) Grad: 46995.4883  LR: 0.00051077  \n",
      "Epoch: [3][150/172] Elapsed 5m 38s (remain 0m 47s) Loss: 0.1878(0.2232) Grad: 48631.8398  LR: 0.00041509  \n",
      "Epoch: [3][171/172] Elapsed 6m 25s (remain 0m 0s) Loss: 0.2595(0.2223) Grad: 45187.5859  LR: 0.00037564  \n",
      "EVAL: [0/32] Elapsed 0m 1s (remain 1m 0s) Loss: 0.4656(0.4656) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4886(0.4141) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2223  avg_val_loss: 0.4141  time: 423s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/172] Elapsed 0m 3s (remain 8m 53s) Loss: 0.1965(0.1965) Grad: 58626.6758  LR: 0.00037378  \n",
      "Epoch: [4][50/172] Elapsed 1m 54s (remain 4m 32s) Loss: 0.2180(0.1898) Grad: 69197.2422  LR: 0.00028372  \n",
      "Epoch: [4][100/172] Elapsed 3m 46s (remain 2m 39s) Loss: 0.2147(0.1850) Grad: 45777.7852  LR: 0.00020163  \n",
      "Epoch: [4][150/172] Elapsed 5m 38s (remain 0m 47s) Loss: 0.1857(0.1836) Grad: 56518.5703  LR: 0.00013054  \n",
      "Epoch: [4][171/172] Elapsed 6m 25s (remain 0m 0s) Loss: 0.1716(0.1812) Grad: 63646.4727  LR: 0.00010461  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.4451(0.4451) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4435(0.3993) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1812  avg_val_loss: 0.3993  time: 424s\n",
      "Epoch 4 - Save Best valid loss: 0.3993 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/172] Elapsed 0m 3s (remain 9m 1s) Loss: 0.1454(0.1454) Grad: 73117.8750  LR: 0.00010344  \n",
      "Epoch: [5][50/172] Elapsed 1m 54s (remain 4m 32s) Loss: 0.1021(0.1636) Grad: 52726.6055  LR: 0.00005267  \n",
      "Epoch: [5][100/172] Elapsed 3m 46s (remain 2m 39s) Loss: 0.1577(0.1580) Grad: 37147.4375  LR: 0.00001840  \n",
      "Epoch: [5][150/172] Elapsed 5m 38s (remain 0m 47s) Loss: 0.1637(0.1592) Grad: 64907.2109  LR: 0.00000188  \n",
      "Epoch: [5][171/172] Elapsed 6m 25s (remain 0m 0s) Loss: 0.2072(0.1598) Grad: 38980.3281  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.4389(0.4389) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4574(0.4038) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1598  avg_val_loss: 0.4038  time: 425s\n",
      "========== fold: 0 result ==========\n",
      "Score with best loss weights stage1: 0.3992754304234805\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/170] Elapsed 0m 3s (remain 9m 54s) Loss: 0.7398(0.7398) Grad: 60033.1172  LR: 0.00004137  \n",
      "Epoch: [1][50/170] Elapsed 1m 55s (remain 4m 29s) Loss: 0.4668(0.6006) Grad: 50335.4570  LR: 0.00099966  \n",
      "Epoch: [1][100/170] Elapsed 3m 46s (remain 2m 35s) Loss: 0.2787(0.4988) Grad: 43097.0469  LR: 0.00098667  \n",
      "Epoch: [1][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2640(0.4481) Grad: 44785.9531  LR: 0.00095533  \n",
      "Epoch: [1][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.2922(0.4314) Grad: 47946.5586  LR: 0.00093883  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 15s) Loss: 0.4004(0.4004) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4174(0.4656) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4314  avg_val_loss: 0.4656  time: 420s\n",
      "Epoch 1 - Save Best valid loss: 0.4656 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/170] Elapsed 0m 3s (remain 8m 47s) Loss: 0.3368(0.3368) Grad: 79117.6172  LR: 0.00093790  \n",
      "Epoch: [2][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.3522(0.2972) Grad: 49907.8711  LR: 0.00088300  \n",
      "Epoch: [2][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.2814(0.2847) Grad: 44948.0625  LR: 0.00081366  \n",
      "Epoch: [2][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2881(0.2795) Grad: 47436.6289  LR: 0.00073250  \n",
      "Epoch: [2][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.3155(0.2769) Grad: 53819.4141  LR: 0.00069919  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.3286(0.3286) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3222(0.3868) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2769  avg_val_loss: 0.3868  time: 420s\n",
      "Epoch 2 - Save Best valid loss: 0.3868 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/170] Elapsed 0m 3s (remain 8m 47s) Loss: 0.1960(0.1960) Grad: 43943.0312  LR: 0.00069740  \n",
      "Epoch: [3][50/170] Elapsed 1m 54s (remain 4m 27s) Loss: 0.3204(0.2285) Grad: 50099.1953  LR: 0.00060491  \n",
      "Epoch: [3][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.1956(0.2222) Grad: 42328.3750  LR: 0.00050846  \n",
      "Epoch: [3][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2660(0.2231) Grad: 50740.0391  LR: 0.00041171  \n",
      "Epoch: [3][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.2033(0.2206) Grad: 36734.5938  LR: 0.00037562  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.3530(0.3530) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3361(0.3896) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2206  avg_val_loss: 0.3896  time: 420s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/170] Elapsed 0m 3s (remain 8m 51s) Loss: 0.1857(0.1857) Grad: 45136.9570  LR: 0.00037374  \n",
      "Epoch: [4][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.1643(0.1872) Grad: 36707.1719  LR: 0.00028266  \n",
      "Epoch: [4][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.1895(0.1876) Grad: 50595.9180  LR: 0.00019978  \n",
      "Epoch: [4][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2224(0.1848) Grad: 45625.1602  LR: 0.00012823  \n",
      "Epoch: [4][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.1782(0.1841) Grad: 49248.9531  LR: 0.00010460  \n",
      "EVAL: [0/32] Elapsed 0m 1s (remain 1m 1s) Loss: 0.3438(0.3438) \n",
      "EVAL: [31/32] Elapsed 0m 36s (remain 0m 0s) Loss: 0.3634(0.3932) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1841  avg_val_loss: 0.3932  time: 419s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/170] Elapsed 0m 3s (remain 8m 51s) Loss: 0.1994(0.1994) Grad: 51117.7539  LR: 0.00010341  \n",
      "Epoch: [5][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.1721(0.1637) Grad: 43356.3281  LR: 0.00005215  \n",
      "Epoch: [5][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.1340(0.1638) Grad: 36949.4609  LR: 0.00001779  \n",
      "Epoch: [5][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.1780(0.1632) Grad: 60452.6875  LR: 0.00000163  \n",
      "Epoch: [5][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.1511(0.1631) Grad: 44303.9648  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.3571(0.3571) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3723(0.4029) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1631  avg_val_loss: 0.4029  time: 419s\n",
      "========== fold: 1 result ==========\n",
      "Score with best loss weights stage1: 0.38682517318522425\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/170] Elapsed 0m 3s (remain 9m 52s) Loss: 0.7929(0.7929) Grad: 62887.6211  LR: 0.00004137  \n",
      "Epoch: [1][50/170] Elapsed 1m 55s (remain 4m 29s) Loss: 0.5296(0.6134) Grad: 56368.3359  LR: 0.00099966  \n",
      "Epoch: [1][100/170] Elapsed 3m 46s (remain 2m 35s) Loss: 0.3498(0.5012) Grad: 82183.6406  LR: 0.00098667  \n",
      "Epoch: [1][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2586(0.4488) Grad: 47889.0820  LR: 0.00095533  \n",
      "Epoch: [1][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.3115(0.4327) Grad: 77326.8047  LR: 0.00093883  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 12s) Loss: 0.5499(0.5499) \n",
      "EVAL: [31/32] Elapsed 0m 36s (remain 0m 0s) Loss: 0.5123(0.4635) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4327  avg_val_loss: 0.4635  time: 418s\n",
      "Epoch 1 - Save Best valid loss: 0.4635 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/170] Elapsed 0m 3s (remain 8m 52s) Loss: 0.2661(0.2661) Grad: 49908.7422  LR: 0.00093790  \n",
      "Epoch: [2][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.2279(0.2884) Grad: 42651.0234  LR: 0.00088300  \n",
      "Epoch: [2][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.2448(0.2805) Grad: 37572.1328  LR: 0.00081366  \n",
      "Epoch: [2][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2278(0.2745) Grad: 61722.1992  LR: 0.00073250  \n",
      "Epoch: [2][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.2833(0.2732) Grad: 51802.6328  LR: 0.00069919  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.4745(0.4745) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4118(0.4109) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2732  avg_val_loss: 0.4109  time: 421s\n",
      "Epoch 2 - Save Best valid loss: 0.4109 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/170] Elapsed 0m 3s (remain 9m 3s) Loss: 0.2748(0.2748) Grad: 59920.0586  LR: 0.00069740  \n",
      "Epoch: [3][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.1965(0.2280) Grad: 42780.5742  LR: 0.00060491  \n",
      "Epoch: [3][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.2530(0.2251) Grad: 71315.2969  LR: 0.00050846  \n",
      "Epoch: [3][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2325(0.2209) Grad: 50296.3242  LR: 0.00041171  \n",
      "Epoch: [3][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.2260(0.2214) Grad: 41924.7891  LR: 0.00037562  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 4s) Loss: 0.4624(0.4624) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4380(0.4007) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2214  avg_val_loss: 0.4007  time: 420s\n",
      "Epoch 3 - Save Best valid loss: 0.4007 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/170] Elapsed 0m 3s (remain 8m 56s) Loss: 0.1637(0.1637) Grad: 43269.1875  LR: 0.00037374  \n",
      "Epoch: [4][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.1600(0.1818) Grad: 47734.3867  LR: 0.00028266  \n",
      "Epoch: [4][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.2068(0.1870) Grad: 60724.0156  LR: 0.00019978  \n",
      "Epoch: [4][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.2375(0.1841) Grad: 76864.9219  LR: 0.00012823  \n",
      "Epoch: [4][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.1546(0.1847) Grad: 46897.9219  LR: 0.00010460  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.4451(0.4451) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4422(0.3905) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1847  avg_val_loss: 0.3905  time: 422s\n",
      "Epoch 4 - Save Best valid loss: 0.3905 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/170] Elapsed 0m 3s (remain 8m 52s) Loss: 0.1957(0.1957) Grad: 70786.7812  LR: 0.00010341  \n",
      "Epoch: [5][50/170] Elapsed 1m 54s (remain 4m 28s) Loss: 0.2110(0.1617) Grad: 57078.8945  LR: 0.00005215  \n",
      "Epoch: [5][100/170] Elapsed 3m 46s (remain 2m 34s) Loss: 0.2118(0.1619) Grad: 72066.2812  LR: 0.00001779  \n",
      "Epoch: [5][150/170] Elapsed 5m 38s (remain 0m 42s) Loss: 0.1769(0.1627) Grad: 47621.8477  LR: 0.00000163  \n",
      "Epoch: [5][169/170] Elapsed 6m 20s (remain 0m 0s) Loss: 0.2116(0.1625) Grad: 89482.9922  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.4523(0.4523) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4404(0.3911) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1625  avg_val_loss: 0.3911  time: 419s\n",
      "========== fold: 2 result ==========\n",
      "Score with best loss weights stage1: 0.3905339685441953\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/169] Elapsed 0m 3s (remain 9m 52s) Loss: 0.7463(0.7463) Grad: 71761.9766  LR: 0.00004139  \n",
      "Epoch: [1][50/169] Elapsed 1m 55s (remain 4m 26s) Loss: 0.3982(0.5893) Grad: 48221.7383  LR: 0.00099964  \n",
      "Epoch: [1][100/169] Elapsed 3m 46s (remain 2m 32s) Loss: 0.3560(0.5000) Grad: 51438.7344  LR: 0.00098640  \n",
      "Epoch: [1][150/169] Elapsed 5m 38s (remain 0m 40s) Loss: 0.3607(0.4516) Grad: 59219.8906  LR: 0.00095460  \n",
      "Epoch: [1][168/169] Elapsed 6m 18s (remain 0m 0s) Loss: 0.3476(0.4383) Grad: 52496.2305  LR: 0.00093883  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 15s) Loss: 0.5530(0.5530) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.5186(0.4819) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4383  avg_val_loss: 0.4819  time: 419s\n",
      "Epoch 1 - Save Best valid loss: 0.4819 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/169] Elapsed 0m 3s (remain 8m 53s) Loss: 0.2405(0.2405) Grad: 36324.6797  LR: 0.00093789  \n",
      "Epoch: [2][50/169] Elapsed 1m 54s (remain 4m 26s) Loss: 0.2492(0.2996) Grad: 57764.8125  LR: 0.00088261  \n",
      "Epoch: [2][100/169] Elapsed 3m 46s (remain 2m 32s) Loss: 0.3338(0.2935) Grad: 55720.1797  LR: 0.00081275  \n",
      "Epoch: [2][150/169] Elapsed 5m 38s (remain 0m 40s) Loss: 0.2524(0.2845) Grad: 57475.6211  LR: 0.00073095  \n",
      "Epoch: [2][168/169] Elapsed 6m 18s (remain 0m 0s) Loss: 0.2704(0.2842) Grad: 54867.3164  LR: 0.00069917  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.4286(0.4286) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4201(0.4117) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2842  avg_val_loss: 0.4117  time: 419s\n",
      "Epoch 2 - Save Best valid loss: 0.4117 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/169] Elapsed 0m 3s (remain 8m 46s) Loss: 0.2143(0.2143) Grad: 51444.9258  LR: 0.00069738  \n",
      "Epoch: [3][50/169] Elapsed 1m 54s (remain 4m 25s) Loss: 0.2257(0.2283) Grad: 62357.1250  LR: 0.00060432  \n",
      "Epoch: [3][100/169] Elapsed 3m 46s (remain 2m 32s) Loss: 0.2305(0.2312) Grad: 42976.4648  LR: 0.00050729  \n",
      "Epoch: [3][150/169] Elapsed 5m 38s (remain 0m 40s) Loss: 0.2322(0.2292) Grad: 48064.5234  LR: 0.00040999  \n",
      "Epoch: [3][168/169] Elapsed 6m 18s (remain 0m 0s) Loss: 0.2373(0.2274) Grad: 51684.2344  LR: 0.00037561  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.3745(0.3745) \n",
      "EVAL: [31/32] Elapsed 0m 40s (remain 0m 0s) Loss: 0.3997(0.4064) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2274  avg_val_loss: 0.4064  time: 420s\n",
      "Epoch 3 - Save Best valid loss: 0.4064 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/169] Elapsed 0m 3s (remain 8m 56s) Loss: 0.1769(0.1769) Grad: 57455.4180  LR: 0.00037372  \n",
      "Epoch: [4][50/169] Elapsed 1m 54s (remain 4m 25s) Loss: 0.1715(0.1956) Grad: 48809.0391  LR: 0.00028212  \n",
      "Epoch: [4][100/169] Elapsed 3m 46s (remain 2m 32s) Loss: 0.1338(0.1927) Grad: 40834.0234  LR: 0.00019884  \n",
      "Epoch: [4][150/169] Elapsed 5m 38s (remain 0m 40s) Loss: 0.1665(0.1905) Grad: 53627.4766  LR: 0.00012707  \n",
      "Epoch: [4][168/169] Elapsed 6m 18s (remain 0m 0s) Loss: 0.1817(0.1911) Grad: 56197.3750  LR: 0.00010459  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 6s) Loss: 0.3703(0.3703) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3905(0.3879) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1911  avg_val_loss: 0.3879  time: 418s\n",
      "Epoch 4 - Save Best valid loss: 0.3879 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/169] Elapsed 0m 3s (remain 8m 50s) Loss: 0.2049(0.2049) Grad: 43979.0195  LR: 0.00010340  \n",
      "Epoch: [5][50/169] Elapsed 1m 54s (remain 4m 25s) Loss: 0.2550(0.1728) Grad: 67841.5859  LR: 0.00005188  \n",
      "Epoch: [5][100/169] Elapsed 3m 46s (remain 2m 32s) Loss: 0.1509(0.1701) Grad: 35092.2188  LR: 0.00001748  \n",
      "Epoch: [5][150/169] Elapsed 5m 38s (remain 0m 40s) Loss: 0.1831(0.1685) Grad: 70357.9844  LR: 0.00000151  \n",
      "Epoch: [5][168/169] Elapsed 6m 18s (remain 0m 0s) Loss: 0.2019(0.1705) Grad: 67495.0156  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.3851(0.3851) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4111(0.3916) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1705  avg_val_loss: 0.3916  time: 419s\n",
      "========== fold: 3 result ==========\n",
      "Score with best loss weights stage1: 0.3879059451836188\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/172] Elapsed 0m 3s (remain 10m 4s) Loss: 0.8192(0.8192) Grad: 73901.1406  LR: 0.00004134  \n",
      "Epoch: [1][50/172] Elapsed 1m 55s (remain 4m 33s) Loss: 0.4375(0.6040) Grad: 97822.1250  LR: 0.00099970  \n",
      "Epoch: [1][100/172] Elapsed 3m 46s (remain 2m 39s) Loss: 0.3531(0.5025) Grad: 47639.7734  LR: 0.00098719  \n",
      "Epoch: [1][150/172] Elapsed 5m 38s (remain 0m 47s) Loss: 0.4140(0.4498) Grad: 66298.8359  LR: 0.00095674  \n",
      "Epoch: [1][171/172] Elapsed 6m 25s (remain 0m 0s) Loss: 0.3630(0.4352) Grad: 44372.7227  LR: 0.00093884  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 12s) Loss: 0.4723(0.4723) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4362(0.4951) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4352  avg_val_loss: 0.4951  time: 424s\n",
      "Epoch 1 - Save Best valid loss: 0.4951 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/172] Elapsed 0m 3s (remain 9m 1s) Loss: 0.2733(0.2733) Grad: 51779.3828  LR: 0.00093792  \n",
      "Epoch: [2][50/172] Elapsed 1m 55s (remain 4m 33s) Loss: 0.3025(0.2920) Grad: 71076.3203  LR: 0.00088375  \n",
      "Epoch: [2][100/172] Elapsed 3m 47s (remain 2m 39s) Loss: 0.3119(0.2865) Grad: 60338.2500  LR: 0.00081546  \n",
      "Epoch: [2][150/172] Elapsed 5m 39s (remain 0m 47s) Loss: 0.3243(0.2814) Grad: 65235.7812  LR: 0.00073554  \n",
      "Epoch: [2][171/172] Elapsed 6m 25s (remain 0m 0s) Loss: 0.1986(0.2787) Grad: 47248.0742  LR: 0.00069921  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.4110(0.4110) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3395(0.4155) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2787  avg_val_loss: 0.4155  time: 425s\n",
      "Epoch 2 - Save Best valid loss: 0.4155 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/172] Elapsed 0m 3s (remain 9m 16s) Loss: 0.3059(0.3059) Grad: 51836.8438  LR: 0.00069744  \n",
      "Epoch: [3][50/172] Elapsed 1m 55s (remain 4m 33s) Loss: 0.1719(0.2377) Grad: 41897.9492  LR: 0.00060606  \n",
      "Epoch: [3][100/172] Elapsed 3m 47s (remain 2m 39s) Loss: 0.2441(0.2300) Grad: 144647.0469  LR: 0.00051077  \n",
      "Epoch: [3][150/172] Elapsed 5m 39s (remain 0m 47s) Loss: 0.2343(0.2266) Grad: 47616.0039  LR: 0.00041509  \n",
      "Epoch: [3][171/172] Elapsed 6m 26s (remain 0m 0s) Loss: 0.2272(0.2249) Grad: 59286.2266  LR: 0.00037564  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.3996(0.3996) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3214(0.3870) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2249  avg_val_loss: 0.3870  time: 425s\n",
      "Epoch 3 - Save Best valid loss: 0.3870 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/172] Elapsed 0m 3s (remain 9m 5s) Loss: 0.2259(0.2259) Grad: 72016.5078  LR: 0.00037378  \n",
      "Epoch: [4][50/172] Elapsed 1m 55s (remain 4m 33s) Loss: 0.1620(0.1930) Grad: 48965.0195  LR: 0.00028372  \n",
      "Epoch: [4][100/172] Elapsed 3m 47s (remain 2m 39s) Loss: 0.1666(0.1895) Grad: 68807.4453  LR: 0.00020163  \n",
      "Epoch: [4][150/172] Elapsed 5m 39s (remain 0m 47s) Loss: 0.1768(0.1908) Grad: 55907.8438  LR: 0.00013054  \n",
      "Epoch: [4][171/172] Elapsed 6m 26s (remain 0m 0s) Loss: 0.1984(0.1886) Grad: 57495.0000  LR: 0.00010461  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.3922(0.3922) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3353(0.3889) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1886  avg_val_loss: 0.3889  time: 425s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/172] Elapsed 0m 3s (remain 9m 9s) Loss: 0.1457(0.1457) Grad: 40037.9141  LR: 0.00010344  \n",
      "Epoch: [5][50/172] Elapsed 1m 55s (remain 4m 33s) Loss: 0.1354(0.1644) Grad: 41506.2969  LR: 0.00005267  \n",
      "Epoch: [5][100/172] Elapsed 3m 47s (remain 2m 39s) Loss: 0.1527(0.1651) Grad: 48141.7812  LR: 0.00001840  \n",
      "Epoch: [5][150/172] Elapsed 5m 39s (remain 0m 47s) Loss: 0.1927(0.1662) Grad: 56434.7539  LR: 0.00000188  \n",
      "Epoch: [5][171/172] Elapsed 6m 26s (remain 0m 0s) Loss: 0.1486(0.1658) Grad: 35378.2734  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.4036(0.4036) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3192(0.3857) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1658  avg_val_loss: 0.3857  time: 426s\n",
      "Epoch 5 - Save Best valid loss: 0.3857 Model\n",
      "========== fold: 4 result ==========\n",
      "Score with best loss weights stage1: 0.385736304805111\n",
      "========== CV ==========\n",
      "Score with best loss weights stage1: 0.390055364428326\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        scores = []\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df, score = train_loop(train, fold, POP_1_DIR)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                scores.append(score)\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                LOGGER.info(f'Score with best loss weights stage1: {score}')\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        LOGGER.info(f'Score with best loss weights stage1: {np.mean(scores)}')\n",
    "        oof_df.to_csv(POP_1_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage1.csv', index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3745a723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:28:46.013046Z",
     "iopub.status.busy": "2024-03-13T17:28:46.012631Z",
     "iopub.status.idle": "2024-03-13T19:01:09.003918Z",
     "shell.execute_reply": "2024-03-13T19:01:09.002657Z"
    },
    "papermill": {
     "duration": 5543.03182,
     "end_time": "2024-03-13T19:01:09.006843",
     "exception": false,
     "start_time": "2024-03-13T17:28:45.975023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/79] Elapsed 0m 3s (remain 4m 34s) Loss: 0.5183(0.5183) Grad: 94041.3438  LR: 0.00004672  \n",
      "Epoch: [1][50/79] Elapsed 1m 55s (remain 1m 3s) Loss: 0.2810(0.3850) Grad: 47933.2188  LR: 0.00098189  \n",
      "Epoch: [1][78/79] Elapsed 2m 57s (remain 0m 0s) Loss: 0.3322(0.3664) Grad: 82335.5781  LR: 0.00093775  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 13s) Loss: 0.5376(0.5376) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4869(0.4817) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.3664  avg_val_loss: 0.4817  time: 217s\n",
      "Epoch 1 - Save Best valid loss: 0.4817 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/79] Elapsed 0m 3s (remain 4m 5s) Loss: 0.2541(0.2541) Grad: 45327.6914  LR: 0.00093572  \n",
      "Epoch: [2][50/79] Elapsed 1m 54s (remain 1m 3s) Loss: 0.2743(0.2836) Grad: 65368.3906  LR: 0.00079844  \n",
      "Epoch: [2][78/79] Elapsed 2m 57s (remain 0m 0s) Loss: 0.2617(0.2770) Grad: 51833.8086  LR: 0.00069713  \n",
      "EVAL: [0/32] Elapsed 0m 1s (remain 1m 1s) Loss: 0.5760(0.5760) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.5625(0.5462) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2770  avg_val_loss: 0.5462  time: 217s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/79] Elapsed 0m 3s (remain 4m 8s) Loss: 0.2612(0.2612) Grad: 50026.4336  LR: 0.00069328  \n",
      "Epoch: [3][50/79] Elapsed 1m 54s (remain 1m 3s) Loss: 0.2213(0.2390) Grad: 55968.5156  LR: 0.00048922  \n",
      "Epoch: [3][78/79] Elapsed 2m 57s (remain 0m 0s) Loss: 0.2488(0.2385) Grad: 55493.6836  LR: 0.00037345  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.5740(0.5740) \n",
      "EVAL: [31/32] Elapsed 0m 36s (remain 0m 0s) Loss: 0.5238(0.5046) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2385  avg_val_loss: 0.5046  time: 214s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/79] Elapsed 0m 3s (remain 4m 3s) Loss: 0.2299(0.2299) Grad: 40352.2031  LR: 0.00036941  \n",
      "Epoch: [4][50/79] Elapsed 1m 54s (remain 1m 3s) Loss: 0.1830(0.2121) Grad: 40473.2305  LR: 0.00018462  \n",
      "Epoch: [4][78/79] Elapsed 2m 57s (remain 0m 0s) Loss: 0.2104(0.2078) Grad: 55541.3672  LR: 0.00010323  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.5999(0.5999) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5620(0.5375) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2078  avg_val_loss: 0.5375  time: 215s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/79] Elapsed 0m 3s (remain 4m 11s) Loss: 0.2282(0.2282) Grad: 50427.3359  LR: 0.00010070  \n",
      "Epoch: [5][50/79] Elapsed 1m 54s (remain 1m 3s) Loss: 0.1985(0.1901) Grad: 56879.2109  LR: 0.00001311  \n",
      "Epoch: [5][78/79] Elapsed 2m 57s (remain 0m 0s) Loss: 0.1914(0.1884) Grad: 41771.0430  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 6s) Loss: 0.6071(0.6071) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5688(0.5468) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1884  avg_val_loss: 0.5468  time: 216s\n",
      "========== fold: 0 result ==========\n",
      "Score with best loss weights stage2: 0.4816953307084586\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/81] Elapsed 0m 3s (remain 4m 43s) Loss: 0.6470(0.6470) Grad: 84007.6484  LR: 0.00004638  \n",
      "Epoch: [1][50/81] Elapsed 1m 55s (remain 1m 7s) Loss: 0.3958(0.4055) Grad: 62731.6797  LR: 0.00098330  \n",
      "Epoch: [1][80/81] Elapsed 3m 2s (remain 0m 0s) Loss: 0.3567(0.3802) Grad: 63854.7422  LR: 0.00093780  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 14s) Loss: 0.4245(0.4245) \n",
      "EVAL: [31/32] Elapsed 0m 36s (remain 0m 0s) Loss: 0.5551(0.4775) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.3802  avg_val_loss: 0.4775  time: 220s\n",
      "Epoch 1 - Save Best valid loss: 0.4775 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/81] Elapsed 0m 3s (remain 4m 13s) Loss: 0.2750(0.2750) Grad: 39304.1133  LR: 0.00093582  \n",
      "Epoch: [2][50/81] Elapsed 1m 54s (remain 1m 7s) Loss: 0.2994(0.2876) Grad: 50926.7930  LR: 0.00080274  \n",
      "Epoch: [2][80/81] Elapsed 3m 1s (remain 0m 0s) Loss: 0.2493(0.2844) Grad: 41885.1562  LR: 0.00069722  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 6s) Loss: 0.4980(0.4980) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.7151(0.5820) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2844  avg_val_loss: 0.5820  time: 222s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/81] Elapsed 0m 3s (remain 4m 13s) Loss: 0.2296(0.2296) Grad: 36696.8555  LR: 0.00069347  \n",
      "Epoch: [3][50/81] Elapsed 1m 54s (remain 1m 7s) Loss: 0.3155(0.2424) Grad: 57057.8828  LR: 0.00049459  \n",
      "Epoch: [3][80/81] Elapsed 3m 1s (remain 0m 0s) Loss: 0.2274(0.2414) Grad: 46616.6992  LR: 0.00037355  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 4s) Loss: 0.5098(0.5098) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.7403(0.5800) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2414  avg_val_loss: 0.5800  time: 221s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/81] Elapsed 0m 3s (remain 4m 16s) Loss: 0.2253(0.2253) Grad: 35284.5859  LR: 0.00036961  \n",
      "Epoch: [4][50/81] Elapsed 1m 54s (remain 1m 7s) Loss: 0.2917(0.2166) Grad: 53678.9922  LR: 0.00018881  \n",
      "Epoch: [4][80/81] Elapsed 3m 1s (remain 0m 0s) Loss: 0.2574(0.2135) Grad: 49999.6328  LR: 0.00010329  \n",
      "EVAL: [0/32] Elapsed 0m 1s (remain 1m 0s) Loss: 0.4805(0.4805) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.7285(0.5539) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2135  avg_val_loss: 0.5539  time: 222s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/81] Elapsed 0m 3s (remain 4m 12s) Loss: 0.1925(0.1925) Grad: 34907.7305  LR: 0.00010083  \n",
      "Epoch: [5][50/81] Elapsed 1m 54s (remain 1m 7s) Loss: 0.2385(0.1960) Grad: 41248.3828  LR: 0.00001435  \n",
      "Epoch: [5][80/81] Elapsed 3m 1s (remain 0m 0s) Loss: 0.1645(0.1975) Grad: 27224.0352  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.4782(0.4782) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.7220(0.5494) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1975  avg_val_loss: 0.5494  time: 221s\n",
      "========== fold: 1 result ==========\n",
      "Score with best loss weights stage2: 0.4774833385059082\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/82] Elapsed 0m 3s (remain 4m 46s) Loss: 0.5047(0.5047) Grad: 72150.4922  LR: 0.00004622  \n",
      "Epoch: [1][50/82] Elapsed 1m 55s (remain 1m 10s) Loss: 0.3441(0.3855) Grad: 56561.2734  LR: 0.00098396  \n",
      "Epoch: [1][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.2912(0.3607) Grad: 68262.3672  LR: 0.00093783  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 13s) Loss: 0.5854(0.5854) \n",
      "EVAL: [31/32] Elapsed 0m 36s (remain 0m 0s) Loss: 0.4894(0.5782) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.3607  avg_val_loss: 0.5782  time: 222s\n",
      "Epoch 1 - Save Best valid loss: 0.5782 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/82] Elapsed 0m 3s (remain 4m 15s) Loss: 0.2494(0.2494) Grad: 50761.6602  LR: 0.00093587  \n",
      "Epoch: [2][50/82] Elapsed 1m 54s (remain 1m 9s) Loss: 0.3047(0.2755) Grad: 59429.7500  LR: 0.00080479  \n",
      "Epoch: [2][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.3100(0.2707) Grad: 48064.0742  LR: 0.00069727  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 4s) Loss: 0.5996(0.5996) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4632(0.5434) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2707  avg_val_loss: 0.5434  time: 223s\n",
      "Epoch 2 - Save Best valid loss: 0.5434 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/82] Elapsed 0m 3s (remain 4m 15s) Loss: 0.2779(0.2779) Grad: 51454.5156  LR: 0.00069356  \n",
      "Epoch: [3][50/82] Elapsed 1m 54s (remain 1m 9s) Loss: 0.2201(0.2309) Grad: 45690.6094  LR: 0.00049718  \n",
      "Epoch: [3][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.1923(0.2312) Grad: 36428.7148  LR: 0.00037360  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 2s) Loss: 0.6021(0.6021) \n",
      "EVAL: [31/32] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5286(0.5959) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2312  avg_val_loss: 0.5959  time: 223s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/82] Elapsed 0m 3s (remain 4m 14s) Loss: 0.1974(0.1974) Grad: 36361.3711  LR: 0.00036971  \n",
      "Epoch: [4][50/82] Elapsed 1m 54s (remain 1m 9s) Loss: 0.2225(0.1967) Grad: 41000.7539  LR: 0.00019084  \n",
      "Epoch: [4][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.2297(0.1972) Grad: 45877.5391  LR: 0.00010332  \n",
      "EVAL: [0/32] Elapsed 0m 1s (remain 1m 1s) Loss: 0.5924(0.5924) \n",
      "EVAL: [31/32] Elapsed 0m 38s (remain 0m 0s) Loss: 0.5390(0.5857) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1972  avg_val_loss: 0.5857  time: 224s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/82] Elapsed 0m 3s (remain 4m 19s) Loss: 0.1683(0.1683) Grad: 33829.5273  LR: 0.00010089  \n",
      "Epoch: [5][50/82] Elapsed 1m 55s (remain 1m 9s) Loss: 0.2089(0.1854) Grad: 49192.0781  LR: 0.00001496  \n",
      "Epoch: [5][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.1739(0.1832) Grad: 40067.7617  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 8s) Loss: 0.5838(0.5838) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.5195(0.5798) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1832  avg_val_loss: 0.5798  time: 224s\n",
      "========== fold: 2 result ==========\n",
      "Score with best loss weights stage2: 0.5433639004689973\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/82] Elapsed 0m 3s (remain 4m 48s) Loss: 0.5983(0.5983) Grad: 90203.2344  LR: 0.00004622  \n",
      "Epoch: [1][50/82] Elapsed 1m 55s (remain 1m 10s) Loss: 0.3208(0.4015) Grad: 50413.5742  LR: 0.00098396  \n",
      "Epoch: [1][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.3636(0.3734) Grad: 84186.6172  LR: 0.00093783  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 16s) Loss: 0.6003(0.6003) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.9129(0.6361) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.3734  avg_val_loss: 0.6361  time: 224s\n",
      "Epoch 1 - Save Best valid loss: 0.6361 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/82] Elapsed 0m 3s (remain 4m 21s) Loss: 0.2717(0.2717) Grad: 48092.5508  LR: 0.00093587  \n",
      "Epoch: [2][50/82] Elapsed 1m 55s (remain 1m 10s) Loss: 0.2629(0.2779) Grad: 50164.6914  LR: 0.00080479  \n",
      "Epoch: [2][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.2730(0.2743) Grad: 48367.8633  LR: 0.00069727  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 9s) Loss: 0.5118(0.5118) \n",
      "EVAL: [31/32] Elapsed 0m 40s (remain 0m 0s) Loss: 0.8328(0.5565) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2743  avg_val_loss: 0.5565  time: 226s\n",
      "Epoch 2 - Save Best valid loss: 0.5565 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/82] Elapsed 0m 3s (remain 4m 20s) Loss: 0.2213(0.2213) Grad: 36038.0742  LR: 0.00069356  \n",
      "Epoch: [3][50/82] Elapsed 1m 55s (remain 1m 10s) Loss: 0.1725(0.2250) Grad: 30495.6621  LR: 0.00049718  \n",
      "Epoch: [3][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.2460(0.2315) Grad: 42320.0039  LR: 0.00037360  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.5176(0.5176) \n",
      "EVAL: [31/32] Elapsed 0m 41s (remain 0m 0s) Loss: 0.8143(0.5522) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2315  avg_val_loss: 0.5522  time: 227s\n",
      "Epoch 3 - Save Best valid loss: 0.5522 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/82] Elapsed 0m 3s (remain 4m 23s) Loss: 0.1760(0.1760) Grad: 37059.5508  LR: 0.00036971  \n",
      "Epoch: [4][50/82] Elapsed 1m 55s (remain 1m 10s) Loss: 0.1727(0.2053) Grad: 36087.7266  LR: 0.00019084  \n",
      "Epoch: [4][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.1615(0.2026) Grad: 31324.9531  LR: 0.00010332  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 3s) Loss: 0.5244(0.5244) \n",
      "EVAL: [31/32] Elapsed 0m 40s (remain 0m 0s) Loss: 0.8289(0.5639) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2026  avg_val_loss: 0.5639  time: 225s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/82] Elapsed 0m 3s (remain 4m 23s) Loss: 0.1656(0.1656) Grad: 38832.3906  LR: 0.00010089  \n",
      "Epoch: [5][50/82] Elapsed 1m 55s (remain 1m 10s) Loss: 0.1585(0.1882) Grad: 38998.3398  LR: 0.00001496  \n",
      "Epoch: [5][81/82] Elapsed 3m 4s (remain 0m 0s) Loss: 0.1759(0.1852) Grad: 46079.2148  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.5251(0.5251) \n",
      "EVAL: [31/32] Elapsed 0m 40s (remain 0m 0s) Loss: 0.8308(0.5647) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1852  avg_val_loss: 0.5647  time: 226s\n",
      "========== fold: 3 result ==========\n",
      "Score with best loss weights stage2: 0.5522099171568546\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/80] Elapsed 0m 3s (remain 4m 42s) Loss: 0.5195(0.5195) Grad: 72729.3281  LR: 0.00004655  \n",
      "Epoch: [1][50/80] Elapsed 1m 55s (remain 1m 5s) Loss: 0.3068(0.3852) Grad: 56567.3047  LR: 0.00098261  \n",
      "Epoch: [1][79/80] Elapsed 2m 59s (remain 0m 0s) Loss: 0.3861(0.3580) Grad: 58810.1758  LR: 0.00093778  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 14s) Loss: 0.6881(0.6881) \n",
      "EVAL: [31/32] Elapsed 0m 40s (remain 0m 0s) Loss: 0.5238(0.5629) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.3580  avg_val_loss: 0.5629  time: 221s\n",
      "Epoch 1 - Save Best valid loss: 0.5629 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/80] Elapsed 0m 3s (remain 4m 14s) Loss: 0.2840(0.2840) Grad: 57398.0117  LR: 0.00093577  \n",
      "Epoch: [2][50/80] Elapsed 1m 55s (remain 1m 5s) Loss: 0.2865(0.2695) Grad: 65933.6328  LR: 0.00080062  \n",
      "Epoch: [2][79/80] Elapsed 2m 59s (remain 0m 0s) Loss: 0.2507(0.2644) Grad: 58713.9648  LR: 0.00069718  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.6307(0.6307) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.5382(0.5812) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2644  avg_val_loss: 0.5812  time: 220s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/80] Elapsed 0m 3s (remain 4m 15s) Loss: 0.2532(0.2532) Grad: 81518.0703  LR: 0.00069337  \n",
      "Epoch: [3][50/80] Elapsed 1m 55s (remain 1m 5s) Loss: 0.2056(0.2179) Grad: 40228.4297  LR: 0.00049194  \n",
      "Epoch: [3][79/80] Elapsed 2m 59s (remain 0m 0s) Loss: 0.2144(0.2234) Grad: 44341.0781  LR: 0.00037351  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.6563(0.6563) \n",
      "EVAL: [31/32] Elapsed 0m 39s (remain 0m 0s) Loss: 0.5489(0.5562) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2234  avg_val_loss: 0.5562  time: 220s\n",
      "Epoch 3 - Save Best valid loss: 0.5562 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/80] Elapsed 0m 3s (remain 4m 10s) Loss: 0.1958(0.1958) Grad: 43178.0547  LR: 0.00036951  \n",
      "Epoch: [4][50/80] Elapsed 1m 55s (remain 1m 5s) Loss: 0.1956(0.1938) Grad: 45578.9219  LR: 0.00018674  \n",
      "Epoch: [4][79/80] Elapsed 2m 59s (remain 0m 0s) Loss: 0.1614(0.1925) Grad: 39843.9648  LR: 0.00010326  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 6s) Loss: 0.7314(0.7314) \n",
      "EVAL: [31/32] Elapsed 0m 41s (remain 0m 0s) Loss: 0.5856(0.6090) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1925  avg_val_loss: 0.6090  time: 222s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/80] Elapsed 0m 3s (remain 4m 14s) Loss: 0.2047(0.2047) Grad: 46291.8203  LR: 0.00010077  \n",
      "Epoch: [5][50/80] Elapsed 1m 55s (remain 1m 5s) Loss: 0.1846(0.1818) Grad: 35256.1172  LR: 0.00001373  \n",
      "Epoch: [5][79/80] Elapsed 2m 59s (remain 0m 0s) Loss: 0.1910(0.1802) Grad: 34956.6836  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 5s) Loss: 0.7260(0.7260) \n",
      "EVAL: [31/32] Elapsed 0m 43s (remain 0m 0s) Loss: 0.5580(0.5998) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1802  avg_val_loss: 0.5998  time: 224s\n",
      "========== fold: 4 result ==========\n",
      "Score with best loss weights stage2: 0.556249942545612\n",
      "========== CV ==========\n",
      "Score with best loss weights stage2: 0.522200485877166\n"
     ]
    }
   ],
   "source": [
    "CFG.stage1_pop1 = False\n",
    "CFG.stage2_pop2 = True\n",
    "CFG.epochs = 5\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        scores = []\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df, score = train_loop(train, fold, POP_2_DIR)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                scores.append(score)\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                LOGGER.info(f'Score with best loss weights stage2: {score}')\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        LOGGER.info(f'Score with best loss weights stage2: {np.mean(scores)}')\n",
    "        oof_df.to_csv(POP_2_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage2.csv', index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "093f89b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T19:01:09.361153Z",
     "iopub.status.busy": "2024-03-13T19:01:09.360255Z",
     "iopub.status.idle": "2024-03-13T19:01:09.454326Z",
     "shell.execute_reply": "2024-03-13T19:01:09.452945Z"
    },
    "papermill": {
     "duration": 0.152703,
     "end_time": "2024-03-13T19:01:09.456747",
     "exception": false,
     "start_time": "2024-03-13T19:01:09.304044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stage2 Score with SparK resnet50 Spectrogram = 0.5221973075437222\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "# === Pre-process OOF ===\n",
    "label_cols = CFG.target_cols\n",
    "gt = oof_df[[\"eeg_id\"] + CFG.target_cols]\n",
    "gt.sort_values(by=\"eeg_id\", inplace=True)\n",
    "gt.reset_index(inplace=True, drop=True)\n",
    "\n",
    "preds = oof_df[[\"eeg_id\"] + CFG.pred_cols]\n",
    "preds.columns = [\"eeg_id\"] + CFG.target_cols\n",
    "preds.sort_values(by=\"eeg_id\", inplace=True)\n",
    "preds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_trues = gt[CFG.target_cols]\n",
    "y_preds = preds[CFG.target_cols]\n",
    "\n",
    "oof = pd.DataFrame(y_preds.copy())\n",
    "oof['id'] = np.arange(len(oof))\n",
    "\n",
    "true = pd.DataFrame(y_trues.copy())\n",
    "true['id'] = np.arange(len(true))\n",
    "\n",
    "cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
    "print('CV Stage2 Score with SparK resnet50 Spectrogram =',cv)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4378712,
     "sourceId": 7517324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4216847,
     "sourceId": 7652061,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4525836,
     "sourceId": 7742867,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4537599,
     "sourceId": 7759456,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4527097,
     "sourceId": 7761629,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16280.6761,
   "end_time": "2024-03-13T19:01:14.890012",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-13T14:29:54.213912",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d15e1dcb93e4c908d6ccc3284ab708b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8bff78105a6d4a0189ef1f99d874dad0",
       "max": 21355344,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_97958e0025a545c889ab3b668a849e66",
       "value": 21355344
      }
     },
     "32a3700eb1704c80b8ebe0ed6ba62d9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3e2b6648baa74030a67879da61fea2a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3f264dc6ef324181bb3b789bd4bd98c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5873a4dc1a5b47d18bf3631218556f90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df593ad44d8f40d2b6ba2b2853e3122e",
       "placeholder": "​",
       "style": "IPY_MODEL_32a3700eb1704c80b8ebe0ed6ba62d9f",
       "value": " 21.4M/21.4M [00:00&lt;00:00, 67.2MB/s]"
      }
     },
     "783c0d71164b4f36af700965815ea0f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7bc09291414948319e962bee4ca151f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_783c0d71164b4f36af700965815ea0f4",
       "placeholder": "​",
       "style": "IPY_MODEL_3e2b6648baa74030a67879da61fea2a2",
       "value": "model.safetensors: 100%"
      }
     },
     "8bff78105a6d4a0189ef1f99d874dad0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97958e0025a545c889ab3b668a849e66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b5e38a4663fe4fde9eb76dcd29dcadb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7bc09291414948319e962bee4ca151f4",
        "IPY_MODEL_2d15e1dcb93e4c908d6ccc3284ab708b",
        "IPY_MODEL_5873a4dc1a5b47d18bf3631218556f90"
       ],
       "layout": "IPY_MODEL_3f264dc6ef324181bb3b789bd4bd98c8"
      }
     },
     "df593ad44d8f40d2b6ba2b2853e3122e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
