{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5904312",
   "metadata": {
    "papermill": {
     "duration": 0.0134,
     "end_time": "2024-03-05T12:01:40.527641",
     "exception": false,
     "start_time": "2024-03-05T12:01:40.514241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f82b4",
   "metadata": {
    "papermill": {
     "duration": 0.012318,
     "end_time": "2024-03-05T12:01:40.552706",
     "exception": false,
     "start_time": "2024-03-05T12:01:40.540388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook\n",
    "\n",
    "The goal of this notebook is to improve the results of the [notebook](https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43#Train-DataLoader) shared by @cdeotte and [@alejopaullier](https://www.kaggle.com/code/alejopaullier/hms-efficientnetb0-pytorch-train), please check them out great notebooks.\n",
    "\n",
    "\n",
    "**Important note**:\n",
    "\n",
    "I shared in the last days a [discussion](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/478474) which was an Improvement of this [notebook](https://www.kaggle.com/code/nischaydnk/hms-submission-1d-eegnet-pipeline-lightning) created by @nischaydnk. The tricks I used were notably changing the optimizer (I used Adan) and I used the two stage training as stated by @seanbearden [here](https://www.kaggle.com/code/seanbearden/effnetb0-2-pop-model-train-twice-lb-0-39) and not using downsampling which worked pretty well.\n",
    "But the two stage training an issue which is data leakage. The idea was to seperate the data with few votes because the kl will hardly penalize the model if it mislabel them. So in my previous experiments I use two groupkfold CV on the two datasets and the samples with few votes are present in both datasets.\n",
    "\n",
    "So in this notebook, I use one CV scheme and in each stage I filter the data then validate on the data that contains both population to prevent data leakage. Let me know in the comment if this approach is correct more info can be found [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477461).\n",
    "\n",
    "As stated [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477498), adding 0.166666667 to the targets will reduce the CV/LB gap.\n",
    "\n",
    "**Consider upvoting this notebook if you find it useful**\n",
    "\n",
    "## Version 1\n",
    "* I train a tf_efficientnet_b0_ns model.\n",
    "\n",
    "### Hyperparams\n",
    "\n",
    "```\n",
    "scheduler='OneCycleLR' \n",
    " # OneCycleLR params\n",
    "  cosanneal_res_params={\n",
    "      'T_0':20,\n",
    "      'eta_min':1e-6,\n",
    "      'T_mult':1,\n",
    "      'last_epoch':-1}\n",
    "  print_freq=50\n",
    "  num_workers = 1\n",
    "  model_name = 'tf_efficientnet_b0_ns'\n",
    "  optimizer='Adam'\n",
    "  stage1_epochs = 5\n",
    "  stage1_epochs = 6\n",
    "  eps = 1e-6\n",
    "  lr = 1e-3\n",
    "  batch_size = 64\n",
    "  weight_decay = 1e-2\n",
    "  seed = 2024\n",
    "```\n",
    "\n",
    "## Version2\n",
    "\n",
    "* I changed the CV sheme, first stage train on all data second stage train on data with `total_evaluators >= 10`\n",
    "* Added Time masking augmentation from [here](https://www.kaggle.com/code/iglovikov/xymasking-aug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13cca965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:01:40.578983Z",
     "iopub.status.busy": "2024-03-05T12:01:40.578688Z",
     "iopub.status.idle": "2024-03-05T12:01:58.315529Z",
     "shell.execute_reply": "2024-03-05T12:01:58.314361Z"
    },
    "papermill": {
     "duration": 17.752859,
     "end_time": "2024-03-05T12:01:58.318157",
     "exception": false,
     "start_time": "2024-03-05T12:01:40.565298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.3.1)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-1.4.1-py3-none-any.whl.metadata (36 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.24.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.22.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.9.0)\r\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\r\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.9.0.80)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.2.1)\r\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (9.5.0)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2023.12.9)\r\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\r\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.2->albumentations) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.2->albumentations) (3.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.1.1)\r\n",
      "Downloading albumentations-1.4.1-py3-none-any.whl (130 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, albumentations\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.3.1\r\n",
      "    Uninstalling albumentations-1.3.1:\r\n",
      "      Successfully uninstalled albumentations-1.3.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed albumentations-1.4.1 scikit-learn-1.4.1.post1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6369d828",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:01:58.349402Z",
     "iopub.status.busy": "2024-03-05T12:01:58.349076Z",
     "iopub.status.idle": "2024-03-05T12:01:58.355567Z",
     "shell.execute_reply": "2024-03-05T12:01:58.354714Z"
    },
    "papermill": {
     "duration": 0.024855,
     "end_time": "2024-03-05T12:01:58.357607",
     "exception": false,
     "start_time": "2024-03-05T12:01:58.332752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# directory settings\n",
    "# ====================================================\n",
    "\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "POP_2_DIR = OUTPUT_DIR + 'pop_2_weight_oof/'\n",
    "if not os.path.exists(POP_2_DIR):\n",
    "    os.makedirs(POP_2_DIR)\n",
    "    \n",
    "POP_1_DIR = OUTPUT_DIR + 'pop_1_weight_oof/'\n",
    "# POP_1_DIR = '/kaggle/input/mixmodel-weights/' + 'pop_1_weight_oof/' \n",
    "if not os.path.exists(POP_1_DIR):\n",
    "    os.makedirs(POP_1_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71ca6a",
   "metadata": {
    "papermill": {
     "duration": 0.013886,
     "end_time": "2024-03-05T12:01:58.385778",
     "exception": false,
     "start_time": "2024-03-05T12:01:58.371892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a978a362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:01:58.415300Z",
     "iopub.status.busy": "2024-03-05T12:01:58.415032Z",
     "iopub.status.idle": "2024-03-05T12:02:11.272924Z",
     "shell.execute_reply": "2024-03-05T12:02:11.272008Z"
    },
    "papermill": {
     "duration": 12.875725,
     "end_time": "2024-03-05T12:02:11.275727",
     "exception": false,
     "start_time": "2024-03-05T12:01:58.400002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
    "from kaggle_kl_div import score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations import (Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "import timm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "VERSION=2\n",
    "\n",
    "MEAN = torch.load('/kaggle/input/mean-and-std-spectrograms/mean.pt').numpy()\n",
    "STD = torch.load('/kaggle/input/mean-and-std-spectrograms/std_dev.pt').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5c1d4",
   "metadata": {
    "papermill": {
     "duration": 0.016299,
     "end_time": "2024-03-05T12:02:11.313702",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.297403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee523f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:02:11.343977Z",
     "iopub.status.busy": "2024-03-05T12:02:11.343337Z",
     "iopub.status.idle": "2024-03-05T12:02:11.352873Z",
     "shell.execute_reply": "2024-03-05T12:02:11.352056Z"
    },
    "papermill": {
     "duration": 0.027336,
     "end_time": "2024-03-05T12:02:11.355403",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.328067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "\n",
    "class CFG:\n",
    "    wandb = False\n",
    "    debug = False\n",
    "    train=True\n",
    "    apex=True\n",
    "    stage1_pop1=True\n",
    "    stage2_pop2=False\n",
    "    VISUALIZE=True\n",
    "    FREEZE=False\n",
    "    SparK=False\n",
    "    scheduler='OneCycleLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n",
    "    # CosineAnnealingLR params\n",
    "    cosanneal_params={\n",
    "        'T_max':6,\n",
    "        'eta_min':1e-5,\n",
    "        'last_epoch':-1\n",
    "    }\n",
    "    #ReduceLROnPlateau params\n",
    "    reduce_params={\n",
    "        'mode':'min',\n",
    "        'factor':0.2,\n",
    "        'patience':4,\n",
    "        'eps':1e-6,\n",
    "        'verbose':True\n",
    "    }\n",
    "    # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1\n",
    "    }\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'tf_efficientnet_b0_ns'\n",
    "    optimizer='Adan'\n",
    "    epochs = 5\n",
    "    factor = 0.9\n",
    "    patience = 2\n",
    "    eps = 1e-6\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 64\n",
    "    weight_decay = 1e-2\n",
    "    batch_scheduler=True\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1e7\n",
    "    seed = 2024\n",
    "    target_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    target_size = 6\n",
    "    num_channels = 8\n",
    "    pred_cols = ['pred_seizure_vote', 'pred_lpd_vote', 'pred_gpd_vote', 'pred_lrda_vote', 'pred_grda_vote', 'pred_other_vote']\n",
    "    n_fold = 5\n",
    "    trn_fold = [0, 1, 2, 3, 4]\n",
    "    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n",
    "    data_root = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n",
    "    raw_eeg_path = \"/kaggle/input/brain-eegs/eegs.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252c04b",
   "metadata": {
    "papermill": {
     "duration": 0.01388,
     "end_time": "2024-03-05T12:02:11.385013",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.371133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46adf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:02:11.414899Z",
     "iopub.status.busy": "2024-03-05T12:02:11.414608Z",
     "iopub.status.idle": "2024-03-05T12:02:11.430958Z",
     "shell.execute_reply": "2024-03-05T12:02:11.430173Z"
    },
    "papermill": {
     "duration": 0.03349,
     "end_time": "2024-03-05T12:02:11.432910",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.399420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def get_score(preds, targets):\n",
    "    oof = pd.DataFrame(preds.copy())\n",
    "    oof['id'] = np.arange(len(oof))\n",
    "\n",
    "    true = pd.DataFrame(targets.copy())\n",
    "    true['id'] = np.arange(len(true))\n",
    "\n",
    "    cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
    "    return cv\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Sample rate and desired cutoff frequencies (in Hz).\n",
    "    fs = 200.0\n",
    "    lowcut = 1.0\n",
    "    highcut = 25.0\n",
    "    \n",
    "    # Filter a noisy signal.\n",
    "    T = 50\n",
    "    nsamples = T * fs\n",
    "    t = np.arange(0, nsamples) / fs\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n",
    "    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n",
    "    y = y[0:-1:4]\n",
    "    \n",
    "    return y\n",
    "\n",
    "class KLDivLossWithLogits(nn.KLDivLoss):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        y = nn.functional.log_softmax(y,  dim=1)\n",
    "        loss = super().forward(y, t)\n",
    "\n",
    "        return loss\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915a712",
   "metadata": {
    "papermill": {
     "duration": 0.014119,
     "end_time": "2024-03-05T12:02:11.461230",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.447111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc11069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:02:11.490844Z",
     "iopub.status.busy": "2024-03-05T12:02:11.490610Z",
     "iopub.status.idle": "2024-03-05T12:02:11.768741Z",
     "shell.execute_reply": "2024-03-05T12:02:11.767523Z"
    },
    "papermill": {
     "duration": 0.295657,
     "end_time": "2024-03-05T12:02:11.770881",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.475224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (106800, 15)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "There are 1950 patients in the training data.\n",
      "There are 17089 EEG IDs in the training data.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
    "TARGETS = train.columns[-6:]\n",
    "print('Train shape:', train.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "train['total_evaluators'] = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n",
    "\n",
    "print(f'There are {train.patient_id.nunique()} patients in the training data.')\n",
    "print(f'There are {train.eeg_id.nunique()} EEG IDs in the training data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e04a50f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:02:11.801757Z",
     "iopub.status.busy": "2024-03-05T12:02:11.801096Z",
     "iopub.status.idle": "2024-03-05T12:02:12.066543Z",
     "shell.execute_reply": "2024-03-05T12:02:12.065697Z"
    },
    "papermill": {
     "duration": 0.283194,
     "end_time": "2024-03-05T12:02:12.068672",
     "exception": false,
     "start_time": "2024-03-05T12:02:11.785478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa3f329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:02:12.099918Z",
     "iopub.status.busy": "2024-03-05T12:02:12.099384Z",
     "iopub.status.idle": "2024-03-05T12:03:18.299741Z",
     "shell.execute_reply": "2024-03-05T12:03:18.298766Z"
    },
    "papermill": {
     "duration": 66.232616,
     "end_time": "2024-03-05T12:03:18.316254",
     "exception": false,
     "start_time": "2024-03-05T12:02:12.083638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.74 s, sys: 6.07 s, total: 8.81 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a18e0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:03:18.348674Z",
     "iopub.status.busy": "2024-03-05T12:03:18.348028Z",
     "iopub.status.idle": "2024-03-05T12:04:51.972011Z",
     "shell.execute_reply": "2024-03-05T12:04:51.971021Z"
    },
    "papermill": {
     "duration": 93.657859,
     "end_time": "2024-03-05T12:04:51.989243",
     "exception": false,
     "start_time": "2024-03-05T12:03:18.331384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.23 s, sys: 9.87 s, total: 15.1 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_eegs = np.load('/kaggle/input/eeg-spectrogram-by-lead-id-unique/eeg_specs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154ff3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:04:52.020660Z",
     "iopub.status.busy": "2024-03-05T12:04:52.020138Z",
     "iopub.status.idle": "2024-03-05T12:04:52.030102Z",
     "shell.execute_reply": "2024-03-05T12:04:52.029273Z"
    },
    "papermill": {
     "duration": 0.027721,
     "end_time": "2024-03-05T12:04:52.032071",
     "exception": false,
     "start_time": "2024-03-05T12:04:52.004350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "def eeg_from_parquet(parquet_path, display=False):\n",
    "    \n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-SAMPLES)//2\n",
    "    eeg = eeg.iloc[offset:offset+SAMPLES]\n",
    "    \n",
    "    if display: \n",
    "        plt.figure(figsize=(10,5))\n",
    "        offset = 0\n",
    "    \n",
    "    # CONVERT TO NUMPY\n",
    "    data = np.zeros((SAMPLES,len(FEATS)))\n",
    "    for j,col in enumerate(FEATS):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        # Downsampling from 200 Hz to 100 Hz\n",
    "        downsampled_x = scipy.signal.resample(x, SAMPLES)\n",
    "        data[:, j] = downsampled_x\n",
    "        \n",
    "        if display: \n",
    "            if j!=0: offset += x.max()\n",
    "            plt.plot(range(SAMPLES),x-offset,label=col)\n",
    "            offset -= x.min()\n",
    "            \n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split('/')[-1]\n",
    "        name = name.split('.')[0]\n",
    "        plt.title(f'EEG {name}',size=16)\n",
    "        plt.show()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87d6f3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:04:52.063610Z",
     "iopub.status.busy": "2024-03-05T12:04:52.062789Z",
     "iopub.status.idle": "2024-03-05T12:06:05.511759Z",
     "shell.execute_reply": "2024-03-05T12:06:05.510886Z"
    },
    "papermill": {
     "duration": 73.467495,
     "end_time": "2024-03-05T12:06:05.514223",
     "exception": false,
     "start_time": "2024-03-05T12:04:52.046728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLES = 5_000\n",
    "CREATE_EEGS = False\n",
    "FEATS = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS,range(len(FEATS)))}\n",
    "\n",
    "raw_eegs = {}\n",
    "DISPLAY = 4\n",
    "EEG_IDS = train.eeg_id.unique()\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/'\n",
    "            \n",
    "if CREATE_EEGS: \n",
    "    for i,eeg_id in enumerate(EEG_IDS):\n",
    "        if (i%100==0)&(i!=0): print(i,', ',end='') \n",
    "\n",
    "        # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n",
    "        data = eeg_from_parquet(f'{PATH}{eeg_id}.parquet', display=i<DISPLAY)              \n",
    "        raw_eegs[eeg_id] = data\n",
    "\n",
    "        if i==DISPLAY:\n",
    "            if CREATE_EEGS:\n",
    "                print(f'Processing {train.eeg_id.nunique()} eeg parquets... ',end='')\n",
    "            else:\n",
    "                print(f'Reading {len(EEG_IDS)} eeg NumPys from disk.')\n",
    "                break\n",
    "    \n",
    "    np.save('eegs',raw_eegs)\n",
    "else:\n",
    "    raw_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd5e2e1",
   "metadata": {
    "papermill": {
     "duration": 0.015321,
     "end_time": "2024-03-05T12:06:05.545220",
     "exception": false,
     "start_time": "2024-03-05T12:06:05.529899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deduplicate Train EEG Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d07d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:05.576282Z",
     "iopub.status.busy": "2024-03-05T12:06:05.575967Z",
     "iopub.status.idle": "2024-03-05T12:06:06.046997Z",
     "shell.execute_reply": "2024-03-05T12:06:06.045946Z"
    },
    "papermill": {
     "duration": 0.489742,
     "end_time": "2024-03-05T12:06:06.049896",
     "exception": false,
     "start_time": "2024-03-05T12:06:05.560154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train[train['label_id'].isin(all_eegs.keys())].copy()\n",
    "\n",
    "y_data = train[TARGETS].values +  0.166666667 # Regularization value\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "train['target'] = train['expert_consensus']\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "del y_data\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2ac71",
   "metadata": {
    "papermill": {
     "duration": 0.015132,
     "end_time": "2024-03-05T12:06:06.080606",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.065474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468cf86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.155103Z",
     "iopub.status.busy": "2024-03-05T12:06:06.154738Z",
     "iopub.status.idle": "2024-03-05T12:06:06.379673Z",
     "shell.execute_reply": "2024-03-05T12:06:06.378857Z"
    },
    "papermill": {
     "duration": 0.286139,
     "end_time": "2024-03-05T12:06:06.381946",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.095807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_fold)\n",
    "\n",
    "train[\"fold\"] = -1\n",
    "\n",
    "for fold_id, (_, val_idx) in enumerate(\n",
    "    gkf.split(train, y=train[\"target\"], groups=train[\"patient_id\"])\n",
    "):\n",
    "    train.loc[val_idx, \"fold\"] = fold_id\n",
    "    \n",
    "del gkf\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34a9e6",
   "metadata": {
    "papermill": {
     "duration": 0.015347,
     "end_time": "2024-03-05T12:06:06.413645",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.398298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425fc92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.446012Z",
     "iopub.status.busy": "2024-03-05T12:06:06.445322Z",
     "iopub.status.idle": "2024-03-05T12:06:06.452801Z",
     "shell.execute_reply": "2024-03-05T12:06:06.451987Z"
    },
    "papermill": {
     "duration": 0.025777,
     "end_time": "2024-03-05T12:06:06.454677",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.428900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(\n",
    "#         self, df: pd.DataFrame,\n",
    "#         augment: bool = False, mode: str = 'train',\n",
    "#         specs: Dict[int, np.ndarray] = spectrograms,\n",
    "#         eeg_specs: Dict[int, np.ndarray] = all_eegs\n",
    "#     ): \n",
    "#         self.df = df\n",
    "#         self.augment = augment\n",
    "#         self.mode = mode\n",
    "#         self.spectograms = spectrograms\n",
    "#         self.eeg_spectograms = eeg_specs\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         \"\"\"\n",
    "#         Denotes the number of batches per epoch.\n",
    "#         \"\"\"\n",
    "#         return len(self.df)\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         \"\"\"\n",
    "#         Generate one batch of data.\n",
    "#         \"\"\"\n",
    "#         X, y = self.__data_generation(index)\n",
    "#         if self.augment:\n",
    "#             X = self.__transform(X) \n",
    "#         return {\"spectrogram\":torch.tensor(X, dtype=torch.float32), \"labels\":torch.tensor(y, dtype=torch.float32)}\n",
    "                        \n",
    "#     def __data_generation(self, index):\n",
    "#         \"\"\"\n",
    "#         Generates data containing batch_size samples.\n",
    "#         \"\"\"\n",
    "#         X = np.zeros((128, 256, 8), dtype='float32')\n",
    "#         y = np.zeros(6, dtype='float32')\n",
    "#         img = np.ones((128,256), dtype='float32')\n",
    "#         row = self.df.iloc[index]\n",
    "#         if self.mode=='test': \n",
    "#             r = 0\n",
    "#         else: \n",
    "#             r = int(row['spectrogram_label_offset_seconds'] // 2)\n",
    "            \n",
    "#         for region in range(4):\n",
    "#             img = self.spectograms[row.spectrogram_id][r:r+300, region*100:(region+1)*100].T\n",
    "            \n",
    "#             # Log transform spectogram\n",
    "#             img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "#             img = np.log(img)\n",
    "\n",
    "# #             # Standarize per image\n",
    "# #             ep = 1e-6\n",
    "# #             mu = np.nanmean(img.flatten())\n",
    "# #             std = np.nanstd(img.flatten())\n",
    "# #             img = (img-mu)/(std+ep)\n",
    "#             img = np.nan_to_num(img, nan=0.0)\n",
    "#             X[14:-14, :, region] = img[:, 22:-22] / 2.0\n",
    "#             img = self.eeg_spectograms[row.label_id]\n",
    "#             X[:, :, 4:] = img\n",
    "            \n",
    "#         if self.mode != 'test':\n",
    "#             y = row[TARGETS].values.astype(np.float32)\n",
    "        \n",
    "#         ep = 1e-6\n",
    "#         X = (X - MEAN) / (STD+ep)\n",
    "#         X = np.nan_to_num(X, nan=0.0)\n",
    "        \n",
    "#         return X, y\n",
    "    \n",
    "#     def __transform(self, img):\n",
    "#         params1 = {\n",
    "#                     \"num_masks_x\": 1,    \n",
    "#                     \"mask_x_length\": (0, 20), # This line changed from fixed  to a range\n",
    "#                     \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),\n",
    "#                     }\n",
    "#         params2 = {    \n",
    "#                     \"num_masks_y\": 1,    \n",
    "#                     \"mask_y_length\": (0, 20),\n",
    "#                     \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),    \n",
    "#                     }\n",
    "#         params3 = {    \n",
    "#                     \"num_masks_x\": (2, 4),\n",
    "#                     \"num_masks_y\": 5,    \n",
    "#                     \"mask_y_length\": 8,\n",
    "#                     \"mask_x_length\": (10, 20),\n",
    "#                     \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),  \n",
    "#                     }\n",
    "        \n",
    "#         transforms = A.Compose([\n",
    "#             A.XYMasking(**params1, p=0.3),\n",
    "#             A.XYMasking(**params2, p=0.3),\n",
    "#             A.XYMasking(**params3, p=0.3),\n",
    "#         ])\n",
    "#         return transforms(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b42013f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.486698Z",
     "iopub.status.busy": "2024-03-05T12:06:06.486374Z",
     "iopub.status.idle": "2024-03-05T12:06:06.514771Z",
     "shell.execute_reply": "2024-03-05T12:06:06.514136Z"
    },
    "papermill": {
     "duration": 0.046401,
     "end_time": "2024-03-05T12:06:06.516544",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.470143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    # bins = np.linspace(-1, 1, classes)\n",
    "    # quantized = np.digitize(mu_x, bins) - 1\n",
    "    return mu_x#quantized\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame,\n",
    "        augment: bool = False, mode: str = 'train',\n",
    "        specs: Dict[int, np.ndarray] = spectrograms,\n",
    "        eeg_specs: Dict[int, np.ndarray] = all_eegs,\n",
    "        eegs: Dict[int, np.ndarray] = raw_eegs\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.spectograms = specs\n",
    "        self.eeg_spectograms = eeg_specs\n",
    "        self.eegs = eegs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        # Processing EEG signal data\n",
    "        eeg_data = self.eegs[row.eeg_id]\n",
    "        sample = np.zeros((eeg_data.shape[0], 8))  # Assuming eeg_data.shape[1] == 8 for 8 channels\n",
    "        FEAT2IDX = {'Fp1': 0, 'T3': 1, 'C3': 2, 'O1': 3, 'Fp2': 4, 'C4': 5, 'T4': 6, 'O2': 7}\n",
    "        \n",
    "        # Compute differences\n",
    "        for i, (start, end) in enumerate([('Fp1', 'T3'), ('T3', 'O1'), ('Fp1', 'C3'), ('C3', 'O1'), \n",
    "                                          ('Fp2', 'C4'), ('C4', 'O2'), ('Fp2', 'T4'), ('T4', 'O2')]):\n",
    "            sample[:, i] = eeg_data[:, FEAT2IDX[start]] - eeg_data[:, FEAT2IDX[end]]\n",
    "        \n",
    "        sample = self.process_sample(sample)\n",
    "        \n",
    "        samples = torch.from_numpy(sample).float()\n",
    "        samples = samples.permute(1, 0)\n",
    "        \n",
    "        # Processing spectrogram data\n",
    "        spec = self.__spec_data_generation(row)\n",
    "        if self.augment:\n",
    "            spec = self.__transform_2d(spec) \n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            label = row[TARGETS]  # Assuming 'TARGETS' is defined somewhere as the label column name\n",
    "            label = torch.tensor(label).float()  \n",
    "            return samples, spec, label\n",
    "        else:\n",
    "            return samples, spec\n",
    "    \n",
    "    def process_sample(self, sample):\n",
    "        # Normalize the sample data\n",
    "        sample = (sample - np.mean(sample, axis=0)) / np.std(sample, axis=0)  # Possibly make this global\n",
    "        sample = np.clip(sample, -1024, 1024)\n",
    "        sample = np.nan_to_num(sample, nan=0)\n",
    "        sample = butter_bandpass_filter(sample, 0.5, 25, 100) # Change is the downsampling is changed\n",
    "        sample = quantize_data(sample, 1)\n",
    "        return sample\n",
    "\n",
    "    def __spec_data_generation(self, row):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples. This method directly\n",
    "        uses class attributes for spectrograms and EEG spectrograms.\n",
    "        \"\"\"\n",
    "        X = np.zeros((128, 256, 8), dtype='float32')        \n",
    "        if self.mode != 'test':\n",
    "            # Assuming your DataFrame has a column that combines min and max values for slicing\n",
    "            r = int(row['spectrogram_label_offset_seconds'] // 2)\n",
    "        else:\n",
    "            r = 0  # Adjust as necessary for test mode\n",
    "        \n",
    "        for region in range(4):\n",
    "            img = self.spectograms[row.spectrogram_id][r:r+300, region*100:(region+1)*100].T\n",
    "            \n",
    "            # Log transform spectogram\n",
    "            img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "            img = np.log(img)\n",
    "            \n",
    "#             ep = 1e-6\n",
    "#             mu = np.nanmean(img.flatten())\n",
    "#             std = np.nanstd(img.flatten())\n",
    "#             img = (img-mu)/(std+ep)\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n",
    "            img = self.eeg_spectograms[row.label_id]\n",
    "            X[:, :, 4:] = img\n",
    "            \n",
    "        ep = 1e-6\n",
    "        X = (X - MEAN) / (STD+ep)\n",
    "        X = np.nan_to_num(X, nan=0.0)\n",
    "                 \n",
    "        return X\n",
    "\n",
    "    def __transform_2d(self, img):\n",
    "        params1 = {\n",
    "                    \"num_masks_x\": 1,    \n",
    "                    \"mask_x_length\": (0, 20), # This line changed from fixed  to a range\n",
    "                    \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),\n",
    "                    }\n",
    "        params2 = {    \n",
    "                    \"num_masks_y\": 1,    \n",
    "                    \"mask_y_length\": (0, 20),\n",
    "                    \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),    \n",
    "                    }\n",
    "        params3 = {    \n",
    "                    \"num_masks_x\": (2, 4),\n",
    "                    \"num_masks_y\": 5,    \n",
    "                    \"mask_y_length\": 8,\n",
    "                    \"mask_x_length\": (10, 20),\n",
    "                    \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),  \n",
    "                    }\n",
    "        \n",
    "        transforms = A.Compose([\n",
    "            A.XYMasking(**params1, p=0.3),\n",
    "            A.XYMasking(**params2, p=0.3),\n",
    "            A.XYMasking(**params3, p=0.3),\n",
    "        ])\n",
    "        return transforms(image=img)['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccac348",
   "metadata": {
    "papermill": {
     "duration": 0.015066,
     "end_time": "2024-03-05T12:06:06.547010",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.531944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8831c84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.578945Z",
     "iopub.status.busy": "2024-03-05T12:06:06.578451Z",
     "iopub.status.idle": "2024-03-05T12:06:06.582593Z",
     "shell.execute_reply": "2024-03-05T12:06:06.581755Z"
    },
    "papermill": {
     "duration": 0.022317,
     "end_time": "2024-03-05T12:06:06.584807",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.562490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = CustomDataset(train, augment=False, mode=\"train\")\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# batch = dataset[4]\n",
    "# X, y = batch[\"spectrogram\"], batch[\"labels\"]\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# plt.imshow(X[:,:,0])\n",
    "\n",
    "# del dataset, X, y\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c600d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.616924Z",
     "iopub.status.busy": "2024-03-05T12:06:06.616218Z",
     "iopub.status.idle": "2024-03-05T12:06:06.620782Z",
     "shell.execute_reply": "2024-03-05T12:06:06.619993Z"
    },
    "papermill": {
     "duration": 0.022614,
     "end_time": "2024-03-05T12:06:06.622723",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.600109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = CustomDataset(train, augment=False, mode=\"train\")\n",
    "# dataloader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# batch = dataset[0]\n",
    "# X, y = batch[\"spectrogram\"], batch[\"labels\"]\n",
    "\n",
    "# total_sum_mean = torch.zeros(X.shape)\n",
    "# total_samples_mean = 0\n",
    "\n",
    "# total_sum_var = torch.zeros(X.shape)\n",
    "# total_samples_var = 0\n",
    "\n",
    "# for i, batch in enumerate(dataloader):\n",
    "#     if i%10==0: print(i, end=\", \")\n",
    "#     X = batch[\"spectrogram\"]\n",
    "    \n",
    "#     total_sum_mean += torch.sum(X, dim=0)\n",
    "#     total_samples_mean += X.size(0)\n",
    "\n",
    "# # Compute mean\n",
    "# mean = total_sum_mean / total_samples_mean\n",
    "# torch.save(mean, 'mean.pt')\n",
    "\n",
    "# for i, batch in enumerate(dataloader):\n",
    "#     if i%10==0: print(i, end=\", \")\n",
    "#     X = batch[\"spectrogram\"]\n",
    "    \n",
    "#     total_sum_var += torch.sum((X - mean) ** 2, dim=0)\n",
    "#     total_samples_var += X.size(0)\n",
    "    \n",
    "# std_dev = torch.sqrt(total_sum_var / total_samples_var)\n",
    "# torch.save(std_dev, 'std_dev.pt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87af927d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.654658Z",
     "iopub.status.busy": "2024-03-05T12:06:06.654404Z",
     "iopub.status.idle": "2024-03-05T12:06:06.928107Z",
     "shell.execute_reply": "2024-03-05T12:06:06.927133Z"
    },
    "papermill": {
     "duration": 0.292479,
     "end_time": "2024-03-05T12:06:06.930297",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.637818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples shape: torch.Size([8, 5000])\n",
      "Spec shape: (128, 256, 8)\n",
      "Label shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "dataset = EEGDataset(train, augment=True, mode=\"train\")\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "samples, spec, label = dataset[0]\n",
    "\n",
    "print(f\"Samples shape: {samples.shape}\")\n",
    "print(f\"Spec shape: {spec.shape}\")\n",
    "print(f\"Label shape: {label.shape}\")\n",
    "\n",
    "del dataset, samples, spec, label\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1305e756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:06.962984Z",
     "iopub.status.busy": "2024-03-05T12:06:06.962677Z",
     "iopub.status.idle": "2024-03-05T12:06:06.967346Z",
     "shell.execute_reply": "2024-03-05T12:06:06.966523Z"
    },
    "papermill": {
     "duration": 0.02323,
     "end_time": "2024-03-05T12:06:06.969322",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.946092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if CFG.VISUALIZE:\n",
    "#     ROWS = 2\n",
    "#     COLS = 3\n",
    "#     for batch in dataloader:\n",
    "#         X, y = batch[\"spectrogram\"], batch[\"labels\"]\n",
    "#         plt.figure(figsize=(20,8))\n",
    "#         for row in range(ROWS):\n",
    "#             for col in range(COLS):\n",
    "#                 plt.subplot(ROWS, COLS, row*COLS + col+1)\n",
    "#                 t = y[row*COLS + col]\n",
    "#                 img = X[row*COLS + col, :, :, 0]\n",
    "#                 mn = img.flatten().min()\n",
    "#                 mx = img.flatten().max()\n",
    "#                 img = (img-mn)/(mx-mn)\n",
    "#                 plt.imshow(img)\n",
    "#                 tars = f'[{t[0]:0.2f}'\n",
    "#                 for s in t[1:]:\n",
    "#                     tars += f', {s:0.2f}'\n",
    "#                 eeg = train.eeg_id.values[row*CFG.batch_size + row*COLS + col]\n",
    "#                 plt.title(f'EEG = {eeg}\\nTarget = {tars}',size=12)\n",
    "#                 plt.yticks([])\n",
    "#                 plt.ylabel('Frequencies (Hz)',size=14)\n",
    "#                 plt.xlabel('Time (sec)',size=16)\n",
    "#         plt.show()\n",
    "#         break\n",
    "        \n",
    "# del dataloader\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9df7cc",
   "metadata": {
    "papermill": {
     "duration": 0.015109,
     "end_time": "2024-03-05T12:06:06.999731",
     "exception": false,
     "start_time": "2024-03-05T12:06:06.984622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f033f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:07.031922Z",
     "iopub.status.busy": "2024-03-05T12:06:07.031275Z",
     "iopub.status.idle": "2024-03-05T12:06:07.036671Z",
     "shell.execute_reply": "2024-03-05T12:06:07.035882Z"
    },
    "papermill": {
     "duration": 0.023504,
     "end_time": "2024-03-05T12:06:07.038534",
     "exception": false,
     "start_time": "2024-03-05T12:06:07.015030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CustomModel(nn.Module):\n",
    "#     def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.USE_KAGGLE_SPECTROGRAMS = True\n",
    "#         self.USE_EEG_SPECTROGRAMS = True\n",
    "#         self.model = timm.create_model(\n",
    "#             config.model_name,\n",
    "#             pretrained=pretrained,\n",
    "#         )\n",
    "#         if config.FREEZE:\n",
    "#             for i,(name, param) in enumerate(list(self.model.named_parameters())\\\n",
    "#                                              [0:config.NUM_FROZEN_LAYERS]):\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#         self.features = nn.Sequential(*list(self.model.children())[:-2])\n",
    "#         self.custom_layers = nn.Sequential(\n",
    "#             nn.AdaptiveAvgPool2d(1),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(self.model.num_features, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def __reshape_input(self, x):\n",
    "#         \"\"\"\n",
    "#         Reshapes input (128, 256, 8) -> (512, 512, 3) monotone image.\n",
    "#         \"\"\" \n",
    "#         # === Get spectograms ===\n",
    "#         spectograms = [x[:, :, :, i:i+1] for i in range(4)]\n",
    "#         spectograms = torch.cat(spectograms, dim=1)\n",
    "        \n",
    "#         # === Get EEG spectograms ===\n",
    "#         eegs = [x[:, :, :, i:i+1] for i in range(4,8)]\n",
    "#         eegs = torch.cat(eegs, dim=1)\n",
    "        \n",
    "#         # === Reshape (512,512,3) ===\n",
    "#         if self.USE_KAGGLE_SPECTROGRAMS & self.USE_EEG_SPECTROGRAMS:\n",
    "#             x = torch.cat([spectograms, eegs], dim=2)\n",
    "#         elif self.USE_EEG_SPECTROGRAMS:\n",
    "#             x = eegs\n",
    "#         else:\n",
    "#             x = spectograms\n",
    "            \n",
    "#         x = torch.cat([x,x,x], dim=3)\n",
    "#         x = x.permute(0, 3, 1, 2)\n",
    "#         return x\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.__reshape_input(x)\n",
    "#         x = self.features(x)\n",
    "#         x = self.custom_layers(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3d3d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:07.070797Z",
     "iopub.status.busy": "2024-03-05T12:06:07.070557Z",
     "iopub.status.idle": "2024-03-05T12:06:07.113669Z",
     "shell.execute_reply": "2024-03-05T12:06:07.113013Z"
    },
    "papermill": {
     "duration": 0.061598,
     "end_time": "2024-03-05T12:06:07.115420",
     "exception": false,
     "start_time": "2024-03-05T12:06:07.053822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _WaveBlock(nn.Module):\n",
    "    \"\"\"WaveNet block.\n",
    "\n",
    "    Args:\n",
    "        kernel_size: kernel size, pass a list of kernel sizes for\n",
    "            inception\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers: int, \n",
    "        in_dim: int,\n",
    "        h_dim: int,\n",
    "        kernel_size: Union[int, List[int]],\n",
    "        conv_module: Optional[Type[nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.dilation_rates = [2**l for l in range(n_layers)]\n",
    "\n",
    "        self.in_conv = nn.Conv2d(in_dim, h_dim, kernel_size=(1, 1)) \n",
    "        self.gated_tcns = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        for layer in range(n_layers):\n",
    "            c_in, c_out = h_dim, h_dim\n",
    "            self.gated_tcns.append(\n",
    "                _GatedTCN(\n",
    "                    in_dim=c_in,\n",
    "                    h_dim=c_out,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation_factor=self.dilation_rates[layer],\n",
    "                    conv_module=conv_module,\n",
    "                )\n",
    "            )\n",
    "            self.skip_convs.append(nn.Conv2d(h_dim, h_dim, kernel_size=(1, 1)))\n",
    "\n",
    "        # Initialize parameters\n",
    "        nn.init.xavier_uniform_(self.in_conv.weight, gain=nn.init.calculate_gain(\"relu\"))\n",
    "        nn.init.zeros_(self.in_conv.bias)\n",
    "        for i in range(len(self.skip_convs)):\n",
    "            nn.init.xavier_uniform_(self.skip_convs[i].weight, gain=nn.init.calculate_gain(\"relu\"))\n",
    "            nn.init.zeros_(self.skip_convs[i].bias)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Shape:\n",
    "            x: (B, C, N, L), where C denotes in_dim\n",
    "            x_skip: (B, C', N, L), where C' denotes h_dim\n",
    "        \"\"\"\n",
    "        # Input convolution\n",
    "        x = self.in_conv(x)\n",
    "\n",
    "        x_skip = x\n",
    "        for layer in range(self.n_layers):\n",
    "            x = self.gated_tcns[layer](x)\n",
    "            x = self.skip_convs[layer](x)\n",
    "\n",
    "            # Skip-connection\n",
    "            x_skip = x_skip + x \n",
    "\n",
    "        return x_skip\n",
    "\n",
    "\n",
    "class _GatedTCN(nn.Module):\n",
    "    \"\"\"Gated temporal convolution layer.\n",
    "\n",
    "    Parameters:\n",
    "        conv_module: customized convolution module\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        h_dim: int,\n",
    "        kernel_size: Union[int, List[int]],\n",
    "        dilation_factor: int,\n",
    "        dropout: Optional[float] = None,\n",
    "        conv_module: Optional[Type[nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Model blocks\n",
    "        if conv_module is None:\n",
    "            self.filt = nn.Conv2d(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=(1, kernel_size), dilation=dilation_factor\n",
    "            )\n",
    "            self.gate = nn.Conv2d(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=(1, kernel_size), dilation=dilation_factor\n",
    "            )\n",
    "        else:\n",
    "            self.filt = conv_module(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=kernel_size, dilation=dilation_factor\n",
    "            )\n",
    "            self.gate = conv_module(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=kernel_size, dilation=dilation_factor\n",
    "            )\n",
    "\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters:\n",
    "            x: input sequence\n",
    "\n",
    "        Return:\n",
    "            h: output sequence\n",
    "\n",
    "        Shape:\n",
    "            x: (B, C, N, L), where L denotes the input sequence length\n",
    "            h: (B, h_dim, N, L')\n",
    "        \"\"\"\n",
    "        x_filt = F.tanh(self.filt(x))\n",
    "        x_gate = F.sigmoid(self.gate(x))\n",
    "        h = x_filt * x_gate\n",
    "        if self.dropout is not None:\n",
    "            h = self.dropout(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class _DilatedInception(nn.Module):\n",
    "    \"\"\"Dilated inception layer.\n",
    "\n",
    "    Note that `out_channels` will be split across #kernels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        kernel_size: List[int], \n",
    "        dilation: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Network parameters\n",
    "        n_kernels = len(kernel_size)\n",
    "        assert out_channels % n_kernels == 0, \"`out_channels` must be divisible by #kernels.\"\n",
    "        h_dim = out_channels // n_kernels\n",
    "\n",
    "        # Model blocks\n",
    "        self.convs = nn.ModuleList()\n",
    "        for k in kernel_size:\n",
    "            self.convs.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels, \n",
    "                    out_channels=h_dim, \n",
    "                    kernel_size=(1, k),\n",
    "                    padding=\"same\",\n",
    "                    dilation=dilation),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters:\n",
    "            x: input sequence\n",
    "\n",
    "        Return:\n",
    "            h: output sequence\n",
    "\n",
    "        Shape:\n",
    "            x: (B, C, N, L), where C = in_channels\n",
    "            h: (B, C', N, L'), where C' = out_channels\n",
    "        \"\"\"\n",
    "        x_convs = []\n",
    "        for conv in self.convs:\n",
    "            x_conv = conv(x)\n",
    "            x_convs.append(x_conv)\n",
    "        h = torch.cat(x_convs, dim=1)\n",
    "\n",
    "        return h\n",
    "    \n",
    "\n",
    "class EEGMegaNet(nn.Module):\n",
    "\n",
    "    def __init__(self, backbone_2d,in_channels_2d, pretrained=True, in_channels=20, num_classes=6):\n",
    "        super(EEGMegaNet, self).__init__()\n",
    "        \n",
    "        # EfficientNet\n",
    "#         self.kernels = kernels\n",
    "#         self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.backbone_2d = timm.create_model(\n",
    "            backbone_2d,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate = 0.1,\n",
    "            drop_path_rate = 0.1\n",
    "        )\n",
    "        \n",
    "        self.features_2d = nn.Sequential(*list(self.backbone_2d.children())[:-2] + [nn.AdaptiveAvgPool2d(1),nn.Flatten()])\n",
    "            \n",
    "        # WaveNet DilatedInception\n",
    "        kernel_size = [2, 3, 6, 7]\n",
    "\n",
    "        self.wave_module = nn.Sequential(\n",
    "            _WaveBlock(12, 1, 16, kernel_size, _DilatedInception),\n",
    "            _WaveBlock(8, 16, 32, kernel_size, _DilatedInception),\n",
    "            _WaveBlock(4, 32, 64, kernel_size, _DilatedInception),\n",
    "            _WaveBlock(1, 64, 64, kernel_size, _DilatedInception),\n",
    "        )\n",
    "        \n",
    "#         for i, kernel_size in enumerate(list(self.kernels)):\n",
    "#             sep_conv = nn.Conv1d(in_channels=in_channels, out_channels=self.planes, kernel_size=(kernel_size),\n",
    "#                                stride=1, padding=0, bias=False,)\n",
    "#             self.parallel_conv.append(sep_conv)\n",
    "\n",
    "#         self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "#         self.relu = nn.ReLU(inplace=False)\n",
    "#         self.conv1 = nn.Conv1d(in_channels=self.planes, out_channels=self.planes, kernel_size=fixed_kernel_size,\n",
    "#                                stride=2, padding=2, bias=False)\n",
    "#         self.block = self._make_resnet_layer(kernel_size=fixed_kernel_size, stride=1, padding=fixed_kernel_size//2)\n",
    "#         self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "#         self.avgpool = nn.AvgPool1d(kernel_size=4, stride=4, padding=2)\n",
    "#         self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=1280, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=4*64, out_features=128)\n",
    "        self.fc = nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "        self.fc1d = nn.Linear(in_features=128, out_features=num_classes)\n",
    "        self.fc2d = nn.Linear(in_features=128, out_features=num_classes)\n",
    "        \n",
    "        \n",
    "#         self.rnn1 = nn.GRU(input_size=156, hidden_size=156, num_layers=1, bidirectional=True)\n",
    "\n",
    "#     def _make_resnet_layer(self, kernel_size, stride, blocks=8, padding=0):\n",
    "#         layers = []\n",
    "#         downsample = None\n",
    "#         base_width = self.planes\n",
    "\n",
    "#         for i in range(blocks):\n",
    "#             downsampling = nn.Sequential(\n",
    "#                     nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "#                 )\n",
    "#             layers.append(ResNet_1D_Block(in_channels=self.planes, out_channels=self.planes, kernel_size=kernel_size,\n",
    "#                                        stride=stride, padding=padding, downsampling=downsampling))\n",
    "\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "    def _reshape_input(self, spec):\n",
    "        \"\"\"\n",
    "        Reshapes input (128, 256, 8) -> (512, 512, 3) monotone image.\n",
    "        \"\"\" \n",
    "        # === Get spectograms ===\n",
    "        spectograms = [spec[:, :, :, i:i+1] for i in range(4)]\n",
    "        spectograms = torch.cat(spectograms, dim=1)\n",
    "        \n",
    "        # === Get EEG spectograms ===\n",
    "        eegs = [spec[:, :, :, i:i+1] for i in range(4,8)]\n",
    "        eegs = torch.cat(eegs, dim=1)\n",
    "        \n",
    "        # === Reshape (512,512,3) ===\n",
    "        spec = spectograms\n",
    "            \n",
    "        spec = torch.cat([spec,spec,spec], dim=3)\n",
    "        spec = spec.permute(0, 3, 1, 2)\n",
    "        return spec\n",
    "\n",
    "    def forward(self, x, spec):\n",
    "        \n",
    "        \n",
    "        spec = self._reshape_input(spec)\n",
    "        spec = self.features_2d(spec)\n",
    "        \n",
    "        bs, length, in_dim = x.shape\n",
    "        x = x.transpose(1, 2).unsqueeze(dim=2)\n",
    "\n",
    "        x_ll_1 = self.wave_module(x[:, 0:1, :])\n",
    "        x_ll_2 = self.wave_module(x[:, 1:2, :])\n",
    "        x_ll = (F.adaptive_avg_pool2d(x_ll_1, (1, 1)) + F.adaptive_avg_pool2d(x_ll_2, (1, 1))) / 2\n",
    "\n",
    "        x_rl_1 = self.wave_module(x[:, 2:3, :])\n",
    "        x_rl_2 = self.wave_module(x[:, 3:4, :])\n",
    "        x_rl = (F.adaptive_avg_pool2d(x_rl_1, (1, 1)) + F.adaptive_avg_pool2d(x_rl_2, (1, 1))) / 2\n",
    "\n",
    "        x_lp_1 = self.wave_module(x[:, 4:5, :])\n",
    "        x_lp_2 = self.wave_module(x[:, 5:6, :])\n",
    "        x_lp = (F.adaptive_avg_pool2d(x_lp_1, (1, 1)) + F.adaptive_avg_pool2d(x_lp_2, (1, 1))) / 2\n",
    "\n",
    "        x_rp_1 = self.wave_module(x[:, 6:7, :])\n",
    "        x_rp_2 = self.wave_module(x[:, 7:8, :])\n",
    "        x_rp = (F.adaptive_avg_pool2d(x_rp_1, (1, 1)) + F.adaptive_avg_pool2d(x_rp_2, (1, 1))) / 2\n",
    "\n",
    "        new_out = torch.cat([x_ll, x_rl, x_lp, x_rp], axis=1).reshape(bs, -1)\n",
    "        \n",
    "        \n",
    "#         # print(spec.shape) #2, 1280, 16, 8\n",
    "#         out_sep = []\n",
    "\n",
    "#         for i in range(len(self.kernels)):\n",
    "#             sep = self.parallel_conv[i](x)\n",
    "#             out_sep.append(sep)\n",
    "\n",
    "#         out = torch.cat(out_sep, dim=2)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.conv1(out)  \n",
    "\n",
    "#         out = self.block(out)\n",
    "#         out = self.bn2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.avgpool(out)  \n",
    "\n",
    "\n",
    "#         out = out.reshape(out.shape[0], -1)  \n",
    "\n",
    "#         rnn_out, _ = self.rnn(x.permute(0,2, 1))\n",
    "#         new_rnn_h = rnn_out[:, -1, :]  \n",
    "\n",
    "#         new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "\n",
    "\n",
    "        new_out = self.fc2(new_out)  \n",
    "        out1d = self.fc1d(new_out)\n",
    "        \n",
    "        spec = self.fc1(spec)  \n",
    "        out2d = self.fc2d(spec)\n",
    "        \n",
    "        result = torch.cat([new_out, spec], dim=1)  \n",
    "        result = self.fc(result)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dd3fe09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:07.147400Z",
     "iopub.status.busy": "2024-03-05T12:06:07.147133Z",
     "iopub.status.idle": "2024-03-05T12:06:07.150898Z",
     "shell.execute_reply": "2024-03-05T12:06:07.150081Z"
    },
    "papermill": {
     "duration": 0.021869,
     "end_time": "2024-03-05T12:06:07.152975",
     "exception": false,
     "start_time": "2024-03-05T12:06:07.131106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iot = torch.randn(2, 128, 256, 8)\n",
    "# model = CustomModel(CFG)\n",
    "# output = model(iot)\n",
    "# print(output.shape)\n",
    "\n",
    "# del iot, model, output\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00eedae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:07.184763Z",
     "iopub.status.busy": "2024-03-05T12:06:07.184503Z",
     "iopub.status.idle": "2024-03-05T12:06:08.602553Z",
     "shell.execute_reply": "2024-03-05T12:06:08.601406Z"
    },
    "papermill": {
     "duration": 1.436329,
     "end_time": "2024-03-05T12:06:08.604646",
     "exception": false,
     "start_time": "2024-03-05T12:06:07.168317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "iot = torch.randn(2, CFG.num_channels, 5_000)#.cuda()\n",
    "spec = torch.randn(2, 128, 256, 8)#.cuda()\n",
    "\n",
    "model = EEGMegaNet(backbone_2d=CFG.model_name,\n",
    "                   in_channels_2d=8,\n",
    "                   pretrained=False,\n",
    "                   in_channels=CFG.num_channels,\n",
    "                   num_classes=CFG.target_size)\n",
    "\n",
    "output = model(iot, spec)\n",
    "print(output.shape)\n",
    "\n",
    "del iot, model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c019b57",
   "metadata": {
    "papermill": {
     "duration": 0.015291,
     "end_time": "2024-03-05T12:06:08.635996",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.620705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adan Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d2fe443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:08.668536Z",
     "iopub.status.busy": "2024-03-05T12:06:08.668158Z",
     "iopub.status.idle": "2024-03-05T12:06:08.694894Z",
     "shell.execute_reply": "2024-03-05T12:06:08.694065Z"
    },
    "papermill": {
     "duration": 0.045155,
     "end_time": "2024-03-05T12:06:08.696779",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.651624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "class Adan(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements a pytorch variant of Adan\n",
    "    Adan was proposed in\n",
    "    Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models[J]. arXiv preprint arXiv:2208.06677, 2022.\n",
    "    https://arxiv.org/abs/2208.06677\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n",
    "        lr (float, optional): learning rate. (default: 1e-3)\n",
    "        betas (Tuple[float, float, flot], optional): coefficients used for computing \n",
    "            running averages of gradient and its norm. (default: (0.98, 0.92, 0.99))\n",
    "        eps (float, optional): term added to the denominator to improve \n",
    "            numerical stability. (default: 1e-8)\n",
    "        weight_decay (float, optional): decoupled weight decay (L2 penalty) (default: 0)\n",
    "        max_grad_norm (float, optional): value used to clip \n",
    "            global grad norm (default: 0.0 no clip)\n",
    "        no_prox (bool): how to perform the decoupled weight decay (default: False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.98, 0.92, 0.99), eps=1e-8,\n",
    "                 weight_decay=0.2, max_grad_norm=0.0, no_prox=False):\n",
    "        if not 0.0 <= max_grad_norm:\n",
    "            raise ValueError(\"Invalid Max grad norm: {}\".format(max_grad_norm))\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        if not 0.0 <= betas[2] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 2: {}\".format(betas[2]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay,\n",
    "                        max_grad_norm=max_grad_norm, no_prox=no_prox)\n",
    "        super(Adan, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Adan, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('no_prox', False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def restart_opt(self):\n",
    "        for group in self.param_groups:\n",
    "            group['step'] = 0\n",
    "            for p in group['params']:\n",
    "                if p.requires_grad:\n",
    "                    state = self.state[p]\n",
    "                    # State initialization\n",
    "\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p)\n",
    "                    # Exponential moving average of gradient difference\n",
    "                    state['exp_avg_diff'] = torch.zeros_like(p)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "            Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        if self.defaults['max_grad_norm'] > 0:\n",
    "            device = self.param_groups[0]['params'][0].device\n",
    "            global_grad_norm = torch.zeros(1, device=device)\n",
    "\n",
    "            max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)\n",
    "            for group in self.param_groups:\n",
    "\n",
    "                for p in group['params']:\n",
    "                    if p.grad is not None:\n",
    "                        grad = p.grad\n",
    "                        global_grad_norm.add_(grad.pow(2).sum())\n",
    "\n",
    "            global_grad_norm = torch.sqrt(global_grad_norm)\n",
    "\n",
    "            clip_global_grad_norm = torch.clamp(max_grad_norm / (global_grad_norm + group['eps']), max=1.0)\n",
    "        else:\n",
    "            clip_global_grad_norm = 1.0\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, beta3 = group['betas']\n",
    "            # assume same step across group now to simplify things\n",
    "            # per parameter step can be easily support by making it tensor, or pass list into kernel\n",
    "            if 'step' in group:\n",
    "                group['step'] += 1\n",
    "            else:\n",
    "                group['step'] = 1\n",
    "\n",
    "            bias_correction1 = 1.0 - beta1 ** group['step']\n",
    "\n",
    "            bias_correction2 = 1.0 - beta2 ** group['step']\n",
    "\n",
    "            bias_correction3 = 1.0 - beta3 ** group['step']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['exp_avg'] = torch.zeros_like(p)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p)\n",
    "                    state['exp_avg_diff'] = torch.zeros_like(p)\n",
    "\n",
    "                grad = p.grad.mul_(clip_global_grad_norm)\n",
    "                if 'pre_grad' not in state or group['step'] == 1:\n",
    "                    state['pre_grad'] = grad\n",
    "\n",
    "                copy_grad = grad.clone()\n",
    "\n",
    "                exp_avg, exp_avg_sq, exp_avg_diff = state['exp_avg'], state['exp_avg_sq'], state['exp_avg_diff']\n",
    "                diff = grad - state['pre_grad']\n",
    "\n",
    "                update = grad + beta2 * diff\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)  # m_t\n",
    "                exp_avg_diff.mul_(beta2).add_(diff, alpha=1 - beta2)  # diff_t\n",
    "                exp_avg_sq.mul_(beta3).addcmul_(update, update, value=1 - beta3)  # n_t\n",
    "\n",
    "                denom = ((exp_avg_sq).sqrt() / math.sqrt(bias_correction3)).add_(group['eps'])\n",
    "                update = ((exp_avg / bias_correction1 + beta2 * exp_avg_diff / bias_correction2)).div_(denom)\n",
    "\n",
    "                if group['no_prox']:\n",
    "                    p.data.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "                    p.add_(update, alpha=-group['lr'])\n",
    "                else:\n",
    "                    p.add_(update, alpha=-group['lr'])\n",
    "                    p.data.div_(1 + group['lr'] * group['weight_decay'])\n",
    "\n",
    "                state['pre_grad'] = copy_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa26426",
   "metadata": {
    "papermill": {
     "duration": 0.016365,
     "end_time": "2024-03-05T12:06:08.728730",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.712365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb21085d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:08.761447Z",
     "iopub.status.busy": "2024-03-05T12:06:08.761170Z",
     "iopub.status.idle": "2024-03-05T12:06:08.771661Z",
     "shell.execute_reply": "2024-03-05T12:06:08.770830Z"
    },
    "papermill": {
     "duration": 0.029042,
     "end_time": "2024-03-05T12:06:08.773535",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.744493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "# def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "#     model.train()\n",
    "#     scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "#     losses = AverageMeter()\n",
    "#     start = end = time.time()\n",
    "#     global_step = 0\n",
    "#     for step, batch in enumerate(train_loader):\n",
    "#         spectrogram = batch['spectrogram'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "#         batch_size = labels.size(0)\n",
    "#         with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "#             y_preds= model(spectrogram)\n",
    "#             loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "#         if CFG.gradient_accumulation_steps > 1:\n",
    "#             loss = loss / CFG.gradient_accumulation_steps\n",
    "#         losses.update(loss.item(), batch_size)\n",
    "#         scaler.scale(loss).backward()\n",
    "#         grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "#         if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#             optimizer.zero_grad()\n",
    "#             global_step += 1\n",
    "#             if CFG.batch_scheduler:\n",
    "#                 scheduler.step()\n",
    "#         end = time.time()\n",
    "#         if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "#             print('Epoch: [{0}][{1}/{2}] '\n",
    "#                   'Elapsed {remain:s} '\n",
    "#                   'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "#                   'Grad: {grad_norm:.4f}  '\n",
    "#                   'LR: {lr:.8f}  '\n",
    "#                   .format(epoch+1, step, len(train_loader), \n",
    "#                           remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "#                           loss=losses,\n",
    "#                           grad_norm=grad_norm,\n",
    "#                           lr=scheduler.get_lr()[0]))\n",
    "#         if CFG.wandb:\n",
    "#             wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "#                        f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "#     return losses.avg\n",
    "\n",
    "\n",
    "# def valid_fn(valid_loader, model, criterion, device):\n",
    "#     losses = AverageMeter()\n",
    "#     model.eval()\n",
    "#     preds = []\n",
    "#     start = end = time.time()\n",
    "#     for step, batch in enumerate(valid_loader):\n",
    "#         spectrogram = batch['spectrogram'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "#         batch_size = labels.size(0)\n",
    "#         with torch.no_grad():\n",
    "#             y_preds = model(spectrogram)\n",
    "#             loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "#         if CFG.gradient_accumulation_steps > 1:\n",
    "#             loss = loss / CFG.gradient_accumulation_steps\n",
    "#         losses.update(loss.item(), batch_size)\n",
    "#         preds.append(nn.Softmax(dim=1)(y_preds).to('cpu').numpy())\n",
    "#         end = time.time()\n",
    "#         if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "#             print('EVAL: [{0}/{1}] '\n",
    "#                   'Elapsed {remain:s} '\n",
    "#                   'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "#                   .format(step, len(valid_loader),\n",
    "#                           loss=losses,\n",
    "#                           remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "#     predictions = np.concatenate(preds)\n",
    "#     return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad82234",
   "metadata": {
    "papermill": {
     "duration": 0.01538,
     "end_time": "2024-03-05T12:06:08.804258",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.788878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f4ba4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:08.836776Z",
     "iopub.status.busy": "2024-03-05T12:06:08.836528Z",
     "iopub.status.idle": "2024-03-05T12:06:08.846232Z",
     "shell.execute_reply": "2024-03-05T12:06:08.845381Z"
    },
    "papermill": {
     "duration": 0.028482,
     "end_time": "2024-03-05T12:06:08.848072",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.819590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # train loop\n",
    "# # ====================================================\n",
    "# def train_loop(folds, fold, directory):\n",
    "    \n",
    "#     LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "#     # ====================================================\n",
    "#     # loader\n",
    "#     # ====================================================\n",
    "#     if CFG.stage1_pop1:\n",
    "#         train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "#     else:\n",
    "#         train_folds = folds[(folds['fold'] != fold) & (folds['total_evaluators'] >= 10)].reset_index(drop=True)\n",
    "#     valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "#     valid_labels = valid_folds[ CFG.target_cols].values\n",
    "    \n",
    "#     train_dataset = CustomDataset(train_folds, augment=True, mode=\"train\")\n",
    "#     valid_dataset = CustomDataset(valid_folds, augment=False, mode=\"train\")\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset,\n",
    "#                               batch_size=CFG.batch_size,\n",
    "#                               shuffle=True,\n",
    "#                               num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "#     valid_loader = DataLoader(valid_dataset,\n",
    "#                               batch_size=CFG.batch_size * 2,\n",
    "#                               shuffle=False,\n",
    "#                               num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "#     # ====================================================\n",
    "#     # model & optimizer\n",
    "#     # ====================================================\n",
    "#     model = CustomModel(CFG)\n",
    "#     if CFG.stage2_pop2:\n",
    "#         model_weight = POP_1_DIR + f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\"\n",
    "#         checkpoint = torch.load(model_weight, map_location=device)\n",
    "#         model.load_state_dict(checkpoint[\"model\"])\n",
    "#     # CPMP: wrap the model to use all GPUs\n",
    "#     #model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "#     model.to(device)\n",
    "    \n",
    "#     def build_optimizer(cfg, model, device):\n",
    "#         lr = cfg.lr\n",
    "#         # lr = default_configs[\"lr\"]\n",
    "#         if cfg.optimizer == \"SAM\":\n",
    "#             base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "#             optimizer_model = SAM(model.parameters(), base_optimizer, lr=lr, momentum=0.9, weight_decay=cfg.weight_decay, adaptive=True)\n",
    "#         elif cfg.optimizer == \"Ranger21\":\n",
    "#             optimizer_model = Ranger21(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, \n",
    "#             num_epochs=cfg.epochs, num_batches_per_epoch=len(train_loader))\n",
    "#         elif cfg.optimizer == \"SGD\":\n",
    "#             optimizer_model = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9)\n",
    "#         elif cfg.optimizer == \"Adam\":\n",
    "#             optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n",
    "#         elif cfg.optimizer == \"Lion\":\n",
    "#             optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "#         elif cfg.optimizer == \"Adan\":\n",
    "#             optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "    \n",
    "#         return optimizer_model\n",
    "    \n",
    "#     optimizer = build_optimizer(CFG, model, device)\n",
    "    \n",
    "#     # ====================================================\n",
    "#     # scheduler\n",
    "#     # ====================================================\n",
    "#     # ====================================================\n",
    "\n",
    "#     def get_scheduler(optimizer):\n",
    "#         if CFG.scheduler=='ReduceLROnPlateau':\n",
    "#             scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n",
    "#         elif CFG.scheduler=='CosineAnnealingLR':\n",
    "#             scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n",
    "#         elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "#             scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n",
    "#         elif CFG.scheduler=='OneCycleLR':\n",
    "#             steps_per_epoch=len(train_loader),\n",
    "#             scheduler = OneCycleLR(optimizer=optimizer, epochs=CFG.epochs, anneal_strategy=\"cos\", pct_start=0.05, steps_per_epoch=len(train_loader),\n",
    "#         max_lr=CFG.lr, final_div_factor=100)\n",
    "#         return scheduler\n",
    "    \n",
    "#     scheduler = get_scheduler(optimizer)\n",
    "\n",
    "#     # ====================================================\n",
    "#     # loop\n",
    "#     # ====================================================\n",
    "#     criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    \n",
    "#     best_score = np.inf\n",
    "\n",
    "#     for epoch in range(CFG.epochs):\n",
    "\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         # train\n",
    "#         avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "#         # eval\n",
    "#         avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "#         elapsed = time.time() - start_time\n",
    "\n",
    "#         LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "#         if CFG.wandb:\n",
    "#             wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "#                        f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "#                        f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "#                        f\"[fold{fold}] score\": score})\n",
    "        \n",
    "#         if best_score > avg_val_loss:\n",
    "#             best_score = avg_val_loss\n",
    "#             LOGGER.info(f'Epoch {epoch+1} - Save Best valid loss: {avg_val_loss:.4f} Model')\n",
    "#             # CPMP: save the original model. It is stored as the module attribute of the DP model.\n",
    "#             if CFG.stage1_pop1:\n",
    "                \n",
    "#                 torch.save({'model': model.state_dict(),\n",
    "#                             'predictions': predictions},\n",
    "#                              directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\")\n",
    "#             else:\n",
    "                \n",
    "#                 torch.save({'model': model.state_dict(),\n",
    "#                             'predictions': predictions},\n",
    "#                              directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\")\n",
    "                \n",
    "#     if CFG.stage1_pop1:\n",
    "#         predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\", \n",
    "#                              map_location=torch.device('cpu'))['predictions']\n",
    "#     else:\n",
    "#         predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\", \n",
    "#                              map_location=torch.device('cpu'))['predictions']\n",
    "#     valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "#     valid_folds[CFG.target_cols] = valid_labels \n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "    \n",
    "#     return valid_folds, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "742017a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:08.880149Z",
     "iopub.status.busy": "2024-03-05T12:06:08.879819Z",
     "iopub.status.idle": "2024-03-05T12:06:08.884177Z",
     "shell.execute_reply": "2024-03-05T12:06:08.883318Z"
    },
    "papermill": {
     "duration": 0.022475,
     "end_time": "2024-03-05T12:06:08.886100",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.863625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     if CFG.train:\n",
    "#         oof_df = pd.DataFrame()\n",
    "#         scores = []\n",
    "#         for fold in range(CFG.n_fold):\n",
    "#             if fold in CFG.trn_fold:\n",
    "#                 _oof_df, score = train_loop(train, fold, POP_1_DIR)\n",
    "#                 oof_df = pd.concat([oof_df, _oof_df])\n",
    "#                 scores.append(score)\n",
    "#                 LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "#                 LOGGER.info(f'Score with best loss weights stage1: {score}')\n",
    "#         oof_df = oof_df.reset_index(drop=True)\n",
    "#         LOGGER.info(f\"========== CV ==========\")\n",
    "#         LOGGER.info(f'Score with best loss weights stage1: {np.mean(scores)}')\n",
    "#         oof_df.to_csv(POP_1_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage1.csv', index=False)\n",
    "        \n",
    "#     if CFG.wandb:\n",
    "#         wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50cc1677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:08.920607Z",
     "iopub.status.busy": "2024-03-05T12:06:08.920049Z",
     "iopub.status.idle": "2024-03-05T12:06:08.924558Z",
     "shell.execute_reply": "2024-03-05T12:06:08.923713Z"
    },
    "papermill": {
     "duration": 0.024015,
     "end_time": "2024-03-05T12:06:08.926630",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.902615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG.stage1_pop1 = False\n",
    "# CFG.stage2_pop2 = True\n",
    "# CFG.epochs = 5\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     if CFG.train:\n",
    "#         oof_df = pd.DataFrame()\n",
    "#         scores = []\n",
    "#         for fold in range(CFG.n_fold):\n",
    "#             if fold in CFG.trn_fold:\n",
    "#                 _oof_df, score = train_loop(train, fold, POP_2_DIR)\n",
    "#                 oof_df = pd.concat([oof_df, _oof_df])\n",
    "#                 scores.append(score)\n",
    "#                 LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "#                 LOGGER.info(f'Score with best loss weights stage2: {score}')\n",
    "#         oof_df = oof_df.reset_index(drop=True)\n",
    "#         LOGGER.info(f\"========== CV ==========\")\n",
    "#         LOGGER.info(f'Score with best loss weights stage2: {np.mean(scores)}')\n",
    "#         oof_df.to_csv(POP_2_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage2.csv', index=False)\n",
    "        \n",
    "#     if CFG.wandb:\n",
    "#         wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb159ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:08.961817Z",
     "iopub.status.busy": "2024-03-05T12:06:08.961547Z",
     "iopub.status.idle": "2024-03-05T12:06:09.003452Z",
     "shell.execute_reply": "2024-03-05T12:06:09.002607Z"
    },
    "papermill": {
     "duration": 0.062079,
     "end_time": "2024-03-05T12:06:09.005491",
     "exception": false,
     "start_time": "2024-03-05T12:06:08.943412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (samples, specs, labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        spectrogram = specs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds= model(samples, spectrogram)\n",
    "            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (samples, specs, labels) in enumerate(valid_loader):\n",
    "        samples = samples.to(device)\n",
    "        spectrogram = specs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(samples, spectrogram)\n",
    "            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(nn.Softmax(dim=1)(y_preds).to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold, directory):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    if CFG.stage1_pop1:\n",
    "        train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    else:\n",
    "        train_folds = folds[(folds['fold'] != fold) & (folds['total_evaluators'] >= 10)].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[ CFG.target_cols].values\n",
    "    \n",
    "    train_dataset = EEGDataset(train_folds, augment=True, mode=\"train\")\n",
    "    valid_dataset = EEGDataset(valid_folds, augment=False, mode=\"train\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = EEGMegaNet(backbone_2d=CFG.model_name,\n",
    "                   in_channels_2d=8,\n",
    "                   in_channels=CFG.num_channels,\n",
    "                   num_classes=CFG.target_size)\n",
    "    \n",
    "    if CFG.stage2_pop2:\n",
    "        model_weight = POP_1_DIR + f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\"\n",
    "        checkpoint = torch.load(model_weight, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    # CPMP: wrap the model to use all GPUs\n",
    "    #model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model.to(device)\n",
    "    \n",
    "    def build_optimizer(cfg, model, device):\n",
    "        lr = cfg.lr\n",
    "        # lr = default_configs[\"lr\"]\n",
    "        if cfg.optimizer == \"SAM\":\n",
    "            base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "            optimizer_model = SAM(model.parameters(), base_optimizer, lr=lr, momentum=0.9, weight_decay=cfg.weight_decay, adaptive=True)\n",
    "        elif cfg.optimizer == \"Ranger21\":\n",
    "            optimizer_model = Ranger21(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, \n",
    "            num_epochs=cfg.epochs, num_batches_per_epoch=len(train_loader))\n",
    "        elif cfg.optimizer == \"SGD\":\n",
    "            optimizer_model = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9)\n",
    "        elif cfg.optimizer == \"Adam\":\n",
    "            optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n",
    "        elif cfg.optimizer == \"Lion\":\n",
    "            optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "        elif cfg.optimizer == \"Adan\":\n",
    "            optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "    \n",
    "        return optimizer_model\n",
    "    \n",
    "    optimizer = build_optimizer(CFG, model, device)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    # ====================================================\n",
    "\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n",
    "        elif CFG.scheduler=='OneCycleLR':\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            scheduler = OneCycleLR(optimizer=optimizer, epochs=CFG.epochs, anneal_strategy=\"cos\", pct_start=0.05, steps_per_epoch=len(train_loader),\n",
    "        max_lr=CFG.lr, final_div_factor=100)\n",
    "        return scheduler\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    \n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score > avg_val_loss:\n",
    "            best_score = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best valid loss: {avg_val_loss:.4f} Model')\n",
    "            # CPMP: save the original model. It is stored as the module attribute of the DP model.\n",
    "            if CFG.stage1_pop1:\n",
    "                \n",
    "                torch.save({'model': model.state_dict(),\n",
    "                            'predictions': predictions},\n",
    "                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\")\n",
    "            else:\n",
    "                \n",
    "                torch.save({'model': model.state_dict(),\n",
    "                            'predictions': predictions},\n",
    "                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\")\n",
    "                \n",
    "    if CFG.stage1_pop1:\n",
    "        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    else:\n",
    "        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "    valid_folds[CFG.target_cols] = valid_labels \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61f1378e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:06:09.040329Z",
     "iopub.status.busy": "2024-03-05T12:06:09.039589Z",
     "iopub.status.idle": "2024-03-05T15:49:12.739688Z",
     "shell.execute_reply": "2024-03-05T15:49:12.738476Z"
    },
    "papermill": {
     "duration": 13383.719845,
     "end_time": "2024-03-05T15:49:12.742267",
     "exception": false,
     "start_time": "2024-03-05T12:06:09.022422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01f12c83dd541959b2837b7a3e9099d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/252] Elapsed 0m 5s (remain 23m 28s) Loss: 0.7210(0.7210) Grad: 86706.6641  LR: 0.00004062  \n",
      "Epoch: [1][50/252] Elapsed 1m 38s (remain 6m 28s) Loss: 0.4553(0.6349) Grad: 45559.2344  LR: 0.00092735  \n",
      "Epoch: [1][100/252] Elapsed 3m 12s (remain 4m 47s) Loss: 0.4029(0.5509) Grad: 62084.8359  LR: 0.00099738  \n",
      "Epoch: [1][150/252] Elapsed 4m 45s (remain 3m 11s) Loss: 0.4170(0.5033) Grad: 58384.4727  LR: 0.00098643  \n",
      "Epoch: [1][200/252] Elapsed 6m 19s (remain 1m 36s) Loss: 0.3480(0.4720) Grad: 45354.7383  LR: 0.00096711  \n",
      "Epoch: [1][250/252] Elapsed 7m 52s (remain 0m 1s) Loss: 0.3040(0.4468) Grad: 42341.5820  LR: 0.00093976  \n",
      "Epoch: [1][251/252] Elapsed 7m 54s (remain 0m 0s) Loss: 0.3265(0.4463) Grad: 49478.9141  LR: 0.00093914  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 25s) Loss: 0.4167(0.4167) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.4466(0.3769) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4463  avg_val_loss: 0.3769  time: 530s\n",
      "Epoch 1 - Save Best valid loss: 0.3769 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/252] Elapsed 0m 3s (remain 13m 22s) Loss: 0.4557(0.4557) Grad: 63679.0742  LR: 0.00093851  \n",
      "Epoch: [2][50/252] Elapsed 1m 36s (remain 6m 22s) Loss: 0.2851(0.3269) Grad: 35783.7344  LR: 0.00090331  \n",
      "Epoch: [2][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.2460(0.3256) Grad: 37018.8086  LR: 0.00086118  \n",
      "Epoch: [2][150/252] Elapsed 4m 45s (remain 3m 10s) Loss: 0.3754(0.3230) Grad: 51684.3945  LR: 0.00081284  \n",
      "Epoch: [2][200/252] Elapsed 6m 18s (remain 1m 36s) Loss: 0.3456(0.3191) Grad: 44191.2734  LR: 0.00075913  \n",
      "Epoch: [2][250/252] Elapsed 7m 52s (remain 0m 1s) Loss: 0.3384(0.3179) Grad: 40455.6055  LR: 0.00070097  \n",
      "Epoch: [2][251/252] Elapsed 7m 53s (remain 0m 0s) Loss: 0.1987(0.3174) Grad: 36805.8867  LR: 0.00069977  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 18s) Loss: 0.4064(0.4064) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3992(0.3681) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3174  avg_val_loss: 0.3681  time: 529s\n",
      "Epoch 2 - Save Best valid loss: 0.3681 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/252] Elapsed 0m 3s (remain 12m 48s) Loss: 0.3091(0.3091) Grad: 48843.2734  LR: 0.00069856  \n",
      "Epoch: [3][50/252] Elapsed 1m 36s (remain 6m 21s) Loss: 0.2634(0.2789) Grad: 40495.4570  LR: 0.00063683  \n",
      "Epoch: [3][100/252] Elapsed 3m 9s (remain 4m 43s) Loss: 0.3148(0.2737) Grad: 66042.6016  LR: 0.00057275  \n",
      "Epoch: [3][150/252] Elapsed 4m 43s (remain 3m 9s) Loss: 0.2901(0.2733) Grad: 72113.7656  LR: 0.00050741  \n",
      "Epoch: [3][200/252] Elapsed 6m 17s (remain 1m 35s) Loss: 0.2502(0.2711) Grad: 37300.9102  LR: 0.00044196  \n",
      "Epoch: [3][250/252] Elapsed 7m 51s (remain 0m 1s) Loss: 0.2399(0.2689) Grad: 43042.1133  LR: 0.00037751  \n",
      "Epoch: [3][251/252] Elapsed 7m 52s (remain 0m 0s) Loss: 0.2308(0.2687) Grad: 39402.1094  LR: 0.00037624  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 18s) Loss: 0.3736(0.3736) \n",
      "EVAL: [31/32] Elapsed 0m 52s (remain 0m 0s) Loss: 0.4049(0.3415) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2687  avg_val_loss: 0.3415  time: 526s\n",
      "Epoch 3 - Save Best valid loss: 0.3415 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/252] Elapsed 0m 3s (remain 12m 50s) Loss: 0.2396(0.2396) Grad: 37325.2695  LR: 0.00037496  \n",
      "Epoch: [4][50/252] Elapsed 1m 36s (remain 6m 20s) Loss: 0.1947(0.2426) Grad: 40930.2812  LR: 0.00031273  \n",
      "Epoch: [4][100/252] Elapsed 3m 10s (remain 4m 44s) Loss: 0.2715(0.2387) Grad: 45738.5586  LR: 0.00025372  \n",
      "Epoch: [4][150/252] Elapsed 4m 44s (remain 3m 10s) Loss: 0.2476(0.2411) Grad: 46887.7930  LR: 0.00019894  \n",
      "Epoch: [4][200/252] Elapsed 6m 18s (remain 1m 35s) Loss: 0.2714(0.2391) Grad: 52673.3203  LR: 0.00014935  \n",
      "Epoch: [4][250/252] Elapsed 7m 52s (remain 0m 1s) Loss: 0.2636(0.2375) Grad: 39652.5977  LR: 0.00010579  \n",
      "Epoch: [4][251/252] Elapsed 7m 53s (remain 0m 0s) Loss: 0.2192(0.2375) Grad: 43554.8398  LR: 0.00010498  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 18s) Loss: 0.3521(0.3521) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3988(0.3422) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2375  avg_val_loss: 0.3422  time: 528s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/252] Elapsed 0m 3s (remain 13m 0s) Loss: 0.2100(0.2100) Grad: 40098.0664  LR: 0.00010418  \n",
      "Epoch: [5][50/252] Elapsed 1m 37s (remain 6m 22s) Loss: 0.2506(0.2103) Grad: 49991.1680  LR: 0.00006769  \n",
      "Epoch: [5][100/252] Elapsed 3m 10s (remain 4m 45s) Loss: 0.1919(0.2111) Grad: 38143.0547  LR: 0.00003863  \n",
      "Epoch: [5][150/252] Elapsed 4m 44s (remain 3m 10s) Loss: 0.2217(0.2151) Grad: 56540.6328  LR: 0.00001752  \n",
      "Epoch: [5][200/252] Elapsed 6m 18s (remain 1m 36s) Loss: 0.2436(0.2160) Grad: 49174.6523  LR: 0.00000470  \n",
      "Epoch: [5][250/252] Elapsed 7m 52s (remain 0m 1s) Loss: 0.2097(0.2160) Grad: 37925.0430  LR: 0.00000040  \n",
      "Epoch: [5][251/252] Elapsed 7m 54s (remain 0m 0s) Loss: 0.2181(0.2160) Grad: 40986.3633  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 17s) Loss: 0.3601(0.3601) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3962(0.3398) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2160  avg_val_loss: 0.3398  time: 529s\n",
      "Epoch 5 - Save Best valid loss: 0.3398 Model\n",
      "========== fold: 0 result ==========\n",
      "Score with best loss weights stage1: 0.3398057226352772\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/252] Elapsed 0m 3s (remain 13m 2s) Loss: 0.7194(0.7194) Grad: 82078.0234  LR: 0.00004062  \n",
      "Epoch: [1][50/252] Elapsed 1m 37s (remain 6m 23s) Loss: 0.4504(0.6437) Grad: 81643.5625  LR: 0.00092735  \n",
      "Epoch: [1][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.3880(0.5485) Grad: 64453.3477  LR: 0.00099738  \n",
      "Epoch: [1][150/252] Elapsed 4m 45s (remain 3m 11s) Loss: 0.3563(0.5001) Grad: 57456.1602  LR: 0.00098643  \n",
      "Epoch: [1][200/252] Elapsed 6m 20s (remain 1m 36s) Loss: 0.3275(0.4685) Grad: 44179.1641  LR: 0.00096711  \n",
      "Epoch: [1][250/252] Elapsed 7m 54s (remain 0m 1s) Loss: 0.3505(0.4472) Grad: 50840.4961  LR: 0.00093976  \n",
      "Epoch: [1][251/252] Elapsed 7m 56s (remain 0m 0s) Loss: 0.3265(0.4467) Grad: 39804.6133  LR: 0.00093914  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 28s) Loss: 0.3567(0.3567) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3642(0.3844) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4467  avg_val_loss: 0.3844  time: 532s\n",
      "Epoch 1 - Save Best valid loss: 0.3844 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/252] Elapsed 0m 3s (remain 12m 53s) Loss: 0.3079(0.3079) Grad: 43223.5938  LR: 0.00093851  \n",
      "Epoch: [2][50/252] Elapsed 1m 37s (remain 6m 26s) Loss: 0.3544(0.3185) Grad: 98422.4531  LR: 0.00090331  \n",
      "Epoch: [2][100/252] Elapsed 3m 12s (remain 4m 47s) Loss: 0.3283(0.3255) Grad: 39303.4883  LR: 0.00086118  \n",
      "Epoch: [2][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.3712(0.3183) Grad: 45533.8711  LR: 0.00081284  \n",
      "Epoch: [2][200/252] Elapsed 6m 21s (remain 1m 36s) Loss: 0.2375(0.3188) Grad: 34434.6367  LR: 0.00075913  \n",
      "Epoch: [2][250/252] Elapsed 7m 56s (remain 0m 1s) Loss: 0.2686(0.3162) Grad: 40029.3164  LR: 0.00070097  \n",
      "Epoch: [2][251/252] Elapsed 7m 58s (remain 0m 0s) Loss: 0.3611(0.3164) Grad: 44631.3242  LR: 0.00069977  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 18s) Loss: 0.3235(0.3235) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3555(0.3541) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3164  avg_val_loss: 0.3541  time: 533s\n",
      "Epoch 2 - Save Best valid loss: 0.3541 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/252] Elapsed 0m 3s (remain 12m 58s) Loss: 0.2580(0.2580) Grad: 41883.4141  LR: 0.00069856  \n",
      "Epoch: [3][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.2607(0.2788) Grad: 34748.5781  LR: 0.00063683  \n",
      "Epoch: [3][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.1898(0.2808) Grad: 38543.1367  LR: 0.00057275  \n",
      "Epoch: [3][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.2284(0.2758) Grad: 36274.7305  LR: 0.00050741  \n",
      "Epoch: [3][200/252] Elapsed 6m 19s (remain 1m 36s) Loss: 0.2886(0.2744) Grad: 46005.9805  LR: 0.00044196  \n",
      "Epoch: [3][250/252] Elapsed 7m 54s (remain 0m 1s) Loss: 0.2715(0.2739) Grad: 41273.8086  LR: 0.00037751  \n",
      "Epoch: [3][251/252] Elapsed 7m 56s (remain 0m 0s) Loss: 0.2124(0.2737) Grad: 39148.1133  LR: 0.00037624  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 18s) Loss: 0.3015(0.3015) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3497(0.3424) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2737  avg_val_loss: 0.3424  time: 531s\n",
      "Epoch 3 - Save Best valid loss: 0.3424 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/252] Elapsed 0m 3s (remain 12m 53s) Loss: 0.2645(0.2645) Grad: 51339.4414  LR: 0.00037496  \n",
      "Epoch: [4][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.3345(0.2480) Grad: 45168.2383  LR: 0.00031273  \n",
      "Epoch: [4][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.2575(0.2474) Grad: 39080.1250  LR: 0.00025372  \n",
      "Epoch: [4][150/252] Elapsed 4m 45s (remain 3m 11s) Loss: 0.1774(0.2416) Grad: 42132.2812  LR: 0.00019894  \n",
      "Epoch: [4][200/252] Elapsed 6m 20s (remain 1m 36s) Loss: 0.2607(0.2404) Grad: 48453.2070  LR: 0.00014935  \n",
      "Epoch: [4][250/252] Elapsed 7m 54s (remain 0m 1s) Loss: 0.3065(0.2389) Grad: 44782.9570  LR: 0.00010579  \n",
      "Epoch: [4][251/252] Elapsed 7m 56s (remain 0m 0s) Loss: 0.3337(0.2393) Grad: 58081.7070  LR: 0.00010498  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 18s) Loss: 0.3103(0.3103) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3802(0.3493) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2393  avg_val_loss: 0.3493  time: 531s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/252] Elapsed 0m 3s (remain 12m 58s) Loss: 0.2014(0.2014) Grad: 39827.6523  LR: 0.00010418  \n",
      "Epoch: [5][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.2488(0.2169) Grad: 55745.9648  LR: 0.00006769  \n",
      "Epoch: [5][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.2136(0.2160) Grad: 43783.8359  LR: 0.00003863  \n",
      "Epoch: [5][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.1958(0.2183) Grad: 43345.8086  LR: 0.00001752  \n",
      "Epoch: [5][200/252] Elapsed 6m 21s (remain 1m 36s) Loss: 0.1974(0.2182) Grad: 37843.4922  LR: 0.00000470  \n",
      "Epoch: [5][250/252] Elapsed 7m 56s (remain 0m 1s) Loss: 0.3126(0.2186) Grad: 45722.7148  LR: 0.00000040  \n",
      "Epoch: [5][251/252] Elapsed 7m 57s (remain 0m 0s) Loss: 0.2313(0.2186) Grad: 49145.7852  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 17s) Loss: 0.3088(0.3088) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3774(0.3500) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2186  avg_val_loss: 0.3500  time: 533s\n",
      "========== fold: 1 result ==========\n",
      "Score with best loss weights stage1: 0.34241816539530534\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/252] Elapsed 0m 3s (remain 13m 24s) Loss: 0.7533(0.7533) Grad: 81173.2734  LR: 0.00004062  \n",
      "Epoch: [1][50/252] Elapsed 1m 38s (remain 6m 28s) Loss: 0.5453(0.6405) Grad: 50082.0078  LR: 0.00092735  \n",
      "Epoch: [1][100/252] Elapsed 3m 13s (remain 4m 48s) Loss: 0.3506(0.5539) Grad: 68670.0781  LR: 0.00099738  \n",
      "Epoch: [1][150/252] Elapsed 4m 47s (remain 3m 12s) Loss: 0.3672(0.4981) Grad: 61580.1836  LR: 0.00098643  \n",
      "Epoch: [1][200/252] Elapsed 6m 23s (remain 1m 37s) Loss: 0.3229(0.4668) Grad: 47100.3086  LR: 0.00096711  \n",
      "Epoch: [1][250/252] Elapsed 7m 57s (remain 0m 1s) Loss: 0.3467(0.4432) Grad: 46805.5469  LR: 0.00093976  \n",
      "Epoch: [1][251/252] Elapsed 7m 59s (remain 0m 0s) Loss: 0.4324(0.4432) Grad: 48528.0742  LR: 0.00093914  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.5116(0.5116) \n",
      "EVAL: [31/32] Elapsed 0m 54s (remain 0m 0s) Loss: 0.3600(0.3678) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4432  avg_val_loss: 0.3678  time: 535s\n",
      "Epoch 1 - Save Best valid loss: 0.3678 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/252] Elapsed 0m 3s (remain 13m 3s) Loss: 0.3420(0.3420) Grad: 42009.6406  LR: 0.00093851  \n",
      "Epoch: [2][50/252] Elapsed 1m 37s (remain 6m 23s) Loss: 0.3376(0.3262) Grad: 56905.8203  LR: 0.00090331  \n",
      "Epoch: [2][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.2911(0.3223) Grad: 44609.3398  LR: 0.00086118  \n",
      "Epoch: [2][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.3004(0.3200) Grad: 36160.6016  LR: 0.00081284  \n",
      "Epoch: [2][200/252] Elapsed 6m 20s (remain 1m 36s) Loss: 0.2869(0.3151) Grad: 38473.4766  LR: 0.00075913  \n",
      "Epoch: [2][250/252] Elapsed 7m 55s (remain 0m 1s) Loss: 0.2756(0.3137) Grad: 48604.8516  LR: 0.00070097  \n",
      "Epoch: [2][251/252] Elapsed 7m 57s (remain 0m 0s) Loss: 0.2850(0.3136) Grad: 39157.5312  LR: 0.00069977  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.4703(0.4703) \n",
      "EVAL: [31/32] Elapsed 0m 54s (remain 0m 0s) Loss: 0.3118(0.3441) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3136  avg_val_loss: 0.3441  time: 533s\n",
      "Epoch 2 - Save Best valid loss: 0.3441 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/252] Elapsed 0m 3s (remain 13m 4s) Loss: 0.2583(0.2583) Grad: 41572.3008  LR: 0.00069856  \n",
      "Epoch: [3][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.2805(0.2734) Grad: 55535.3672  LR: 0.00063683  \n",
      "Epoch: [3][100/252] Elapsed 3m 12s (remain 4m 47s) Loss: 0.3258(0.2730) Grad: 53775.9922  LR: 0.00057275  \n",
      "Epoch: [3][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.2963(0.2741) Grad: 41820.9883  LR: 0.00050741  \n",
      "Epoch: [3][200/252] Elapsed 6m 20s (remain 1m 36s) Loss: 0.3097(0.2707) Grad: 55778.4766  LR: 0.00044196  \n",
      "Epoch: [3][250/252] Elapsed 7m 55s (remain 0m 1s) Loss: 0.2445(0.2697) Grad: 51386.8164  LR: 0.00037751  \n",
      "Epoch: [3][251/252] Elapsed 7m 57s (remain 0m 0s) Loss: 0.2645(0.2697) Grad: 39180.6289  LR: 0.00037624  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.4588(0.4588) \n",
      "EVAL: [31/32] Elapsed 0m 54s (remain 0m 0s) Loss: 0.2799(0.3318) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2697  avg_val_loss: 0.3318  time: 533s\n",
      "Epoch 3 - Save Best valid loss: 0.3318 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/252] Elapsed 0m 3s (remain 12m 53s) Loss: 0.2427(0.2427) Grad: 51141.9297  LR: 0.00037496  \n",
      "Epoch: [4][50/252] Elapsed 1m 37s (remain 6m 22s) Loss: 0.2982(0.2333) Grad: 50907.2617  LR: 0.00031273  \n",
      "Epoch: [4][100/252] Elapsed 3m 10s (remain 4m 44s) Loss: 0.1920(0.2371) Grad: 30140.0254  LR: 0.00025372  \n",
      "Epoch: [4][150/252] Elapsed 4m 44s (remain 3m 10s) Loss: 0.2459(0.2337) Grad: 55801.6367  LR: 0.00019894  \n",
      "Epoch: [4][200/252] Elapsed 6m 19s (remain 1m 36s) Loss: 0.2510(0.2349) Grad: 49669.6680  LR: 0.00014935  \n",
      "Epoch: [4][250/252] Elapsed 7m 53s (remain 0m 1s) Loss: 0.2683(0.2343) Grad: 50314.3203  LR: 0.00010579  \n",
      "Epoch: [4][251/252] Elapsed 7m 55s (remain 0m 0s) Loss: 0.2009(0.2342) Grad: 36039.3242  LR: 0.00010498  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.4657(0.4657) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2852(0.3343) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2342  avg_val_loss: 0.3343  time: 530s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/252] Elapsed 0m 3s (remain 12m 58s) Loss: 0.2204(0.2204) Grad: 47902.3008  LR: 0.00010418  \n",
      "Epoch: [5][50/252] Elapsed 1m 37s (remain 6m 22s) Loss: 0.1831(0.2098) Grad: 37145.1836  LR: 0.00006769  \n",
      "Epoch: [5][100/252] Elapsed 3m 11s (remain 4m 45s) Loss: 0.2344(0.2147) Grad: 45894.0234  LR: 0.00003863  \n",
      "Epoch: [5][150/252] Elapsed 4m 45s (remain 3m 10s) Loss: 0.2092(0.2161) Grad: 38830.7773  LR: 0.00001752  \n",
      "Epoch: [5][200/252] Elapsed 6m 19s (remain 1m 36s) Loss: 0.1952(0.2156) Grad: 44622.5312  LR: 0.00000470  \n",
      "Epoch: [5][250/252] Elapsed 7m 53s (remain 0m 1s) Loss: 0.1773(0.2156) Grad: 38015.2812  LR: 0.00000040  \n",
      "Epoch: [5][251/252] Elapsed 7m 55s (remain 0m 0s) Loss: 0.2123(0.2156) Grad: 41361.6172  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 24s) Loss: 0.4608(0.4608) \n",
      "EVAL: [31/32] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2852(0.3361) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2156  avg_val_loss: 0.3361  time: 531s\n",
      "========== fold: 2 result ==========\n",
      "Score with best loss weights stage1: 0.3317610838565609\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/252] Elapsed 0m 3s (remain 13m 39s) Loss: 0.7823(0.7823) Grad: 95399.9844  LR: 0.00004062  \n",
      "Epoch: [1][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.5783(0.6481) Grad: 52939.3477  LR: 0.00092735  \n",
      "Epoch: [1][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.3358(0.5565) Grad: 47600.9258  LR: 0.00099738  \n",
      "Epoch: [1][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.4455(0.5067) Grad: 53512.4648  LR: 0.00098643  \n",
      "Epoch: [1][200/252] Elapsed 6m 20s (remain 1m 36s) Loss: 0.3968(0.4747) Grad: 53092.9492  LR: 0.00096711  \n",
      "Epoch: [1][250/252] Elapsed 7m 54s (remain 0m 1s) Loss: 0.2856(0.4526) Grad: 41246.9922  LR: 0.00093976  \n",
      "Epoch: [1][251/252] Elapsed 7m 56s (remain 0m 0s) Loss: 0.3319(0.4521) Grad: 44289.7188  LR: 0.00093914  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.3699(0.3699) \n",
      "EVAL: [31/32] Elapsed 0m 54s (remain 0m 0s) Loss: 0.4380(0.3625) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4521  avg_val_loss: 0.3625  time: 532s\n",
      "Epoch 1 - Save Best valid loss: 0.3625 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/252] Elapsed 0m 3s (remain 12m 59s) Loss: 0.2476(0.2476) Grad: 38111.5469  LR: 0.00093851  \n",
      "Epoch: [2][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.3845(0.3271) Grad: 47756.9805  LR: 0.00090331  \n",
      "Epoch: [2][100/252] Elapsed 3m 11s (remain 4m 46s) Loss: 0.3285(0.3217) Grad: 46466.7656  LR: 0.00086118  \n",
      "Epoch: [2][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.2783(0.3205) Grad: 45559.5859  LR: 0.00081284  \n",
      "Epoch: [2][200/252] Elapsed 6m 21s (remain 1m 36s) Loss: 0.2752(0.3222) Grad: 55742.5977  LR: 0.00075913  \n",
      "Epoch: [2][250/252] Elapsed 7m 56s (remain 0m 1s) Loss: 0.2867(0.3200) Grad: 42210.0273  LR: 0.00070097  \n",
      "Epoch: [2][251/252] Elapsed 7m 58s (remain 0m 0s) Loss: 0.2930(0.3198) Grad: 34051.4688  LR: 0.00069977  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 20s) Loss: 0.3855(0.3855) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.3927(0.3343) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3198  avg_val_loss: 0.3343  time: 536s\n",
      "Epoch 2 - Save Best valid loss: 0.3343 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/252] Elapsed 0m 3s (remain 13m 27s) Loss: 0.3362(0.3362) Grad: 39404.4219  LR: 0.00069856  \n",
      "Epoch: [3][50/252] Elapsed 1m 38s (remain 6m 26s) Loss: 0.3263(0.2889) Grad: 42716.7734  LR: 0.00063683  \n",
      "Epoch: [3][100/252] Elapsed 3m 12s (remain 4m 47s) Loss: 0.2487(0.2806) Grad: 36959.1758  LR: 0.00057275  \n",
      "Epoch: [3][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.2951(0.2812) Grad: 44067.7578  LR: 0.00050741  \n",
      "Epoch: [3][200/252] Elapsed 6m 21s (remain 1m 36s) Loss: 0.2937(0.2791) Grad: 43977.8281  LR: 0.00044196  \n",
      "Epoch: [3][250/252] Elapsed 7m 56s (remain 0m 1s) Loss: 0.2703(0.2745) Grad: 41710.5586  LR: 0.00037751  \n",
      "Epoch: [3][251/252] Elapsed 7m 57s (remain 0m 0s) Loss: 0.2037(0.2742) Grad: 31024.7070  LR: 0.00037624  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.3514(0.3514) \n",
      "EVAL: [31/32] Elapsed 0m 54s (remain 0m 0s) Loss: 0.3268(0.3235) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2742  avg_val_loss: 0.3235  time: 534s\n",
      "Epoch 3 - Save Best valid loss: 0.3235 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/252] Elapsed 0m 3s (remain 13m 0s) Loss: 0.1967(0.1967) Grad: 38810.8750  LR: 0.00037496  \n",
      "Epoch: [4][50/252] Elapsed 1m 37s (remain 6m 24s) Loss: 0.2445(0.2492) Grad: 42389.3398  LR: 0.00031273  \n",
      "Epoch: [4][100/252] Elapsed 3m 12s (remain 4m 47s) Loss: 0.2759(0.2423) Grad: 39636.9688  LR: 0.00025372  \n",
      "Epoch: [4][150/252] Elapsed 4m 46s (remain 3m 11s) Loss: 0.2553(0.2433) Grad: 35413.9219  LR: 0.00019894  \n",
      "Epoch: [4][200/252] Elapsed 6m 22s (remain 1m 37s) Loss: 0.2656(0.2434) Grad: 49847.8242  LR: 0.00014935  \n",
      "Epoch: [4][250/252] Elapsed 7m 57s (remain 0m 1s) Loss: 0.2592(0.2415) Grad: 40292.5078  LR: 0.00010579  \n",
      "Epoch: [4][251/252] Elapsed 7m 59s (remain 0m 0s) Loss: 0.2487(0.2416) Grad: 47331.9766  LR: 0.00010498  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 20s) Loss: 0.3758(0.3758) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3106(0.3234) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2416  avg_val_loss: 0.3234  time: 536s\n",
      "Epoch 4 - Save Best valid loss: 0.3234 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/252] Elapsed 0m 3s (remain 13m 21s) Loss: 0.1493(0.1493) Grad: 27037.9238  LR: 0.00010418  \n",
      "Epoch: [5][50/252] Elapsed 1m 38s (remain 6m 28s) Loss: 0.2584(0.2180) Grad: 50071.1133  LR: 0.00006769  \n",
      "Epoch: [5][100/252] Elapsed 3m 14s (remain 4m 50s) Loss: 0.2555(0.2174) Grad: 52111.2109  LR: 0.00003863  \n",
      "Epoch: [5][150/252] Elapsed 4m 49s (remain 3m 13s) Loss: 0.1916(0.2191) Grad: 34268.9258  LR: 0.00001752  \n",
      "Epoch: [5][200/252] Elapsed 6m 24s (remain 1m 37s) Loss: 0.1829(0.2213) Grad: 37837.6367  LR: 0.00000470  \n",
      "Epoch: [5][250/252] Elapsed 8m 0s (remain 0m 1s) Loss: 0.2155(0.2214) Grad: 37053.1836  LR: 0.00000040  \n",
      "Epoch: [5][251/252] Elapsed 8m 2s (remain 0m 0s) Loss: 0.2298(0.2214) Grad: 46171.3906  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.3718(0.3718) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3224(0.3270) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2214  avg_val_loss: 0.3270  time: 538s\n",
      "========== fold: 3 result ==========\n",
      "Score with best loss weights stage1: 0.3233949635971644\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/252] Elapsed 0m 3s (remain 13m 17s) Loss: 0.7684(0.7684) Grad: 74687.1953  LR: 0.00004062  \n",
      "Epoch: [1][50/252] Elapsed 1m 39s (remain 6m 30s) Loss: 0.5457(0.6550) Grad: 63186.0508  LR: 0.00092735  \n",
      "Epoch: [1][100/252] Elapsed 3m 13s (remain 4m 49s) Loss: 0.4038(0.5602) Grad: 48662.2422  LR: 0.00099738  \n",
      "Epoch: [1][150/252] Elapsed 4m 48s (remain 3m 13s) Loss: 0.3747(0.5108) Grad: 52347.2227  LR: 0.00098643  \n",
      "Epoch: [1][200/252] Elapsed 6m 24s (remain 1m 37s) Loss: 0.3762(0.4759) Grad: 53859.1523  LR: 0.00096711  \n",
      "Epoch: [1][250/252] Elapsed 7m 59s (remain 0m 1s) Loss: 0.2774(0.4534) Grad: 37693.2500  LR: 0.00093976  \n",
      "Epoch: [1][251/252] Elapsed 8m 1s (remain 0m 0s) Loss: 0.3175(0.4529) Grad: 43945.4688  LR: 0.00093914  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 22s) Loss: 0.4204(0.4204) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3356(0.3697) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4529  avg_val_loss: 0.3697  time: 538s\n",
      "Epoch 1 - Save Best valid loss: 0.3697 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/252] Elapsed 0m 3s (remain 13m 25s) Loss: 0.3431(0.3431) Grad: 36210.2344  LR: 0.00093851  \n",
      "Epoch: [2][50/252] Elapsed 1m 38s (remain 6m 28s) Loss: 0.3029(0.3370) Grad: 45177.1484  LR: 0.00090331  \n",
      "Epoch: [2][100/252] Elapsed 3m 13s (remain 4m 49s) Loss: 0.3161(0.3286) Grad: 41139.7188  LR: 0.00086118  \n",
      "Epoch: [2][150/252] Elapsed 4m 49s (remain 3m 13s) Loss: 0.3348(0.3257) Grad: 42753.6719  LR: 0.00081284  \n",
      "Epoch: [2][200/252] Elapsed 6m 25s (remain 1m 37s) Loss: 0.2850(0.3224) Grad: 45507.7188  LR: 0.00075913  \n",
      "Epoch: [2][250/252] Elapsed 8m 2s (remain 0m 1s) Loss: 0.3420(0.3209) Grad: 43096.5000  LR: 0.00070097  \n",
      "Epoch: [2][251/252] Elapsed 8m 4s (remain 0m 0s) Loss: 0.2749(0.3207) Grad: 35965.7852  LR: 0.00069977  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 25s) Loss: 0.4656(0.4656) \n",
      "EVAL: [31/32] Elapsed 1m 0s (remain 0m 0s) Loss: 0.3115(0.3637) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3207  avg_val_loss: 0.3637  time: 545s\n",
      "Epoch 2 - Save Best valid loss: 0.3637 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/252] Elapsed 0m 3s (remain 13m 39s) Loss: 0.3072(0.3072) Grad: 34337.5898  LR: 0.00069856  \n",
      "Epoch: [3][50/252] Elapsed 1m 39s (remain 6m 32s) Loss: 0.2579(0.2774) Grad: 40102.2539  LR: 0.00063683  \n",
      "Epoch: [3][100/252] Elapsed 3m 16s (remain 4m 53s) Loss: 0.2665(0.2765) Grad: 37082.3086  LR: 0.00057275  \n",
      "Epoch: [3][150/252] Elapsed 4m 54s (remain 3m 16s) Loss: 0.2369(0.2776) Grad: 38464.1602  LR: 0.00050741  \n",
      "Epoch: [3][200/252] Elapsed 6m 30s (remain 1m 39s) Loss: 0.2923(0.2763) Grad: 46141.2930  LR: 0.00044196  \n",
      "Epoch: [3][250/252] Elapsed 8m 7s (remain 0m 1s) Loss: 0.3180(0.2754) Grad: 39066.7031  LR: 0.00037751  \n",
      "Epoch: [3][251/252] Elapsed 8m 9s (remain 0m 0s) Loss: 0.2493(0.2753) Grad: 36762.0547  LR: 0.00037624  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 29s) Loss: 0.4341(0.4341) \n",
      "EVAL: [31/32] Elapsed 1m 2s (remain 0m 0s) Loss: 0.2790(0.3337) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2753  avg_val_loss: 0.3337  time: 553s\n",
      "Epoch 3 - Save Best valid loss: 0.3337 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/252] Elapsed 0m 3s (remain 13m 45s) Loss: 0.2585(0.2585) Grad: 40926.5391  LR: 0.00037496  \n",
      "Epoch: [4][50/252] Elapsed 1m 40s (remain 6m 37s) Loss: 0.2711(0.2503) Grad: 44559.0586  LR: 0.00031273  \n",
      "Epoch: [4][100/252] Elapsed 3m 17s (remain 4m 54s) Loss: 0.1855(0.2425) Grad: 33942.3242  LR: 0.00025372  \n",
      "Epoch: [4][150/252] Elapsed 4m 53s (remain 3m 16s) Loss: 0.2851(0.2454) Grad: 50167.3555  LR: 0.00019894  \n",
      "Epoch: [4][200/252] Elapsed 6m 29s (remain 1m 38s) Loss: 0.2859(0.2430) Grad: 40540.3984  LR: 0.00014935  \n",
      "Epoch: [4][250/252] Elapsed 8m 7s (remain 0m 1s) Loss: 0.2277(0.2417) Grad: 47489.1953  LR: 0.00010579  \n",
      "Epoch: [4][251/252] Elapsed 8m 9s (remain 0m 0s) Loss: 0.2133(0.2415) Grad: 35774.0664  LR: 0.00010498  \n",
      "EVAL: [0/32] Elapsed 0m 3s (remain 1m 35s) Loss: 0.4515(0.4515) \n",
      "EVAL: [31/32] Elapsed 1m 2s (remain 0m 0s) Loss: 0.2800(0.3353) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2415  avg_val_loss: 0.3353  time: 552s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/252] Elapsed 0m 3s (remain 13m 51s) Loss: 0.2436(0.2436) Grad: 47073.7500  LR: 0.00010418  \n",
      "Epoch: [5][50/252] Elapsed 1m 39s (remain 6m 33s) Loss: 0.1985(0.2243) Grad: 36976.3516  LR: 0.00006769  \n",
      "Epoch: [5][100/252] Elapsed 3m 16s (remain 4m 53s) Loss: 0.2343(0.2204) Grad: 45672.1875  LR: 0.00003863  \n",
      "Epoch: [5][150/252] Elapsed 4m 52s (remain 3m 15s) Loss: 0.2143(0.2198) Grad: 44063.3203  LR: 0.00001752  \n",
      "Epoch: [5][200/252] Elapsed 6m 28s (remain 1m 38s) Loss: 0.1978(0.2210) Grad: 46179.5078  LR: 0.00000470  \n",
      "Epoch: [5][250/252] Elapsed 8m 5s (remain 0m 1s) Loss: 0.3115(0.2222) Grad: 41069.5586  LR: 0.00000040  \n",
      "Epoch: [5][251/252] Elapsed 8m 7s (remain 0m 0s) Loss: 0.2773(0.2224) Grad: 46810.2266  LR: 0.00000040  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 25s) Loss: 0.4711(0.4711) \n",
      "EVAL: [31/32] Elapsed 0m 59s (remain 0m 0s) Loss: 0.2798(0.3443) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2224  avg_val_loss: 0.3443  time: 548s\n",
      "========== fold: 4 result ==========\n",
      "Score with best loss weights stage1: 0.33368180306744644\n",
      "========== CV ==========\n",
      "Score with best loss weights stage1: 0.33421234771035085\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        scores = []\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df, score = train_loop(train, fold, POP_1_DIR)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                scores.append(score)\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                LOGGER.info(f'Score with best loss weights stage1: {score}')\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        LOGGER.info(f'Score with best loss weights stage1: {np.mean(scores)}')\n",
    "        oof_df.to_csv(POP_1_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage1.csv', index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c082d022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T15:49:12.824019Z",
     "iopub.status.busy": "2024-03-05T15:49:12.822946Z",
     "iopub.status.idle": "2024-03-05T17:16:41.324035Z",
     "shell.execute_reply": "2024-03-05T17:16:41.322961Z"
    },
    "papermill": {
     "duration": 5248.545185,
     "end_time": "2024-03-05T17:16:41.327414",
     "exception": false,
     "start_time": "2024-03-05T15:49:12.782229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/77] Elapsed 0m 3s (remain 4m 13s) Loss: 0.3013(0.3013) Grad: 54780.7227  LR: 0.00004709  \n",
      "Epoch: [1][50/77] Elapsed 1m 40s (remain 0m 51s) Loss: 0.2268(0.2337) Grad: 51333.8047  LR: 0.00098035  \n",
      "Epoch: [1][76/77] Elapsed 2m 30s (remain 0m 0s) Loss: 0.2172(0.2296) Grad: 37590.8750  LR: 0.00093770  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 26s) Loss: 0.4566(0.4566) \n",
      "EVAL: [31/32] Elapsed 0m 59s (remain 0m 0s) Loss: 0.4531(0.4201) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2296  avg_val_loss: 0.4201  time: 211s\n",
      "Epoch 1 - Save Best valid loss: 0.4201 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/77] Elapsed 0m 3s (remain 4m 9s) Loss: 0.2333(0.2333) Grad: 53217.4414  LR: 0.00093561  \n",
      "Epoch: [2][50/77] Elapsed 1m 41s (remain 0m 51s) Loss: 0.1600(0.2018) Grad: 36284.3750  LR: 0.00079389  \n",
      "Epoch: [2][76/77] Elapsed 2m 31s (remain 0m 0s) Loss: 0.1958(0.2022) Grad: 46706.5430  LR: 0.00069703  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 26s) Loss: 0.5029(0.5029) \n",
      "EVAL: [31/32] Elapsed 1m 2s (remain 0m 0s) Loss: 0.5184(0.4513) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2022  avg_val_loss: 0.4513  time: 215s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/77] Elapsed 0m 3s (remain 4m 13s) Loss: 0.1740(0.1740) Grad: 40019.3672  LR: 0.00069308  \n",
      "Epoch: [3][50/77] Elapsed 1m 40s (remain 0m 51s) Loss: 0.1614(0.1688) Grad: 30320.8730  LR: 0.00048357  \n",
      "Epoch: [3][76/77] Elapsed 2m 30s (remain 0m 0s) Loss: 0.1629(0.1678) Grad: 39810.0820  LR: 0.00037335  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 27s) Loss: 0.4977(0.4977) \n",
      "EVAL: [31/32] Elapsed 1m 1s (remain 0m 0s) Loss: 0.4956(0.4675) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1678  avg_val_loss: 0.4675  time: 214s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/77] Elapsed 0m 3s (remain 4m 6s) Loss: 0.2094(0.2094) Grad: 50137.5273  LR: 0.00036920  \n",
      "Epoch: [4][50/77] Elapsed 1m 40s (remain 0m 51s) Loss: 0.1486(0.1510) Grad: 46561.8594  LR: 0.00018026  \n",
      "Epoch: [4][76/77] Elapsed 2m 31s (remain 0m 0s) Loss: 0.1374(0.1487) Grad: 46234.8086  LR: 0.00010317  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 28s) Loss: 0.4710(0.4710) \n",
      "EVAL: [31/32] Elapsed 1m 1s (remain 0m 0s) Loss: 0.4564(0.4377) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1487  avg_val_loss: 0.4377  time: 214s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/77] Elapsed 0m 3s (remain 4m 1s) Loss: 0.1400(0.1400) Grad: 61824.8438  LR: 0.00010057  \n",
      "Epoch: [5][50/77] Elapsed 1m 38s (remain 0m 50s) Loss: 0.1169(0.1415) Grad: 30324.7910  LR: 0.00001188  \n",
      "Epoch: [5][76/77] Elapsed 2m 27s (remain 0m 0s) Loss: 0.1365(0.1379) Grad: 38906.5195  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.4820(0.4820) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.4646(0.4471) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1379  avg_val_loss: 0.4471  time: 204s\n",
      "========== fold: 0 result ==========\n",
      "Score with best loss weights stage2: 0.4200883538586567\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/79] Elapsed 0m 3s (remain 4m 6s) Loss: 0.3057(0.3057) Grad: 55272.8086  LR: 0.00004672  \n",
      "Epoch: [1][50/79] Elapsed 1m 38s (remain 0m 53s) Loss: 0.2260(0.2364) Grad: 41528.6523  LR: 0.00098189  \n",
      "Epoch: [1][78/79] Elapsed 2m 31s (remain 0m 0s) Loss: 0.2354(0.2356) Grad: 38593.7695  LR: 0.00093775  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 20s) Loss: 0.3795(0.3795) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.5082(0.4326) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2356  avg_val_loss: 0.4326  time: 208s\n",
      "Epoch 1 - Save Best valid loss: 0.4326 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/79] Elapsed 0m 3s (remain 4m 5s) Loss: 0.1817(0.1817) Grad: 27841.7754  LR: 0.00093572  \n",
      "Epoch: [2][50/79] Elapsed 1m 38s (remain 0m 54s) Loss: 0.1808(0.2025) Grad: 39662.6406  LR: 0.00079844  \n",
      "Epoch: [2][78/79] Elapsed 2m 31s (remain 0m 0s) Loss: 0.1679(0.1997) Grad: 35269.9570  LR: 0.00069713  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.3962(0.3962) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.5663(0.4394) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1997  avg_val_loss: 0.4394  time: 208s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/79] Elapsed 0m 3s (remain 4m 19s) Loss: 0.1681(0.1681) Grad: 32405.9785  LR: 0.00069328  \n",
      "Epoch: [3][50/79] Elapsed 1m 38s (remain 0m 53s) Loss: 0.1392(0.1739) Grad: 32030.8906  LR: 0.00048922  \n",
      "Epoch: [3][78/79] Elapsed 2m 30s (remain 0m 0s) Loss: 0.2251(0.1736) Grad: 43903.1211  LR: 0.00037345  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.3882(0.3882) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.5693(0.4497) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1736  avg_val_loss: 0.4497  time: 207s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/79] Elapsed 0m 3s (remain 4m 5s) Loss: 0.1742(0.1742) Grad: 34028.9062  LR: 0.00036941  \n",
      "Epoch: [4][50/79] Elapsed 1m 37s (remain 0m 53s) Loss: 0.1369(0.1551) Grad: 37411.9961  LR: 0.00018462  \n",
      "Epoch: [4][78/79] Elapsed 2m 31s (remain 0m 0s) Loss: 0.1540(0.1548) Grad: 42889.3203  LR: 0.00010323  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 20s) Loss: 0.4171(0.4171) \n",
      "EVAL: [31/32] Elapsed 0m 54s (remain 0m 0s) Loss: 0.5890(0.4874) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1548  avg_val_loss: 0.4874  time: 207s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/79] Elapsed 0m 3s (remain 4m 5s) Loss: 0.1231(0.1231) Grad: 34143.1211  LR: 0.00010070  \n",
      "Epoch: [5][50/79] Elapsed 1m 38s (remain 0m 54s) Loss: 0.1236(0.1408) Grad: 26584.6758  LR: 0.00001311  \n",
      "Epoch: [5][78/79] Elapsed 2m 30s (remain 0m 0s) Loss: 0.1576(0.1421) Grad: 38588.4922  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 22s) Loss: 0.4128(0.4128) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.5813(0.4847) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1421  avg_val_loss: 0.4847  time: 208s\n",
      "========== fold: 1 result ==========\n",
      "Score with best loss weights stage2: 0.4325795969603999\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/80] Elapsed 0m 3s (remain 4m 18s) Loss: 0.2936(0.2936) Grad: 58272.6992  LR: 0.00004655  \n",
      "Epoch: [1][50/80] Elapsed 1m 38s (remain 0m 56s) Loss: 0.2339(0.2370) Grad: 54196.0039  LR: 0.00098261  \n",
      "Epoch: [1][79/80] Elapsed 2m 33s (remain 0m 0s) Loss: 0.1820(0.2357) Grad: 32385.9395  LR: 0.00093778  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.4609(0.4609) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3609(0.4487) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2357  avg_val_loss: 0.4487  time: 210s\n",
      "Epoch 1 - Save Best valid loss: 0.4487 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/80] Elapsed 0m 3s (remain 4m 9s) Loss: 0.1828(0.1828) Grad: 35502.3164  LR: 0.00093577  \n",
      "Epoch: [2][50/80] Elapsed 1m 38s (remain 0m 55s) Loss: 0.2288(0.1983) Grad: 44895.1641  LR: 0.00080062  \n",
      "Epoch: [2][79/80] Elapsed 2m 33s (remain 0m 0s) Loss: 0.1820(0.1965) Grad: 34243.7227  LR: 0.00069718  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 22s) Loss: 0.5098(0.5098) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.3755(0.4473) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1965  avg_val_loss: 0.4473  time: 211s\n",
      "Epoch 2 - Save Best valid loss: 0.4473 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/80] Elapsed 0m 3s (remain 4m 9s) Loss: 0.1721(0.1721) Grad: 33688.9023  LR: 0.00069337  \n",
      "Epoch: [3][50/80] Elapsed 1m 38s (remain 0m 55s) Loss: 0.1970(0.1718) Grad: 39102.8867  LR: 0.00049194  \n",
      "Epoch: [3][79/80] Elapsed 2m 33s (remain 0m 0s) Loss: 0.1893(0.1713) Grad: 44598.1992  LR: 0.00037351  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.4980(0.4980) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.3934(0.4621) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1713  avg_val_loss: 0.4621  time: 211s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/80] Elapsed 0m 3s (remain 4m 11s) Loss: 0.1405(0.1405) Grad: 29296.4570  LR: 0.00036951  \n",
      "Epoch: [4][50/80] Elapsed 1m 38s (remain 0m 56s) Loss: 0.1249(0.1492) Grad: 29471.1152  LR: 0.00018674  \n",
      "Epoch: [4][79/80] Elapsed 2m 34s (remain 0m 0s) Loss: 0.1760(0.1493) Grad: 48759.5898  LR: 0.00010326  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 22s) Loss: 0.5163(0.5163) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.4003(0.4748) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1493  avg_val_loss: 0.4748  time: 212s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/80] Elapsed 0m 3s (remain 4m 11s) Loss: 0.1060(0.1060) Grad: 35946.7227  LR: 0.00010077  \n",
      "Epoch: [5][50/80] Elapsed 1m 38s (remain 0m 56s) Loss: 0.1340(0.1367) Grad: 34171.7773  LR: 0.00001373  \n",
      "Epoch: [5][79/80] Elapsed 2m 34s (remain 0m 0s) Loss: 0.1565(0.1367) Grad: 31395.1836  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 23s) Loss: 0.5169(0.5169) \n",
      "EVAL: [31/32] Elapsed 0m 57s (remain 0m 0s) Loss: 0.3997(0.4827) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1367  avg_val_loss: 0.4827  time: 213s\n",
      "========== fold: 2 result ==========\n",
      "Score with best loss weights stage2: 0.4473044087988981\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/80] Elapsed 0m 3s (remain 4m 11s) Loss: 0.2873(0.2873) Grad: 60617.2031  LR: 0.00004655  \n",
      "Epoch: [1][50/80] Elapsed 1m 38s (remain 0m 56s) Loss: 0.2308(0.2285) Grad: 43037.7305  LR: 0.00098261  \n",
      "Epoch: [1][79/80] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3254(0.2282) Grad: 56967.9883  LR: 0.00093778  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.4530(0.4530) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.5576(0.4262) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2282  avg_val_loss: 0.4262  time: 210s\n",
      "Epoch 1 - Save Best valid loss: 0.4262 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/80] Elapsed 0m 3s (remain 4m 13s) Loss: 0.1780(0.1780) Grad: 35125.6602  LR: 0.00093577  \n",
      "Epoch: [2][50/80] Elapsed 1m 38s (remain 0m 56s) Loss: 0.1979(0.1958) Grad: 37848.2852  LR: 0.00080062  \n",
      "Epoch: [2][79/80] Elapsed 2m 34s (remain 0m 0s) Loss: 0.2148(0.1919) Grad: 45298.9883  LR: 0.00069718  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 24s) Loss: 0.4803(0.4803) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.5886(0.4584) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1919  avg_val_loss: 0.4584  time: 212s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/80] Elapsed 0m 3s (remain 4m 10s) Loss: 0.1378(0.1378) Grad: 29796.1992  LR: 0.00069337  \n",
      "Epoch: [3][50/80] Elapsed 1m 39s (remain 0m 56s) Loss: 0.1463(0.1666) Grad: 33028.4375  LR: 0.00049194  \n",
      "Epoch: [3][79/80] Elapsed 2m 34s (remain 0m 0s) Loss: 0.2036(0.1688) Grad: 46083.4766  LR: 0.00037351  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 23s) Loss: 0.4777(0.4777) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.5855(0.4484) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1688  avg_val_loss: 0.4484  time: 212s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/80] Elapsed 0m 3s (remain 4m 15s) Loss: 0.1347(0.1347) Grad: 36434.7461  LR: 0.00036951  \n",
      "Epoch: [4][50/80] Elapsed 1m 39s (remain 0m 56s) Loss: 0.1504(0.1547) Grad: 31879.2266  LR: 0.00018674  \n",
      "Epoch: [4][79/80] Elapsed 2m 34s (remain 0m 0s) Loss: 0.1244(0.1506) Grad: 34065.3516  LR: 0.00010326  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 19s) Loss: 0.4958(0.4958) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.6605(0.4695) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1506  avg_val_loss: 0.4695  time: 212s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/80] Elapsed 0m 3s (remain 4m 11s) Loss: 0.1236(0.1236) Grad: 31125.4551  LR: 0.00010077  \n",
      "Epoch: [5][50/80] Elapsed 1m 38s (remain 0m 55s) Loss: 0.1438(0.1389) Grad: 39658.3984  LR: 0.00001373  \n",
      "Epoch: [5][79/80] Elapsed 2m 33s (remain 0m 0s) Loss: 0.1333(0.1353) Grad: 35437.7148  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.4790(0.4790) \n",
      "EVAL: [31/32] Elapsed 0m 56s (remain 0m 0s) Loss: 0.6243(0.4517) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1353  avg_val_loss: 0.4517  time: 210s\n",
      "========== fold: 3 result ==========\n",
      "Score with best loss weights stage2: 0.4262003840729077\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/78] Elapsed 0m 3s (remain 4m 6s) Loss: 0.3314(0.3314) Grad: 55505.6523  LR: 0.00004690  \n",
      "Epoch: [1][50/78] Elapsed 1m 38s (remain 0m 51s) Loss: 0.2740(0.2506) Grad: 49671.7773  LR: 0.00098114  \n",
      "Epoch: [1][77/78] Elapsed 2m 29s (remain 0m 0s) Loss: 0.1743(0.2424) Grad: 31306.7500  LR: 0.00093773  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 20s) Loss: 0.6240(0.6240) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3992(0.4538) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2424  avg_val_loss: 0.4538  time: 206s\n",
      "Epoch 1 - Save Best valid loss: 0.4538 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/78] Elapsed 0m 3s (remain 4m 5s) Loss: 0.2098(0.2098) Grad: 32582.3066  LR: 0.00093566  \n",
      "Epoch: [2][50/78] Elapsed 1m 38s (remain 0m 52s) Loss: 0.1800(0.2029) Grad: 33119.4609  LR: 0.00079620  \n",
      "Epoch: [2][77/78] Elapsed 2m 29s (remain 0m 0s) Loss: 0.2066(0.2039) Grad: 36256.7617  LR: 0.00069708  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 23s) Loss: 0.6422(0.6422) \n",
      "EVAL: [31/32] Elapsed 0m 57s (remain 0m 0s) Loss: 0.4095(0.4684) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2039  avg_val_loss: 0.4684  time: 209s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/78] Elapsed 0m 3s (remain 4m 3s) Loss: 0.1739(0.1739) Grad: 33786.7734  LR: 0.00069318  \n",
      "Epoch: [3][50/78] Elapsed 1m 38s (remain 0m 52s) Loss: 0.1634(0.1726) Grad: 36766.3047  LR: 0.00048643  \n",
      "Epoch: [3][77/78] Elapsed 2m 29s (remain 0m 0s) Loss: 0.1196(0.1721) Grad: 31649.6016  LR: 0.00037340  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 23s) Loss: 0.6542(0.6542) \n",
      "EVAL: [31/32] Elapsed 0m 57s (remain 0m 0s) Loss: 0.3854(0.4775) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1721  avg_val_loss: 0.4775  time: 208s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/78] Elapsed 0m 3s (remain 4m 4s) Loss: 0.1800(0.1800) Grad: 31564.2305  LR: 0.00036931  \n",
      "Epoch: [4][50/78] Elapsed 1m 38s (remain 0m 51s) Loss: 0.1538(0.1530) Grad: 36591.7812  LR: 0.00018247  \n",
      "Epoch: [4][77/78] Elapsed 2m 29s (remain 0m 0s) Loss: 0.1548(0.1523) Grad: 43388.4102  LR: 0.00010320  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.6423(0.6423) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3624(0.4658) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.1523  avg_val_loss: 0.4658  time: 206s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/78] Elapsed 0m 3s (remain 4m 4s) Loss: 0.1577(0.1577) Grad: 31943.7168  LR: 0.00010064  \n",
      "Epoch: [5][50/78] Elapsed 1m 37s (remain 0m 51s) Loss: 0.1373(0.1434) Grad: 38032.4648  LR: 0.00001250  \n",
      "Epoch: [5][77/78] Elapsed 2m 29s (remain 0m 0s) Loss: 0.1327(0.1457) Grad: 25893.7051  LR: 0.00000042  \n",
      "EVAL: [0/32] Elapsed 0m 2s (remain 1m 21s) Loss: 0.6807(0.6807) \n",
      "EVAL: [31/32] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3837(0.4832) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.1457  avg_val_loss: 0.4832  time: 206s\n",
      "========== fold: 4 result ==========\n",
      "Score with best loss weights stage2: 0.4537840990056132\n",
      "========== CV ==========\n",
      "Score with best loss weights stage2: 0.4359913685392952\n"
     ]
    }
   ],
   "source": [
    "CFG.stage1_pop1 = False\n",
    "CFG.stage2_pop2 = True\n",
    "CFG.epochs = 5\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        scores = []\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df, score = train_loop(train, fold, POP_2_DIR)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                scores.append(score)\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                LOGGER.info(f'Score with best loss weights stage2: {score}')\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        LOGGER.info(f'Score with best loss weights stage2: {np.mean(scores)}')\n",
    "        oof_df.to_csv(POP_2_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage2.csv', index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3533880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:16:41.435735Z",
     "iopub.status.busy": "2024-03-05T17:16:41.435396Z",
     "iopub.status.idle": "2024-03-05T17:16:41.522474Z",
     "shell.execute_reply": "2024-03-05T17:16:41.521454Z"
    },
    "papermill": {
     "duration": 0.142288,
     "end_time": "2024-03-05T17:16:41.524507",
     "exception": false,
     "start_time": "2024-03-05T17:16:41.382219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stage2 Score with SparK resnet50 Spectrogram = 0.43599096805040505\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "# === Pre-process OOF ===\n",
    "label_cols = CFG.target_cols\n",
    "gt = oof_df[[\"eeg_id\"] + CFG.target_cols]\n",
    "gt.sort_values(by=\"eeg_id\", inplace=True)\n",
    "gt.reset_index(inplace=True, drop=True)\n",
    "\n",
    "preds = oof_df[[\"eeg_id\"] + CFG.pred_cols]\n",
    "preds.columns = [\"eeg_id\"] + CFG.target_cols\n",
    "preds.sort_values(by=\"eeg_id\", inplace=True)\n",
    "preds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_trues = gt[CFG.target_cols]\n",
    "y_preds = preds[CFG.target_cols]\n",
    "\n",
    "oof = pd.DataFrame(y_preds.copy())\n",
    "oof['id'] = np.arange(len(oof))\n",
    "\n",
    "true = pd.DataFrame(y_trues.copy())\n",
    "true['id'] = np.arange(len(true))\n",
    "\n",
    "cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
    "print('CV Stage2 Score with SparK resnet50 Spectrogram =',cv)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4378712,
     "sourceId": 7517324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4216847,
     "sourceId": 7652061,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4525836,
     "sourceId": 7742867,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4537599,
     "sourceId": 7759456,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4527097,
     "sourceId": 7761629,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18909.380854,
   "end_time": "2024-03-05T17:16:46.892204",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-05T12:01:37.511350",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1266948a83c0439b9f9d24bc2b81c2e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3489fa2805d84c8a9254f5a0416c162b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1266948a83c0439b9f9d24bc2b81c2e5",
       "placeholder": "​",
       "style": "IPY_MODEL_4175f8f387284363aca0d79dfb8c1e6b",
       "value": " 21.4M/21.4M [00:00&lt;00:00, 60.2MB/s]"
      }
     },
     "3a37df387bd042cdb36e7fcf5c13f14d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4175f8f387284363aca0d79dfb8c1e6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6cd0ede840e848c2a98e49f29585077f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "80061fd8deca4f3d81fc9fbd6f485cf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a74dc6cfa7cb42deadaddf206a82063c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bebc41410122480c929c7e69aad2d0c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a74dc6cfa7cb42deadaddf206a82063c",
       "placeholder": "​",
       "style": "IPY_MODEL_80061fd8deca4f3d81fc9fbd6f485cf5",
       "value": "model.safetensors: 100%"
      }
     },
     "c01f12c83dd541959b2837b7a3e9099d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bebc41410122480c929c7e69aad2d0c1",
        "IPY_MODEL_e5ae41b70c364e11a58b692fc2622328",
        "IPY_MODEL_3489fa2805d84c8a9254f5a0416c162b"
       ],
       "layout": "IPY_MODEL_3a37df387bd042cdb36e7fcf5c13f14d"
      }
     },
     "df57482ad9714497bd86ecf45e4f53fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5ae41b70c364e11a58b692fc2622328": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df57482ad9714497bd86ecf45e4f53fd",
       "max": 21355344.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6cd0ede840e848c2a98e49f29585077f",
       "value": 21355344.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
